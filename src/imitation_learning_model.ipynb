{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single model datapoints - state\n",
    "df1_x1 = pd.read_excel('./single_model_dataset/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x2 = pd.read_excel('./single_model_dataset/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x3 = pd.read_excel('./single_model_dataset/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x4 = pd.read_excel('./single_model_dataset/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x5 = pd.read_excel('./single_model_dataset/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df2_x1 = pd.read_excel('./single_model_dataset/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x2 = pd.read_excel('./single_model_dataset/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x3 = pd.read_excel('./single_model_dataset/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x4 = pd.read_excel('./single_model_dataset/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x5 = pd.read_excel('./single_model_dataset/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df3_x1 = pd.read_excel('./single_model_dataset/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x2 = pd.read_excel('./single_model_dataset/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x3 = pd.read_excel('./single_model_dataset/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x4 = pd.read_excel('./single_model_dataset/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x5 = pd.read_excel('./single_model_dataset/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df4_x1 = pd.read_excel('./single_model_dataset/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x2 = pd.read_excel('./single_model_dataset/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x3 = pd.read_excel('./single_model_dataset/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x4 = pd.read_excel('./single_model_dataset/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x5 = pd.read_excel('./single_model_dataset/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df5_x1 = pd.read_excel('./single_model_dataset/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x2 = pd.read_excel('./single_model_dataset/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x3 = pd.read_excel('./single_model_dataset/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x4 = pd.read_excel('./single_model_dataset/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x5 = pd.read_excel('./single_model_dataset/df5_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df6_x1 = pd.read_excel('./single_model_dataset/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x2 = pd.read_excel('./single_model_dataset/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x3 = pd.read_excel('./single_model_dataset/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x4 = pd.read_excel('./single_model_dataset/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x5 = pd.read_excel('./single_model_dataset/df6_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df7_x1 = pd.read_excel('./single_model_dataset/df7_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x2 = pd.read_excel('./single_model_dataset/df7_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x3 = pd.read_excel('./single_model_dataset/df7_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x4 = pd.read_excel('./single_model_dataset/df7_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x5 = pd.read_excel('./single_model_dataset/df7_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df8_x1 = pd.read_excel('./single_model_dataset/df8_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x2 = pd.read_excel('./single_model_dataset/df8_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x3 = pd.read_excel('./single_model_dataset/df8_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x4 = pd.read_excel('./single_model_dataset/df8_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x5 = pd.read_excel('./single_model_dataset/df8_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df9_x1 = pd.read_excel('./single_model_dataset/df9_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x2 = pd.read_excel('./single_model_dataset/df9_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x3 = pd.read_excel('./single_model_dataset/df9_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x4 = pd.read_excel('./single_model_dataset/df9_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x5 = pd.read_excel('./single_model_dataset/df9_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df10_x1 = pd.read_excel('./single_model_dataset/df10_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x2 = pd.read_excel('./single_model_dataset/df10_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x3 = pd.read_excel('./single_model_dataset/df10_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x4 = pd.read_excel('./single_model_dataset/df10_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x5 = pd.read_excel('./single_model_dataset/df10_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df11_x1 = pd.read_excel('./single_model_dataset/df11_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x2 = pd.read_excel('./single_model_dataset/df11_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x3 = pd.read_excel('./single_model_dataset/df11_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x4 = pd.read_excel('./single_model_dataset/df11_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x5 = pd.read_excel('./single_model_dataset/df11_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df12_x1 = pd.read_excel('./single_model_dataset/df12_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x2 = pd.read_excel('./single_model_dataset/df12_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x3 = pd.read_excel('./single_model_dataset/df12_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x4 = pd.read_excel('./single_model_dataset/df12_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x5 = pd.read_excel('./single_model_dataset/df12_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df13_x1 = pd.read_excel('./single_model_dataset/df13_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x2 = pd.read_excel('./single_model_dataset/df13_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x3 = pd.read_excel('./single_model_dataset/df13_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x4 = pd.read_excel('./single_model_dataset/df13_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x5 = pd.read_excel('./single_model_dataset/df13_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df14_x1 = pd.read_excel('./single_model_dataset/df14_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x2 = pd.read_excel('./single_model_dataset/df14_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x3 = pd.read_excel('./single_model_dataset/df14_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x4 = pd.read_excel('./single_model_dataset/df14_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x5 = pd.read_excel('./single_model_dataset/df14_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df15_x1 = pd.read_excel('./single_model_dataset/df15_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x2 = pd.read_excel('./single_model_dataset/df15_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x3 = pd.read_excel('./single_model_dataset/df15_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x4 = pd.read_excel('./single_model_dataset/df15_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x5 = pd.read_excel('./single_model_dataset/df15_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df16_x1 = pd.read_excel('./single_model_dataset/df16_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x2 = pd.read_excel('./single_model_dataset/df16_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x3 = pd.read_excel('./single_model_dataset/df16_3/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df17_x = pd.read_excel('./single_model_dataset/df17/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x = pd.read_excel('./single_model_dataset/df18/val_X.xls',header=None).iloc[1: , :]\n",
    "df19_x = pd.read_excel('./single_model_dataset/df19/val_X.xls',header=None).iloc[1: , :]\n",
    "df20_x = pd.read_excel('./single_model_dataset/df20/val_X.xls',header=None).iloc[1: , :]\n",
    "df21_x = pd.read_excel('./single_model_dataset/df21/val_X.xls',header=None).iloc[1: , :]\n",
    "df22_x = pd.read_excel('./single_model_dataset/df22/val_X.xls',header=None).iloc[1: , :]\n",
    "df23_x = pd.read_excel('./single_model_dataset/df23/val_X.xls',header=None).iloc[1: , :]\n",
    "df24_x = pd.read_excel('./single_model_dataset/df24/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df25_x1 = pd.read_excel('./New_dataset_2/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df25_x2 = pd.read_excel('./New_dataset_2/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df25_x3 = pd.read_excel('./New_dataset_2/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df25_x4 = pd.read_excel('./New_dataset_2/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df25_x5 = pd.read_excel('./New_dataset_2/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df26_x1 = pd.read_excel('./New_dataset_2/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df26_x2 = pd.read_excel('./New_dataset_2/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df26_x3 = pd.read_excel('./New_dataset_2/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df26_x4 = pd.read_excel('./New_dataset_2/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df26_x5 = pd.read_excel('./New_dataset_2/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df27_x1 = pd.read_excel('./New_dataset_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df27_x2 = pd.read_excel('./New_dataset_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df27_x3 = pd.read_excel('./New_dataset_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df27_x4 = pd.read_excel('./New_dataset_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df28_x1 = pd.read_excel('./New_dataset_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df28_x2 = pd.read_excel('./New_dataset_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df28_x3 = pd.read_excel('./New_dataset_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df28_x4 = pd.read_excel('./New_dataset_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "#df28_x5 = pd.read_excel('./New_dataset_2/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df29_x1 = pd.read_excel('./New_dataset_2/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df29_x2 = pd.read_excel('./New_dataset_2/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df29_x3 = pd.read_excel('./New_dataset_2/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df29_x4 = pd.read_excel('./New_dataset_2/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df29_x5 = pd.read_excel('./New_dataset_2/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df30_x1 = pd.read_excel('./New_dataset_2/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df30_x2 = pd.read_excel('./New_dataset_2/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df30_x3 = pd.read_excel('./New_dataset_2/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df30_x4 = pd.read_excel('./New_dataset_2/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df30_x5 = pd.read_excel('./New_dataset_2/df5_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df31_x1 = pd.read_excel('./New_dataset_2/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df31_x2 = pd.read_excel('./New_dataset_2/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df31_x3 = pd.read_excel('./New_dataset_2/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df31_x4 = pd.read_excel('./New_dataset_2/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df31_x5 = pd.read_excel('./New_dataset_2/df6_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df32_x1 = pd.read_excel('./New_Data_2/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df32_x2 = pd.read_excel('./New_Data_2/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df32_x3 = pd.read_excel('./New_Data_2/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df32_x4 = pd.read_excel('./New_Data_2/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df32_x5 = pd.read_excel('./New_Data_2/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df33_x1 = pd.read_excel('./New_Data_2/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df33_x2 = pd.read_excel('./New_Data_2/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df33_x3 = pd.read_excel('./New_Data_2/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df33_x4 = pd.read_excel('./New_Data_2/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df33_x5 = pd.read_excel('./New_Data_2/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df34_x1 = pd.read_excel('./New_Data_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df34_x2 = pd.read_excel('./New_Data_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df34_x3 = pd.read_excel('./New_Data_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df34_x4 = pd.read_excel('./New_Data_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df35_x1 = pd.read_excel('./New_Data_2/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df35_x2 = pd.read_excel('./New_Data_2/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df35_x3 = pd.read_excel('./New_Data_2/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df35_x4 = pd.read_excel('./New_Data_2/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df35_x5 = pd.read_excel('./New_Data_2/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df36_x1 = pd.read_excel('./New_Data_2/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df36_x2 = pd.read_excel('./New_Data_2/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df36_x3 = pd.read_excel('./New_Data_2/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df36_x4 = pd.read_excel('./New_Data_2/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df37_x1 = pd.read_excel('./New_Data_2/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df37_x2 = pd.read_excel('./New_Data_2/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df37_x3 = pd.read_excel('./New_Data_2/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df37_x4 = pd.read_excel('./New_Data_2/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df38_x1 = pd.read_excel('./New_Data_2/df7_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df38_x2 = pd.read_excel('./New_Data_2/df7_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df38_x3 = pd.read_excel('./New_Data_2/df7_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df38_x4 = pd.read_excel('./New_Data_2/df7_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df38_x5 = pd.read_excel('./New_Data_2/df7_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df39_x1 = pd.read_excel('./New_Data_2/df8_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df39_x2 = pd.read_excel('./New_Data_2/df8_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df39_x3 = pd.read_excel('./New_Data_2/df8_3/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df40_x = pd.read_excel('./mlme_data_set/Dataset/df1/val_X.xls',header=None).iloc[1: , :]\n",
    "df41_x = pd.read_excel('./mlme_data_set/Dataset/df2/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x = pd.read_excel('./mlme_data_set/Dataset/df3/val_X.xls',header=None).iloc[1: , :]\n",
    "df43_x = pd.read_excel('./mlme_data_set/Dataset/df4/val_X.xls',header=None).iloc[1: , :]\n",
    "df44_x = pd.read_excel('./mlme_data_set/Dataset/df5/val_X.xls',header=None).iloc[1: , :]\n",
    "df45_x = pd.read_excel('./mlme_data_set/Dataset/df6/val_X.xls',header=None).iloc[1: , :]\n",
    "df46_x = pd.read_excel('./mlme_data_set/Dataset/df7/val_X.xls',header=None).iloc[1: , :]\n",
    "df47_x = pd.read_excel('./mlme_data_set/Dataset/df8/val_X.xls',header=None).iloc[1: , :]\n",
    "df48_x = pd.read_excel('./mlme_data_set/Dataset/df9/val_X.xls',header=None).iloc[1: , :]\n",
    "df49_x = pd.read_excel('./mlme_data_set/Dataset/df10/val_X.xls',header=None).iloc[1: , :]\n",
    "df50_x = pd.read_excel('./mlme_data_set/Dataset/df11/val_X.xls',header=None).iloc[1: , :]\n",
    "df51_x = pd.read_excel('./mlme_data_set/Dataset/df12/val_X.xls',header=None).iloc[1: , :]\n",
    "df52_x = pd.read_excel('./mlme_data_set/Dataset/df13/val_X.xls',header=None).iloc[1: , :]\n",
    "df53_x = pd.read_excel('./mlme_data_set/Dataset/df14/val_X.xls',header=None).iloc[1: , :]\n",
    "df54_x = pd.read_excel('./mlme_data_set/Dataset/df15/val_X.xls',header=None).iloc[1: , :]\n",
    "df55_x = pd.read_excel('./mlme_data_set/Dataset/df16/val_X.xls',header=None).iloc[1: , :]\n",
    "df56_x = pd.read_excel('./mlme_data_set/Dataset/df17/val_X.xls',header=None).iloc[1: , :]\n",
    "df57_x = pd.read_excel('./mlme_data_set/Dataset/df18/val_X.xls',header=None).iloc[1: , :]\n",
    "df58_x = pd.read_excel('./mlme_data_set/Dataset/df19/val_X.xls',header=None).iloc[1: , :]\n",
    "df59_x = pd.read_excel('./mlme_data_set/Dataset/df20/val_X.xls',header=None).iloc[1: , :]\n",
    "df60_x = pd.read_excel('./mlme_data_set/Dataset/df21/val_X.xls',header=None).iloc[1: , :]\n",
    "df61_x = pd.read_excel('./mlme_data_set/Dataset/df22/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df62_x1 = pd.read_excel('./mlme_data_set/Dataset/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x2 = pd.read_excel('./mlme_data_set/Dataset/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x3 = pd.read_excel('./mlme_data_set/Dataset/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x4 = pd.read_excel('./mlme_data_set/Dataset/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x5 = pd.read_excel('./mlme_data_set/Dataset/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x6 = pd.read_excel('./mlme_data_set/Dataset/df3_6/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x7 = pd.read_excel('./mlme_data_set/Dataset/df3_7/val_X.xls',header=None).iloc[1: , :]\n",
    "df62_x8 = pd.read_excel('./mlme_data_set/Dataset/df3_8/val_X.xls',header=None).iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for two models\n",
    "#model 1\n",
    "df1_x1 = pd.read_excel('./single_model_dataset/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x2 = pd.read_excel('./single_model_dataset/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x3 = pd.read_excel('./single_model_dataset/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x4 = pd.read_excel('./single_model_dataset/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x5 = pd.read_excel('./single_model_dataset/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df2_x1 = pd.read_excel('./single_model_dataset/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x2 = pd.read_excel('./single_model_dataset/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x3 = pd.read_excel('./single_model_dataset/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x4 = pd.read_excel('./single_model_dataset/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x5 = pd.read_excel('./single_model_dataset/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df3_x1 = pd.read_excel('./single_model_dataset/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x2 = pd.read_excel('./single_model_dataset/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x3 = pd.read_excel('./single_model_dataset/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x4 = pd.read_excel('./single_model_dataset/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x5 = pd.read_excel('./single_model_dataset/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df4_x1 = pd.read_excel('./single_model_dataset/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x2 = pd.read_excel('./single_model_dataset/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x3 = pd.read_excel('./single_model_dataset/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x4 = pd.read_excel('./single_model_dataset/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x5 = pd.read_excel('./single_model_dataset/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df5_x1 = pd.read_excel('./single_model_dataset/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x2 = pd.read_excel('./single_model_dataset/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x3 = pd.read_excel('./single_model_dataset/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x4 = pd.read_excel('./single_model_dataset/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x5 = pd.read_excel('./single_model_dataset/df5_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df6_x1 = pd.read_excel('./single_model_dataset/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x2 = pd.read_excel('./single_model_dataset/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x3 = pd.read_excel('./single_model_dataset/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x4 = pd.read_excel('./single_model_dataset/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x5 = pd.read_excel('./single_model_dataset/df6_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df7_x1 = pd.read_excel('./single_model_dataset/df11_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x2 = pd.read_excel('./single_model_dataset/df11_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x3 = pd.read_excel('./single_model_dataset/df11_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x4 = pd.read_excel('./single_model_dataset/df11_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x5 = pd.read_excel('./single_model_dataset/df11_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df8_x1 = pd.read_excel('./single_model_dataset/df12_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x2 = pd.read_excel('./single_model_dataset/df12_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x3 = pd.read_excel('./single_model_dataset/df12_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x4 = pd.read_excel('./single_model_dataset/df12_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x5 = pd.read_excel('./single_model_dataset/df12_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df9_x1 = pd.read_excel('./single_model_dataset/df13_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x2 = pd.read_excel('./single_model_dataset/df13_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x3 = pd.read_excel('./single_model_dataset/df13_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x4 = pd.read_excel('./single_model_dataset/df13_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x5 = pd.read_excel('./single_model_dataset/df13_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df10_x1 = pd.read_excel('./single_model_dataset/df14_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x2 = pd.read_excel('./single_model_dataset/df14_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x3 = pd.read_excel('./single_model_dataset/df14_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x4 = pd.read_excel('./single_model_dataset/df14_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x5 = pd.read_excel('./single_model_dataset/df14_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df11_x1 = pd.read_excel('./single_model_dataset/df15_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x2 = pd.read_excel('./single_model_dataset/df15_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x3 = pd.read_excel('./single_model_dataset/df15_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x4 = pd.read_excel('./single_model_dataset/df15_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x5 = pd.read_excel('./single_model_dataset/df15_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df12_x1 = pd.read_excel('./New_Data_2/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x2 = pd.read_excel('./New_Data_2/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x3 = pd.read_excel('./New_Data_2/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x4 = pd.read_excel('./New_Data_2/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x5 = pd.read_excel('./New_Data_2/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df13_x1 = pd.read_excel('./New_Data_2/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x2 = pd.read_excel('./New_Data_2/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x3 = pd.read_excel('./New_Data_2/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x4 = pd.read_excel('./New_Data_2/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df13_x5 = pd.read_excel('./New_Data_2/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df14_x1 = pd.read_excel('./New_Data_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x2 = pd.read_excel('./New_Data_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x3 = pd.read_excel('./New_Data_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x4 = pd.read_excel('./New_Data_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df15_x1 = pd.read_excel('./New_Data_2/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x2 = pd.read_excel('./New_Data_2/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x3 = pd.read_excel('./New_Data_2/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x4 = pd.read_excel('./New_Data_2/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x5 = pd.read_excel('./New_Data_2/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df16_x1 = pd.read_excel('./New_Data_2/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x2 = pd.read_excel('./New_Data_2/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x3 = pd.read_excel('./New_Data_2/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x4 = pd.read_excel('./New_Data_2/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df17_x1 = pd.read_excel('./New_Data_2/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df17_x2 = pd.read_excel('./New_Data_2/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df17_x3 = pd.read_excel('./New_Data_2/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df17_x4 = pd.read_excel('./New_Data_2/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df18_x1 = pd.read_excel('./New_Data_2/df7_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x2 = pd.read_excel('./New_Data_2/df7_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x3 = pd.read_excel('./New_Data_2/df7_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x4 = pd.read_excel('./New_Data_2/df7_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x5 = pd.read_excel('./New_Data_2/df7_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df19_x1 = pd.read_excel('./New_Data_2/df8_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df19_x2 = pd.read_excel('./New_Data_2/df8_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df19_x3 = pd.read_excel('./New_Data_2/df8_3/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df20_x = pd.read_excel('./mlme_data_set/Dataset/df1/val_X.xls',header=None).iloc[1: , :]\n",
    "df21_x = pd.read_excel('./mlme_data_set/Dataset/df2/val_X.xls',header=None).iloc[1: , :]\n",
    "df22_x = pd.read_excel('./mlme_data_set/Dataset/df3/val_X.xls',header=None).iloc[1: , :]\n",
    "df23_x = pd.read_excel('./mlme_data_set/Dataset/df4/val_X.xls',header=None).iloc[1: , :]\n",
    "df24_x = pd.read_excel('./mlme_data_set/Dataset/df5/val_X.xls',header=None).iloc[1: , :]\n",
    "df25_x = pd.read_excel('./mlme_data_set/Dataset/df6/val_X.xls',header=None).iloc[1: , :]\n",
    "df26_x = pd.read_excel('./mlme_data_set/Dataset/df7/val_X.xls',header=None).iloc[1: , :]\n",
    "df27_x = pd.read_excel('./mlme_data_set/Dataset/df8/val_X.xls',header=None).iloc[1: , :]\n",
    "df28_x = pd.read_excel('./mlme_data_set/Dataset/df9/val_X.xls',header=None).iloc[1: , :]\n",
    "df29_x = pd.read_excel('./mlme_data_set/Dataset/df10/val_X.xls',header=None).iloc[1: , :]\n",
    "df30_x = pd.read_excel('./mlme_data_set/Dataset/df11/val_X.xls',header=None).iloc[1: , :]\n",
    "df31_x = pd.read_excel('./mlme_data_set/Dataset/df12/val_X.xls',header=None).iloc[1: , :]\n",
    "df32_x = pd.read_excel('./mlme_data_set/Dataset/df13/val_X.xls',header=None).iloc[1: , :]\n",
    "df33_x = pd.read_excel('./mlme_data_set/Dataset/df14/val_X.xls',header=None).iloc[1: , :]\n",
    "df34_x = pd.read_excel('./mlme_data_set/Dataset/df15/val_X.xls',header=None).iloc[1: , :]\n",
    "df35_x = pd.read_excel('./mlme_data_set/Dataset/df16/val_X.xls',header=None).iloc[1: , :]\n",
    "df36_x = pd.read_excel('./mlme_data_set/Dataset/df17/val_X.xls',header=None).iloc[1: , :]\n",
    "df37_x = pd.read_excel('./mlme_data_set/Dataset/df18/val_X.xls',header=None).iloc[1: , :]\n",
    "df38_x = pd.read_excel('./mlme_data_set/Dataset/df19/val_X.xls',header=None).iloc[1: , :]\n",
    "df39_x = pd.read_excel('./mlme_data_set/Dataset/df20/val_X.xls',header=None).iloc[1: , :]\n",
    "df40_x = pd.read_excel('./mlme_data_set/Dataset/df21/val_X.xls',header=None).iloc[1: , :]\n",
    "df41_x = pd.read_excel('./mlme_data_set/Dataset/df22/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df42_x1 = pd.read_excel('./mlme_data_set/Dataset/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x2 = pd.read_excel('./mlme_data_set/Dataset/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x3 = pd.read_excel('./mlme_data_set/Dataset/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x4 = pd.read_excel('./mlme_data_set/Dataset/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x5 = pd.read_excel('./mlme_data_set/Dataset/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x6 = pd.read_excel('./mlme_data_set/Dataset/df3_6/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x7 = pd.read_excel('./mlme_data_set/Dataset/df3_7/val_X.xls',header=None).iloc[1: , :]\n",
    "df42_x8 = pd.read_excel('./mlme_data_set/Dataset/df3_8/val_X.xls',header=None).iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1_x1.append(df1_x2).append(df1_x3).append(df1_x4).append(df1_x5).append(df2_x1).append(df2_x2).append(df2_x3).append(df2_x4).append(df2_x5).append(df3_x1).append(df3_x2).append(df3_x3).append(df3_x4).append(df3_x5).append(df4_x1).append(df4_x2).append(df4_x3).append(df4_x4).append(df4_x5).append(df5_x1).append(df5_x2).append(df5_x3).append(df5_x4).append(df5_x5).append(df6_x1).append(df6_x2).append(df6_x3).append(df6_x4).append(df6_x5).append(df7_x1).append(df7_x2).append(df7_x3).append(df7_x4).append(df7_x5).append(df8_x1).append(df8_x2).append(df8_x3).append(df8_x4).append(df8_x5).append(df9_x1).append(df9_x2).append(df9_x3).append(df9_x4).append(df9_x5).append(df10_x1).append(df10_x2).append(df10_x3).append(df10_x4).append(df10_x5).append(df11_x1).append(df11_x2).append(df11_x3).append(df11_x4).append(df11_x5).append(df12_x1).append(df12_x2).append(df12_x3).append(df12_x4).append(df12_x5).append(df13_x1).append(df13_x2).append(df13_x3).append(df13_x4).append(df13_x5).append(df14_x1).append(df14_x2).append(df14_x3).append(df14_x4).append(df15_x1).append(df15_x2).append(df15_x3).append(df15_x4).append(df15_x5).append(df16_x1).append(df16_x2).append(df16_x3).append(df16_x4).append(df17_x1).append(df17_x2).append(df17_x3).append(df17_x4).append(df18_x1).append(df18_x2).append(df18_x3).append(df18_x4).append(df18_x5).append(df19_x1).append(df19_x2).append(df19_x3).append(df20_x).append(df21_x).append(df22_x).append(df23_x).append(df24_x).append(df25_x).append(df26_x).append(df27_x).append(df28_x).append(df29_x).append(df30_x).append(df31_x).append(df32_x).append(df33_x).append(df34_x).append(df35_x).append(df36_x).append(df37_x).append(df38_x).append(df39_x).append(df40_x).append(df41_x).append(df42_x1).append(df42_x2).append(df42_x3).append(df42_x4).append(df42_x5).append(df42_x6).append(df42_x7).append(df42_x8)\n",
    "x_renamed = x.rename(columns={0:\"x\",1:\"theta1\",2:\"theta2\",3:\"v\",4:\"dtheta1\",5:\"dtheta2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for two models\n",
    "#model 2\n",
    "df1_x1 = pd.read_excel('./single_model_dataset/df7_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x2 = pd.read_excel('./single_model_dataset/df7_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x3 = pd.read_excel('./single_model_dataset/df7_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x4 = pd.read_excel('./single_model_dataset/df7_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df1_x5 = pd.read_excel('./single_model_dataset/df7_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df2_x1 = pd.read_excel('./single_model_dataset/df8_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x2 = pd.read_excel('./single_model_dataset/df8_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x3 = pd.read_excel('./single_model_dataset/df8_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x4 = pd.read_excel('./single_model_dataset/df8_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df2_x5 = pd.read_excel('./single_model_dataset/df8_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df3_x1 = pd.read_excel('./single_model_dataset/df9_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x2 = pd.read_excel('./single_model_dataset/df9_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x3 = pd.read_excel('./single_model_dataset/df9_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x4 = pd.read_excel('./single_model_dataset/df9_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df3_x5 = pd.read_excel('./single_model_dataset/df9_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df4_x1 = pd.read_excel('./single_model_dataset/df10_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x2 = pd.read_excel('./single_model_dataset/df10_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x3 = pd.read_excel('./single_model_dataset/df10_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x4 = pd.read_excel('./single_model_dataset/df10_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df4_x5 = pd.read_excel('./single_model_dataset/df10_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df5_x1 = pd.read_excel('./New_dataset_2/df1_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x2 = pd.read_excel('./New_dataset_2/df1_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x3 = pd.read_excel('./New_dataset_2/df1_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x4 = pd.read_excel('./New_dataset_2/df1_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df5_x5 = pd.read_excel('./New_dataset_2/df1_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df6_x1 = pd.read_excel('./New_dataset_2/df2_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x2 = pd.read_excel('./New_dataset_2/df2_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x3 = pd.read_excel('./New_dataset_2/df2_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x4 = pd.read_excel('./New_dataset_2/df2_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df6_x5 = pd.read_excel('./New_dataset_2/df2_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df7_x1 = pd.read_excel('./New_dataset_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x2 = pd.read_excel('./New_dataset_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x3 = pd.read_excel('./New_dataset_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df7_x4 = pd.read_excel('./New_dataset_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df8_x1 = pd.read_excel('./New_dataset_2/df3_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x2 = pd.read_excel('./New_dataset_2/df3_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x3 = pd.read_excel('./New_dataset_2/df3_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df8_x4 = pd.read_excel('./New_dataset_2/df3_4/val_X.xls',header=None).iloc[1: , :]\n",
    "#df28_x5 = pd.read_excel('./New_dataset_2/df3_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df9_x1 = pd.read_excel('./New_dataset_2/df4_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x2 = pd.read_excel('./New_dataset_2/df4_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x3 = pd.read_excel('./New_dataset_2/df4_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x4 = pd.read_excel('./New_dataset_2/df4_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df9_x5 = pd.read_excel('./New_dataset_2/df4_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df10_x1 = pd.read_excel('./New_dataset_2/df5_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x2 = pd.read_excel('./New_dataset_2/df5_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x3 = pd.read_excel('./New_dataset_2/df5_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x4 = pd.read_excel('./New_dataset_2/df5_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df10_x5 = pd.read_excel('./New_dataset_2/df5_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df11_x1 = pd.read_excel('./New_dataset_2/df6_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x2 = pd.read_excel('./New_dataset_2/df6_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x3 = pd.read_excel('./New_dataset_2/df6_3/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x4 = pd.read_excel('./New_dataset_2/df6_4/val_X.xls',header=None).iloc[1: , :]\n",
    "df11_x5 = pd.read_excel('./New_dataset_2/df6_5/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df12_x1 = pd.read_excel('./single_model_dataset/df16_1/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x2 = pd.read_excel('./single_model_dataset/df16_2/val_X.xls',header=None).iloc[1: , :]\n",
    "df12_x3 = pd.read_excel('./single_model_dataset/df16_3/val_X.xls',header=None).iloc[1: , :]\n",
    "\n",
    "df13_x = pd.read_excel('./single_model_dataset/df17/val_X.xls',header=None).iloc[1: , :]\n",
    "df14_x = pd.read_excel('./single_model_dataset/df18/val_X.xls',header=None).iloc[1: , :]\n",
    "df15_x = pd.read_excel('./single_model_dataset/df19/val_X.xls',header=None).iloc[1: , :]\n",
    "df16_x = pd.read_excel('./single_model_dataset/df20/val_X.xls',header=None).iloc[1: , :]\n",
    "df17_x = pd.read_excel('./single_model_dataset/df21/val_X.xls',header=None).iloc[1: , :]\n",
    "df18_x = pd.read_excel('./single_model_dataset/df22/val_X.xls',header=None).iloc[1: , :]\n",
    "df19_x = pd.read_excel('./single_model_dataset/df23/val_X.xls',header=None).iloc[1: , :]\n",
    "df20_x = pd.read_excel('./single_model_dataset/df24/val_X.xls',header=None).iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df1_x1.append(df1_x2).append(df1_x3).append(df1_x4).append(df1_x5).append(df2_x1).append(df2_x2).append(df2_x3).append(df2_x4).append(df2_x5).append(df3_x1).append(df3_x2).append(df3_x3).append(df3_x4).append(df3_x5).append(df4_x1).append(df4_x2).append(df4_x3).append(df4_x4).append(df4_x5).append(df5_x1).append(df5_x2).append(df5_x3).append(df5_x4).append(df5_x5).append(df6_x1).append(df6_x2).append(df6_x3).append(df6_x4).append(df6_x5).append(df7_x1).append(df7_x2).append(df7_x3).append(df7_x4).append(df8_x1).append(df8_x2).append(df8_x3).append(df8_x4).append(df9_x1).append(df9_x2).append(df9_x3).append(df9_x4).append(df9_x5).append(df10_x1).append(df10_x2).append(df10_x3).append(df10_x4).append(df10_x5).append(df11_x1).append(df11_x2).append(df11_x3).append(df11_x4).append(df11_x5).append(df12_x1).append(df12_x2).append(df12_x3).append(df13_x).append(df14_x).append(df15_x).append(df16_x).append(df17_x).append(df18_x).append(df19_x).append(df20_x)\n",
    "x_renamed = x.rename(columns={0:\"x\",1:\"theta1\",2:\"theta2\",3:\"v\",4:\"dtheta1\",5:\"dtheta2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single model datapoints - force\n",
    "df1_f1 = pd.read_excel('./single_model_dataset/df1_1/val_F.xls',header=None)\n",
    "df1_f2 = pd.read_excel('./single_model_dataset/df1_2/val_F.xls',header=None)\n",
    "df1_f3 = pd.read_excel('./single_model_dataset/df1_3/val_F.xls',header=None)\n",
    "df1_f4 = pd.read_excel('./single_model_dataset/df1_4/val_F.xls',header=None)\n",
    "df1_f5 = pd.read_excel('./single_model_dataset/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df2_f1 = pd.read_excel('./single_model_dataset/df2_1/val_F.xls',header=None)\n",
    "df2_f2 = pd.read_excel('./single_model_dataset/df2_2/val_F.xls',header=None)\n",
    "df2_f3 = pd.read_excel('./single_model_dataset/df2_3/val_F.xls',header=None)\n",
    "df2_f4 = pd.read_excel('./single_model_dataset/df2_4/val_F.xls',header=None)\n",
    "df2_f5 = pd.read_excel('./single_model_dataset/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df3_f1 = pd.read_excel('./single_model_dataset/df3_1/val_F.xls',header=None)\n",
    "df3_f2 = pd.read_excel('./single_model_dataset/df3_2/val_F.xls',header=None)\n",
    "df3_f3 = pd.read_excel('./single_model_dataset/df3_3/val_F.xls',header=None)\n",
    "df3_f4 = pd.read_excel('./single_model_dataset/df3_4/val_F.xls',header=None)\n",
    "df3_f5 = pd.read_excel('./single_model_dataset/df3_5/val_F.xls',header=None)\n",
    "\n",
    "df4_f1 = pd.read_excel('./single_model_dataset/df4_1/val_F.xls',header=None)\n",
    "df4_f2 = pd.read_excel('./single_model_dataset/df4_2/val_F.xls',header=None)\n",
    "df4_f3 = pd.read_excel('./single_model_dataset/df4_3/val_F.xls',header=None)\n",
    "df4_f4 = pd.read_excel('./single_model_dataset/df4_4/val_F.xls',header=None)\n",
    "df4_f5 = pd.read_excel('./single_model_dataset/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df5_f1 = pd.read_excel('./single_model_dataset/df5_1/val_F.xls',header=None)\n",
    "df5_f2 = pd.read_excel('./single_model_dataset/df5_2/val_F.xls',header=None)\n",
    "df5_f3 = pd.read_excel('./single_model_dataset/df5_3/val_F.xls',header=None)\n",
    "df5_f4 = pd.read_excel('./single_model_dataset/df5_4/val_F.xls',header=None)\n",
    "df5_f5 = pd.read_excel('./single_model_dataset/df5_5/val_F.xls',header=None)\n",
    "\n",
    "df6_f1 = pd.read_excel('./single_model_dataset/df6_1/val_F.xls',header=None)\n",
    "df6_f2 = pd.read_excel('./single_model_dataset/df6_2/val_F.xls',header=None)\n",
    "df6_f3 = pd.read_excel('./single_model_dataset/df6_3/val_F.xls',header=None)\n",
    "df6_f4 = pd.read_excel('./single_model_dataset/df6_4/val_F.xls',header=None)\n",
    "df6_f5 = pd.read_excel('./single_model_dataset/df6_5/val_F.xls',header=None)\n",
    "\n",
    "df7_f1 = pd.read_excel('./single_model_dataset/df7_1/val_F.xls',header=None)\n",
    "df7_f2 = pd.read_excel('./single_model_dataset/df7_2/val_F.xls',header=None)\n",
    "df7_f3 = pd.read_excel('./single_model_dataset/df7_3/val_F.xls',header=None)\n",
    "df7_f4 = pd.read_excel('./single_model_dataset/df7_4/val_F.xls',header=None)\n",
    "df7_f5 = pd.read_excel('./single_model_dataset/df7_5/val_F.xls',header=None)\n",
    "\n",
    "df8_f1 = pd.read_excel('./single_model_dataset/df8_1/val_F.xls',header=None)\n",
    "df8_f2 = pd.read_excel('./single_model_dataset/df8_2/val_F.xls',header=None)\n",
    "df8_f3 = pd.read_excel('./single_model_dataset/df8_3/val_F.xls',header=None)\n",
    "df8_f4 = pd.read_excel('./single_model_dataset/df8_4/val_F.xls',header=None)\n",
    "df8_f5 = pd.read_excel('./single_model_dataset/df8_5/val_F.xls',header=None)\n",
    "\n",
    "df9_f1 = pd.read_excel('./single_model_dataset/df9_1/val_F.xls',header=None)\n",
    "df9_f2 = pd.read_excel('./single_model_dataset/df9_2/val_F.xls',header=None)\n",
    "df9_f3 = pd.read_excel('./single_model_dataset/df9_3/val_F.xls',header=None)\n",
    "df9_f4 = pd.read_excel('./single_model_dataset/df9_4/val_F.xls',header=None)\n",
    "df9_f5 = pd.read_excel('./single_model_dataset/df9_5/val_F.xls',header=None)\n",
    "\n",
    "df10_f1 = pd.read_excel('./single_model_dataset/df10_1/val_F.xls',header=None)\n",
    "df10_f2 = pd.read_excel('./single_model_dataset/df10_2/val_F.xls',header=None)\n",
    "df10_f3 = pd.read_excel('./single_model_dataset/df10_3/val_F.xls',header=None)\n",
    "df10_f4 = pd.read_excel('./single_model_dataset/df10_4/val_F.xls',header=None)\n",
    "df10_f5 = pd.read_excel('./single_model_dataset/df10_5/val_F.xls',header=None)\n",
    "\n",
    "df11_f1 = pd.read_excel('./single_model_dataset/df11_1/val_F.xls',header=None)\n",
    "df11_f2 = pd.read_excel('./single_model_dataset/df11_2/val_F.xls',header=None)\n",
    "df11_f3 = pd.read_excel('./single_model_dataset/df11_3/val_F.xls',header=None)\n",
    "df11_f4 = pd.read_excel('./single_model_dataset/df11_4/val_F.xls',header=None)\n",
    "df11_f5 = pd.read_excel('./single_model_dataset/df11_5/val_F.xls',header=None)\n",
    "\n",
    "df12_f1 = pd.read_excel('./single_model_dataset/df12_1/val_F.xls',header=None)\n",
    "df12_f2 = pd.read_excel('./single_model_dataset/df12_2/val_F.xls',header=None)\n",
    "df12_f3 = pd.read_excel('./single_model_dataset/df12_3/val_F.xls',header=None)\n",
    "df12_f4 = pd.read_excel('./single_model_dataset/df12_4/val_F.xls',header=None)\n",
    "df12_f5 = pd.read_excel('./single_model_dataset/df12_5/val_F.xls',header=None)\n",
    "\n",
    "df13_f1 = pd.read_excel('./single_model_dataset/df13_1/val_F.xls',header=None)\n",
    "df13_f2 = pd.read_excel('./single_model_dataset/df13_2/val_F.xls',header=None)\n",
    "df13_f3 = pd.read_excel('./single_model_dataset/df13_3/val_F.xls',header=None)\n",
    "df13_f4 = pd.read_excel('./single_model_dataset/df13_4/val_F.xls',header=None)\n",
    "df13_f5 = pd.read_excel('./single_model_dataset/df13_5/val_F.xls',header=None)\n",
    "\n",
    "df14_f1 = pd.read_excel('./single_model_dataset/df14_1/val_F.xls',header=None)\n",
    "df14_f2 = pd.read_excel('./single_model_dataset/df14_2/val_F.xls',header=None)\n",
    "df14_f3 = pd.read_excel('./single_model_dataset/df14_3/val_F.xls',header=None)\n",
    "df14_f4 = pd.read_excel('./single_model_dataset/df14_4/val_F.xls',header=None)\n",
    "df14_f5 = pd.read_excel('./single_model_dataset/df14_5/val_F.xls',header=None)\n",
    "\n",
    "df15_f1 = pd.read_excel('./single_model_dataset/df15_1/val_F.xls',header=None)\n",
    "df15_f2 = pd.read_excel('./single_model_dataset/df15_2/val_F.xls',header=None)\n",
    "df15_f3 = pd.read_excel('./single_model_dataset/df15_3/val_F.xls',header=None)\n",
    "df15_f4 = pd.read_excel('./single_model_dataset/df15_4/val_F.xls',header=None)\n",
    "df15_f5 = pd.read_excel('./single_model_dataset/df15_5/val_F.xls',header=None)\n",
    "\n",
    "df16_f1 = pd.read_excel('./single_model_dataset/df16_1/val_F.xls',header=None)\n",
    "df16_f2 = pd.read_excel('./single_model_dataset/df16_2/val_F.xls',header=None)\n",
    "df16_f3 = pd.read_excel('./single_model_dataset/df16_3/val_F.xls',header=None)\n",
    "\n",
    "df17_f = pd.read_excel('./single_model_dataset/df17/val_F.xls',header=None)\n",
    "df18_f = pd.read_excel('./single_model_dataset/df18/val_F.xls',header=None)\n",
    "df19_f = pd.read_excel('./single_model_dataset/df19/val_F.xls',header=None)\n",
    "df20_f = pd.read_excel('./single_model_dataset/df20/val_F.xls',header=None)\n",
    "df21_f = pd.read_excel('./single_model_dataset/df21/val_F.xls',header=None)\n",
    "df22_f = pd.read_excel('./single_model_dataset/df22/val_F.xls',header=None)\n",
    "df23_f = pd.read_excel('./single_model_dataset/df23/val_F.xls',header=None)\n",
    "df24_f = pd.read_excel('./single_model_dataset/df24/val_F.xls',header=None)\n",
    "\n",
    "df25_f1 = pd.read_excel('./New_dataset_2/df1_1/val_F.xls',header=None)\n",
    "df25_f2 = pd.read_excel('./New_dataset_2/df1_2/val_F.xls',header=None)\n",
    "df25_f3 = pd.read_excel('./New_dataset_2/df1_3/val_F.xls',header=None)\n",
    "df25_f4 = pd.read_excel('./New_dataset_2/df1_4/val_F.xls',header=None)\n",
    "df25_f5 = pd.read_excel('./New_dataset_2/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df26_f1 = pd.read_excel('./New_dataset_2/df2_1/val_F.xls',header=None)\n",
    "df26_f2 = pd.read_excel('./New_dataset_2/df2_2/val_F.xls',header=None)\n",
    "df26_f3 = pd.read_excel('./New_dataset_2/df2_3/val_F.xls',header=None)\n",
    "df26_f4 = pd.read_excel('./New_dataset_2/df2_4/val_F.xls',header=None)\n",
    "df26_f5 = pd.read_excel('./New_dataset_2/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df27_f1 = pd.read_excel('./New_dataset_2/df3_1/val_F.xls',header=None)\n",
    "df27_f2 = pd.read_excel('./New_dataset_2/df3_2/val_F.xls',header=None)\n",
    "df27_f3 = pd.read_excel('./New_dataset_2/df3_3/val_F.xls',header=None)\n",
    "df27_f4 = pd.read_excel('./New_dataset_2/df3_4/val_F.xls',header=None)\n",
    "\n",
    "df28_f1 = pd.read_excel('./New_dataset_2/df3_1/val_F.xls',header=None)\n",
    "df28_f2 = pd.read_excel('./New_dataset_2/df3_2/val_F.xls',header=None)\n",
    "df28_f3 = pd.read_excel('./New_dataset_2/df3_3/val_F.xls',header=None)\n",
    "df28_f4 = pd.read_excel('./New_dataset_2/df3_4/val_F.xls',header=None)\n",
    "#df28_f5 = pd.read_excel('./New_dataset_2/df3_5/val_F.xls',header=None)\n",
    "\n",
    "df29_f1 = pd.read_excel('./New_dataset_2/df4_1/val_F.xls',header=None)\n",
    "df29_f2 = pd.read_excel('./New_dataset_2/df4_2/val_F.xls',header=None)\n",
    "df29_f3 = pd.read_excel('./New_dataset_2/df4_3/val_F.xls',header=None)\n",
    "df29_f4 = pd.read_excel('./New_dataset_2/df4_4/val_F.xls',header=None)\n",
    "df29_f5 = pd.read_excel('./New_dataset_2/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df30_f1 = pd.read_excel('./New_dataset_2/df5_1/val_F.xls',header=None)\n",
    "df30_f2 = pd.read_excel('./New_dataset_2/df5_2/val_F.xls',header=None)\n",
    "df30_f3 = pd.read_excel('./New_dataset_2/df5_3/val_F.xls',header=None)\n",
    "df30_f4 = pd.read_excel('./New_dataset_2/df5_4/val_F.xls',header=None)\n",
    "df30_f5 = pd.read_excel('./New_dataset_2/df5_5/val_F.xls',header=None)\n",
    "\n",
    "df31_f1 = pd.read_excel('./New_dataset_2/df6_1/val_F.xls',header=None)\n",
    "df31_f2 = pd.read_excel('./New_dataset_2/df6_2/val_F.xls',header=None)\n",
    "df31_f3 = pd.read_excel('./New_dataset_2/df6_3/val_F.xls',header=None)\n",
    "df31_f4 = pd.read_excel('./New_dataset_2/df6_4/val_F.xls',header=None)\n",
    "df31_f5 = pd.read_excel('./New_dataset_2/df6_5/val_F.xls',header=None)\n",
    "\n",
    "df32_f1 = pd.read_excel('./New_Data_2/df1_1/val_F.xls',header=None)\n",
    "df32_f2 = pd.read_excel('./New_Data_2/df1_2/val_F.xls',header=None)\n",
    "df32_f3 = pd.read_excel('./New_Data_2/df1_3/val_F.xls',header=None)\n",
    "df32_f4 = pd.read_excel('./New_Data_2/df1_4/val_F.xls',header=None)\n",
    "df32_f5 = pd.read_excel('./New_Data_2/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df33_f1 = pd.read_excel('./New_Data_2/df2_1/val_F.xls',header=None)\n",
    "df33_f2 = pd.read_excel('./New_Data_2/df2_2/val_F.xls',header=None)\n",
    "df33_f3 = pd.read_excel('./New_Data_2/df2_3/val_F.xls',header=None)\n",
    "df33_f4 = pd.read_excel('./New_Data_2/df2_4/val_F.xls',header=None)\n",
    "df33_f5 = pd.read_excel('./New_Data_2/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df34_f1 = pd.read_excel('./New_Data_2/df3_1/val_F.xls',header=None)\n",
    "df34_f2 = pd.read_excel('./New_Data_2/df3_2/val_F.xls',header=None)\n",
    "df34_f3 = pd.read_excel('./New_Data_2/df3_3/val_F.xls',header=None)\n",
    "df34_f4 = pd.read_excel('./New_Data_2/df3_4/val_F.xls',header=None)\n",
    "\n",
    "df35_f1 = pd.read_excel('./New_Data_2/df4_1/val_F.xls',header=None)\n",
    "df35_f2 = pd.read_excel('./New_Data_2/df4_2/val_F.xls',header=None)\n",
    "df35_f3 = pd.read_excel('./New_Data_2/df4_3/val_F.xls',header=None)\n",
    "df35_f4 = pd.read_excel('./New_Data_2/df4_4/val_F.xls',header=None)\n",
    "df35_f5 = pd.read_excel('./New_Data_2/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df36_f1 = pd.read_excel('./New_Data_2/df5_1/val_F.xls',header=None)\n",
    "df36_f2 = pd.read_excel('./New_Data_2/df5_2/val_F.xls',header=None)\n",
    "df36_f3 = pd.read_excel('./New_Data_2/df5_3/val_F.xls',header=None)\n",
    "df36_f4 = pd.read_excel('./New_Data_2/df5_4/val_F.xls',header=None)\n",
    "\n",
    "df37_f1 = pd.read_excel('./New_Data_2/df6_1/val_F.xls',header=None)\n",
    "df37_f2 = pd.read_excel('./New_Data_2/df6_2/val_F.xls',header=None)\n",
    "df37_f3 = pd.read_excel('./New_Data_2/df6_3/val_F.xls',header=None)\n",
    "df37_f4 = pd.read_excel('./New_Data_2/df6_4/val_F.xls',header=None)\n",
    "\n",
    "df38_f1 = pd.read_excel('./New_Data_2/df7_1/val_F.xls',header=None)\n",
    "df38_f2 = pd.read_excel('./New_Data_2/df7_2/val_F.xls',header=None)\n",
    "df38_f3 = pd.read_excel('./New_Data_2/df7_3/val_F.xls',header=None)\n",
    "df38_f4 = pd.read_excel('./New_Data_2/df7_4/val_F.xls',header=None)\n",
    "df38_f5 = pd.read_excel('./New_Data_2/df7_5/val_F.xls',header=None)\n",
    "\n",
    "df39_f1 = pd.read_excel('./New_Data_2/df8_1/val_F.xls',header=None)\n",
    "df39_f2 = pd.read_excel('./New_Data_2/df8_2/val_F.xls',header=None)\n",
    "df39_f3 = pd.read_excel('./New_Data_2/df8_3/val_F.xls',header=None)\n",
    "\n",
    "df40_f = pd.read_excel('./mlme_data_set/Dataset/df1/val_F.xls',header=None)\n",
    "df41_f = pd.read_excel('./mlme_data_set/Dataset/df2/val_F.xls',header=None)\n",
    "df42_f = pd.read_excel('./mlme_data_set/Dataset/df3/val_F.xls',header=None)\n",
    "df43_f = pd.read_excel('./mlme_data_set/Dataset/df4/val_F.xls',header=None)\n",
    "df44_f = pd.read_excel('./mlme_data_set/Dataset/df5/val_F.xls',header=None)\n",
    "df45_f = pd.read_excel('./mlme_data_set/Dataset/df6/val_F.xls',header=None)\n",
    "df46_f = pd.read_excel('./mlme_data_set/Dataset/df7/val_F.xls',header=None)\n",
    "df47_f = pd.read_excel('./mlme_data_set/Dataset/df8/val_F.xls',header=None)\n",
    "df48_f = pd.read_excel('./mlme_data_set/Dataset/df9/val_F.xls',header=None)\n",
    "df49_f = pd.read_excel('./mlme_data_set/Dataset/df10/val_F.xls',header=None)\n",
    "df50_f = pd.read_excel('./mlme_data_set/Dataset/df11/val_F.xls',header=None)\n",
    "df51_f = pd.read_excel('./mlme_data_set/Dataset/df12/val_F.xls',header=None)\n",
    "df52_f = pd.read_excel('./mlme_data_set/Dataset/df13/val_F.xls',header=None)\n",
    "df53_f = pd.read_excel('./mlme_data_set/Dataset/df14/val_F.xls',header=None)\n",
    "df54_f = pd.read_excel('./mlme_data_set/Dataset/df15/val_F.xls',header=None)\n",
    "df55_f = pd.read_excel('./mlme_data_set/Dataset/df16/val_F.xls',header=None)\n",
    "df56_f = pd.read_excel('./mlme_data_set/Dataset/df17/val_F.xls',header=None)\n",
    "df57_f = pd.read_excel('./mlme_data_set/Dataset/df18/val_F.xls',header=None)\n",
    "df58_f = pd.read_excel('./mlme_data_set/Dataset/df19/val_F.xls',header=None)\n",
    "df59_f = pd.read_excel('./mlme_data_set/Dataset/df20/val_F.xls',header=None)\n",
    "df60_f = pd.read_excel('./mlme_data_set/Dataset/df21/val_F.xls',header=None)\n",
    "df61_f = pd.read_excel('./mlme_data_set/Dataset/df22/val_F.xls',header=None)\n",
    "\n",
    "df62_f1 = pd.read_excel('./mlme_data_set/Dataset/df3_1/val_F.xls',header=None)\n",
    "df62_f2 = pd.read_excel('./mlme_data_set/Dataset/df3_2/val_F.xls',header=None)\n",
    "df62_f3 = pd.read_excel('./mlme_data_set/Dataset/df3_3/val_F.xls',header=None)\n",
    "df62_f4 = pd.read_excel('./mlme_data_set/Dataset/df3_4/val_F.xls',header=None)\n",
    "df62_f5 = pd.read_excel('./mlme_data_set/Dataset/df3_5/val_F.xls',header=None)\n",
    "df62_f6 = pd.read_excel('./mlme_data_set/Dataset/df3_6/val_F.xls',header=None)\n",
    "df62_f7 = pd.read_excel('./mlme_data_set/Dataset/df3_7/val_F.xls',header=None)\n",
    "df62_f8 = pd.read_excel('./mlme_data_set/Dataset/df3_8/val_F.xls',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for two models\n",
    "#model 1\n",
    "df1_f1 = pd.read_excel('./single_model_dataset/df1_1/val_F.xls',header=None)\n",
    "df1_f2 = pd.read_excel('./single_model_dataset/df1_2/val_F.xls',header=None)\n",
    "df1_f3 = pd.read_excel('./single_model_dataset/df1_3/val_F.xls',header=None)\n",
    "df1_f4 = pd.read_excel('./single_model_dataset/df1_4/val_F.xls',header=None)\n",
    "df1_f5 = pd.read_excel('./single_model_dataset/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df2_f1 = pd.read_excel('./single_model_dataset/df2_1/val_F.xls',header=None)\n",
    "df2_f2 = pd.read_excel('./single_model_dataset/df2_2/val_F.xls',header=None)\n",
    "df2_f3 = pd.read_excel('./single_model_dataset/df2_3/val_F.xls',header=None)\n",
    "df2_f4 = pd.read_excel('./single_model_dataset/df2_4/val_F.xls',header=None)\n",
    "df2_f5 = pd.read_excel('./single_model_dataset/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df3_f1 = pd.read_excel('./single_model_dataset/df3_1/val_F.xls',header=None)\n",
    "df3_f2 = pd.read_excel('./single_model_dataset/df3_2/val_F.xls',header=None)\n",
    "df3_f3 = pd.read_excel('./single_model_dataset/df3_3/val_F.xls',header=None)\n",
    "df3_f4 = pd.read_excel('./single_model_dataset/df3_4/val_F.xls',header=None)\n",
    "df3_f5 = pd.read_excel('./single_model_dataset/df3_5/val_F.xls',header=None)\n",
    "\n",
    "df4_f1 = pd.read_excel('./single_model_dataset/df4_1/val_F.xls',header=None)\n",
    "df4_f2 = pd.read_excel('./single_model_dataset/df4_2/val_F.xls',header=None)\n",
    "df4_f3 = pd.read_excel('./single_model_dataset/df4_3/val_F.xls',header=None)\n",
    "df4_f4 = pd.read_excel('./single_model_dataset/df4_4/val_F.xls',header=None)\n",
    "df4_f5 = pd.read_excel('./single_model_dataset/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df5_f1 = pd.read_excel('./single_model_dataset/df5_1/val_F.xls',header=None)\n",
    "df5_f2 = pd.read_excel('./single_model_dataset/df5_2/val_F.xls',header=None)\n",
    "df5_f3 = pd.read_excel('./single_model_dataset/df5_3/val_F.xls',header=None)\n",
    "df5_f4 = pd.read_excel('./single_model_dataset/df5_4/val_F.xls',header=None)\n",
    "df5_f5 = pd.read_excel('./single_model_dataset/df5_5/val_F.xls',header=None)\n",
    "\n",
    "df6_f1 = pd.read_excel('./single_model_dataset/df6_1/val_F.xls',header=None)\n",
    "df6_f2 = pd.read_excel('./single_model_dataset/df6_2/val_F.xls',header=None)\n",
    "df6_f3 = pd.read_excel('./single_model_dataset/df6_3/val_F.xls',header=None)\n",
    "df6_f4 = pd.read_excel('./single_model_dataset/df6_4/val_F.xls',header=None)\n",
    "df6_f5 = pd.read_excel('./single_model_dataset/df6_5/val_F.xls',header=None)\n",
    "\n",
    "df7_f1 = pd.read_excel('./single_model_dataset/df11_1/val_F.xls',header=None)\n",
    "df7_f2 = pd.read_excel('./single_model_dataset/df11_2/val_F.xls',header=None)\n",
    "df7_f3 = pd.read_excel('./single_model_dataset/df11_3/val_F.xls',header=None)\n",
    "df7_f4 = pd.read_excel('./single_model_dataset/df11_4/val_F.xls',header=None)\n",
    "df7_f5 = pd.read_excel('./single_model_dataset/df11_5/val_F.xls',header=None)\n",
    "\n",
    "df8_f1 = pd.read_excel('./single_model_dataset/df12_1/val_F.xls',header=None)\n",
    "df8_f2 = pd.read_excel('./single_model_dataset/df12_2/val_F.xls',header=None)\n",
    "df8_f3 = pd.read_excel('./single_model_dataset/df12_3/val_F.xls',header=None)\n",
    "df8_f4 = pd.read_excel('./single_model_dataset/df12_4/val_F.xls',header=None)\n",
    "df8_f5 = pd.read_excel('./single_model_dataset/df12_5/val_F.xls',header=None)\n",
    "\n",
    "df9_f1 = pd.read_excel('./single_model_dataset/df13_1/val_F.xls',header=None)\n",
    "df9_f2 = pd.read_excel('./single_model_dataset/df13_2/val_F.xls',header=None)\n",
    "df9_f3 = pd.read_excel('./single_model_dataset/df13_3/val_F.xls',header=None)\n",
    "df9_f4 = pd.read_excel('./single_model_dataset/df13_4/val_F.xls',header=None)\n",
    "df9_f5 = pd.read_excel('./single_model_dataset/df13_5/val_F.xls',header=None)\n",
    "\n",
    "df10_f1 = pd.read_excel('./single_model_dataset/df14_1/val_F.xls',header=None)\n",
    "df10_f2 = pd.read_excel('./single_model_dataset/df14_2/val_F.xls',header=None)\n",
    "df10_f3 = pd.read_excel('./single_model_dataset/df14_3/val_F.xls',header=None)\n",
    "df10_f4 = pd.read_excel('./single_model_dataset/df14_4/val_F.xls',header=None)\n",
    "df10_f5 = pd.read_excel('./single_model_dataset/df14_5/val_F.xls',header=None)\n",
    "\n",
    "df11_f1 = pd.read_excel('./single_model_dataset/df15_1/val_F.xls',header=None)\n",
    "df11_f2 = pd.read_excel('./single_model_dataset/df15_2/val_F.xls',header=None)\n",
    "df11_f3 = pd.read_excel('./single_model_dataset/df15_3/val_F.xls',header=None)\n",
    "df11_f4 = pd.read_excel('./single_model_dataset/df15_4/val_F.xls',header=None)\n",
    "df11_f5 = pd.read_excel('./single_model_dataset/df15_5/val_F.xls',header=None)\n",
    "\n",
    "df12_f1 = pd.read_excel('./New_Data_2/df1_1/val_F.xls',header=None)\n",
    "df12_f2 = pd.read_excel('./New_Data_2/df1_2/val_F.xls',header=None)\n",
    "df12_f3 = pd.read_excel('./New_Data_2/df1_3/val_F.xls',header=None)\n",
    "df12_f4 = pd.read_excel('./New_Data_2/df1_4/val_F.xls',header=None)\n",
    "df12_f5 = pd.read_excel('./New_Data_2/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df13_f1 = pd.read_excel('./New_Data_2/df2_1/val_F.xls',header=None)\n",
    "df13_f2 = pd.read_excel('./New_Data_2/df2_2/val_F.xls',header=None)\n",
    "df13_f3 = pd.read_excel('./New_Data_2/df2_3/val_F.xls',header=None)\n",
    "df13_f4 = pd.read_excel('./New_Data_2/df2_4/val_F.xls',header=None)\n",
    "df13_f5 = pd.read_excel('./New_Data_2/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df14_f1 = pd.read_excel('./New_Data_2/df3_1/val_F.xls',header=None)\n",
    "df14_f2 = pd.read_excel('./New_Data_2/df3_2/val_F.xls',header=None)\n",
    "df14_f3 = pd.read_excel('./New_Data_2/df3_3/val_F.xls',header=None)\n",
    "df14_f4 = pd.read_excel('./New_Data_2/df3_4/val_F.xls',header=None)\n",
    "\n",
    "df15_f1 = pd.read_excel('./New_Data_2/df4_1/val_F.xls',header=None)\n",
    "df15_f2 = pd.read_excel('./New_Data_2/df4_2/val_F.xls',header=None)\n",
    "df15_f3 = pd.read_excel('./New_Data_2/df4_3/val_F.xls',header=None)\n",
    "df15_f4 = pd.read_excel('./New_Data_2/df4_4/val_F.xls',header=None)\n",
    "df15_f5 = pd.read_excel('./New_Data_2/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df16_f1 = pd.read_excel('./New_Data_2/df5_1/val_F.xls',header=None)\n",
    "df16_f2 = pd.read_excel('./New_Data_2/df5_2/val_F.xls',header=None)\n",
    "df16_f3 = pd.read_excel('./New_Data_2/df5_3/val_F.xls',header=None)\n",
    "df16_f4 = pd.read_excel('./New_Data_2/df5_4/val_F.xls',header=None)\n",
    "\n",
    "df17_f1 = pd.read_excel('./New_Data_2/df6_1/val_F.xls',header=None)\n",
    "df17_f2 = pd.read_excel('./New_Data_2/df6_2/val_F.xls',header=None)\n",
    "df17_f3 = pd.read_excel('./New_Data_2/df6_3/val_F.xls',header=None)\n",
    "df17_f4 = pd.read_excel('./New_Data_2/df6_4/val_F.xls',header=None)\n",
    "\n",
    "df18_f1 = pd.read_excel('./New_Data_2/df7_1/val_F.xls',header=None)\n",
    "df18_f2 = pd.read_excel('./New_Data_2/df7_2/val_F.xls',header=None)\n",
    "df18_f3 = pd.read_excel('./New_Data_2/df7_3/val_F.xls',header=None)\n",
    "df18_f4 = pd.read_excel('./New_Data_2/df7_4/val_F.xls',header=None)\n",
    "df18_f5 = pd.read_excel('./New_Data_2/df7_5/val_F.xls',header=None)\n",
    "\n",
    "df19_f1 = pd.read_excel('./New_Data_2/df8_1/val_F.xls',header=None)\n",
    "df19_f2 = pd.read_excel('./New_Data_2/df8_2/val_F.xls',header=None)\n",
    "df19_f3 = pd.read_excel('./New_Data_2/df8_3/val_F.xls',header=None)\n",
    "\n",
    "df20_f = pd.read_excel('./mlme_data_set/Dataset/df1/val_F.xls',header=None)\n",
    "df21_f = pd.read_excel('./mlme_data_set/Dataset/df2/val_F.xls',header=None)\n",
    "df22_f = pd.read_excel('./mlme_data_set/Dataset/df3/val_F.xls',header=None)\n",
    "df23_f = pd.read_excel('./mlme_data_set/Dataset/df4/val_F.xls',header=None)\n",
    "df24_f = pd.read_excel('./mlme_data_set/Dataset/df5/val_F.xls',header=None)\n",
    "df25_f = pd.read_excel('./mlme_data_set/Dataset/df6/val_F.xls',header=None)\n",
    "df26_f = pd.read_excel('./mlme_data_set/Dataset/df7/val_F.xls',header=None)\n",
    "df27_f = pd.read_excel('./mlme_data_set/Dataset/df8/val_F.xls',header=None)\n",
    "df28_f = pd.read_excel('./mlme_data_set/Dataset/df9/val_F.xls',header=None)\n",
    "df29_f = pd.read_excel('./mlme_data_set/Dataset/df10/val_F.xls',header=None)\n",
    "df30_f = pd.read_excel('./mlme_data_set/Dataset/df11/val_F.xls',header=None)\n",
    "df31_f = pd.read_excel('./mlme_data_set/Dataset/df12/val_F.xls',header=None)\n",
    "df32_f = pd.read_excel('./mlme_data_set/Dataset/df13/val_F.xls',header=None)\n",
    "df33_f = pd.read_excel('./mlme_data_set/Dataset/df14/val_F.xls',header=None)\n",
    "df34_f = pd.read_excel('./mlme_data_set/Dataset/df15/val_F.xls',header=None)\n",
    "df35_f = pd.read_excel('./mlme_data_set/Dataset/df16/val_F.xls',header=None)\n",
    "df36_f = pd.read_excel('./mlme_data_set/Dataset/df17/val_F.xls',header=None)\n",
    "df37_f = pd.read_excel('./mlme_data_set/Dataset/df18/val_F.xls',header=None)\n",
    "df38_f = pd.read_excel('./mlme_data_set/Dataset/df19/val_F.xls',header=None)\n",
    "df39_f = pd.read_excel('./mlme_data_set/Dataset/df20/val_F.xls',header=None)\n",
    "df40_f = pd.read_excel('./mlme_data_set/Dataset/df21/val_F.xls',header=None)\n",
    "df41_f = pd.read_excel('./mlme_data_set/Dataset/df22/val_F.xls',header=None)\n",
    "\n",
    "df42_f1 = pd.read_excel('./mlme_data_set/Dataset/df3_1/val_F.xls',header=None)\n",
    "df42_f2 = pd.read_excel('./mlme_data_set/Dataset/df3_2/val_F.xls',header=None)\n",
    "df42_f3 = pd.read_excel('./mlme_data_set/Dataset/df3_3/val_F.xls',header=None)\n",
    "df42_f4 = pd.read_excel('./mlme_data_set/Dataset/df3_4/val_F.xls',header=None)\n",
    "df42_f5 = pd.read_excel('./mlme_data_set/Dataset/df3_5/val_F.xls',header=None)\n",
    "df42_f6 = pd.read_excel('./mlme_data_set/Dataset/df3_6/val_F.xls',header=None)\n",
    "df42_f7 = pd.read_excel('./mlme_data_set/Dataset/df3_7/val_F.xls',header=None)\n",
    "df42_f8 = pd.read_excel('./mlme_data_set/Dataset/df3_8/val_F.xls',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1_f1.append(df1_f2).append(df1_f3).append(df1_f4).append(df1_f5).append(df2_f1).append(df2_f2).append(df2_f3).append(df2_f4).append(df2_f5).append(df3_f1).append(df3_f2).append(df3_f3).append(df3_f4).append(df3_f5).append(df4_f1).append(df4_f2).append(df4_f3).append(df4_f4).append(df4_f5).append(df5_f1).append(df5_f2).append(df5_f3).append(df5_f4).append(df5_f5).append(df6_f1).append(df6_f2).append(df6_f3).append(df6_f4).append(df6_f5).append(df7_f1).append(df7_f2).append(df7_f3).append(df7_f4).append(df7_f5).append(df8_f1).append(df8_f2).append(df8_f3).append(df8_f4).append(df8_f5).append(df9_f1).append(df9_f2).append(df9_f3).append(df9_f4).append(df9_f5).append(df10_f1).append(df10_f2).append(df10_f3).append(df10_f4).append(df10_f5).append(df11_f1).append(df11_f2).append(df11_f3).append(df11_f4).append(df11_f5).append(df12_f1).append(df12_f2).append(df12_f3).append(df12_f4).append(df12_f5).append(df13_f1).append(df13_f2).append(df13_f3).append(df13_f4).append(df13_f5).append(df14_f1).append(df14_f2).append(df14_f3).append(df14_f4).append(df15_f1).append(df15_f2).append(df15_f3).append(df15_f4).append(df15_f5).append(df16_f1).append(df16_f2).append(df16_f3).append(df16_f4).append(df17_f1).append(df17_f2).append(df17_f3).append(df17_f4).append(df18_f1).append(df18_f2).append(df18_f3).append(df18_f4).append(df18_f5).append(df19_f1).append(df19_f2).append(df19_f3).append(df20_f).append(df21_f).append(df22_f).append(df23_f).append(df24_f).append(df25_f).append(df26_f).append(df27_f).append(df28_f).append(df29_f).append(df30_f).append(df31_f).append(df32_f).append(df33_f).append(df34_f).append(df35_f).append(df36_f).append(df37_f).append(df38_f).append(df39_f).append(df40_f).append(df41_f).append(df42_f1).append(df42_f2).append(df42_f3).append(df42_f4).append(df42_f5).append(df42_f6).append(df42_f7).append(df42_f8)\n",
    "y_renamed = y.rename(columns={0:\"F\"}).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for two models\n",
    "#model 2\n",
    "df1_f1 = pd.read_excel('./single_model_dataset/df7_1/val_F.xls',header=None)\n",
    "df1_f2 = pd.read_excel('./single_model_dataset/df7_2/val_F.xls',header=None)\n",
    "df1_f3 = pd.read_excel('./single_model_dataset/df7_3/val_F.xls',header=None)\n",
    "df1_f4 = pd.read_excel('./single_model_dataset/df7_4/val_F.xls',header=None)\n",
    "df1_f5 = pd.read_excel('./single_model_dataset/df7_5/val_F.xls',header=None)\n",
    "\n",
    "df2_f1 = pd.read_excel('./single_model_dataset/df8_1/val_F.xls',header=None)\n",
    "df2_f2 = pd.read_excel('./single_model_dataset/df8_2/val_F.xls',header=None)\n",
    "df2_f3 = pd.read_excel('./single_model_dataset/df8_3/val_F.xls',header=None)\n",
    "df2_f4 = pd.read_excel('./single_model_dataset/df8_4/val_F.xls',header=None)\n",
    "df2_f5 = pd.read_excel('./single_model_dataset/df8_5/val_F.xls',header=None)\n",
    "\n",
    "df3_f1 = pd.read_excel('./single_model_dataset/df9_1/val_F.xls',header=None)\n",
    "df3_f2 = pd.read_excel('./single_model_dataset/df9_2/val_F.xls',header=None)\n",
    "df3_f3 = pd.read_excel('./single_model_dataset/df9_3/val_F.xls',header=None)\n",
    "df3_f4 = pd.read_excel('./single_model_dataset/df9_4/val_F.xls',header=None)\n",
    "df3_f5 = pd.read_excel('./single_model_dataset/df9_5/val_F.xls',header=None)\n",
    "\n",
    "df4_f1 = pd.read_excel('./single_model_dataset/df10_1/val_F.xls',header=None)\n",
    "df4_f2 = pd.read_excel('./single_model_dataset/df10_2/val_F.xls',header=None)\n",
    "df4_f3 = pd.read_excel('./single_model_dataset/df10_3/val_F.xls',header=None)\n",
    "df4_f4 = pd.read_excel('./single_model_dataset/df10_4/val_F.xls',header=None)\n",
    "df4_f5 = pd.read_excel('./single_model_dataset/df10_5/val_F.xls',header=None)\n",
    "\n",
    "df5_f1 = pd.read_excel('./New_dataset_2/df1_1/val_F.xls',header=None)\n",
    "df5_f2 = pd.read_excel('./New_dataset_2/df1_2/val_F.xls',header=None)\n",
    "df5_f3 = pd.read_excel('./New_dataset_2/df1_3/val_F.xls',header=None)\n",
    "df5_f4 = pd.read_excel('./New_dataset_2/df1_4/val_F.xls',header=None)\n",
    "df5_f5 = pd.read_excel('./New_dataset_2/df1_5/val_F.xls',header=None)\n",
    "\n",
    "df6_f1 = pd.read_excel('./New_dataset_2/df2_1/val_F.xls',header=None)\n",
    "df6_f2 = pd.read_excel('./New_dataset_2/df2_2/val_F.xls',header=None)\n",
    "df6_f3 = pd.read_excel('./New_dataset_2/df2_3/val_F.xls',header=None)\n",
    "df6_f4 = pd.read_excel('./New_dataset_2/df2_4/val_F.xls',header=None)\n",
    "df6_f5 = pd.read_excel('./New_dataset_2/df2_5/val_F.xls',header=None)\n",
    "\n",
    "df7_f1 = pd.read_excel('./New_dataset_2/df3_1/val_F.xls',header=None)\n",
    "df7_f2 = pd.read_excel('./New_dataset_2/df3_2/val_F.xls',header=None)\n",
    "df7_f3 = pd.read_excel('./New_dataset_2/df3_3/val_F.xls',header=None)\n",
    "df7_f4 = pd.read_excel('./New_dataset_2/df3_4/val_F.xls',header=None)\n",
    "\n",
    "df8_f1 = pd.read_excel('./New_dataset_2/df3_1/val_F.xls',header=None)\n",
    "df8_f2 = pd.read_excel('./New_dataset_2/df3_2/val_F.xls',header=None)\n",
    "df8_f3 = pd.read_excel('./New_dataset_2/df3_3/val_F.xls',header=None)\n",
    "df8_f4 = pd.read_excel('./New_dataset_2/df3_4/val_F.xls',header=None)\n",
    "#df28_f5 = pd.read_excel('./New_dataset_2/df3_5/val_F.xls',header=None)\n",
    "\n",
    "df9_f1 = pd.read_excel('./New_dataset_2/df4_1/val_F.xls',header=None)\n",
    "df9_f2 = pd.read_excel('./New_dataset_2/df4_2/val_F.xls',header=None)\n",
    "df9_f3 = pd.read_excel('./New_dataset_2/df4_3/val_F.xls',header=None)\n",
    "df9_f4 = pd.read_excel('./New_dataset_2/df4_4/val_F.xls',header=None)\n",
    "df9_f5 = pd.read_excel('./New_dataset_2/df4_5/val_F.xls',header=None)\n",
    "\n",
    "df10_f1 = pd.read_excel('./New_dataset_2/df5_1/val_F.xls',header=None)\n",
    "df10_f2 = pd.read_excel('./New_dataset_2/df5_2/val_F.xls',header=None)\n",
    "df10_f3 = pd.read_excel('./New_dataset_2/df5_3/val_F.xls',header=None)\n",
    "df10_f4 = pd.read_excel('./New_dataset_2/df5_4/val_F.xls',header=None)\n",
    "df10_f5 = pd.read_excel('./New_dataset_2/df5_5/val_F.xls',header=None)\n",
    "\n",
    "df11_f1 = pd.read_excel('./New_dataset_2/df6_1/val_F.xls',header=None)\n",
    "df11_f2 = pd.read_excel('./New_dataset_2/df6_2/val_F.xls',header=None)\n",
    "df11_f3 = pd.read_excel('./New_dataset_2/df6_3/val_F.xls',header=None)\n",
    "df11_f4 = pd.read_excel('./New_dataset_2/df6_4/val_F.xls',header=None)\n",
    "df11_f5 = pd.read_excel('./New_dataset_2/df6_5/val_F.xls',header=None)\n",
    "\n",
    "df12_f1 = pd.read_excel('./single_model_dataset/df16_1/val_F.xls',header=None)\n",
    "df12_f2 = pd.read_excel('./single_model_dataset/df16_2/val_F.xls',header=None)\n",
    "df12_f3 = pd.read_excel('./single_model_dataset/df16_3/val_F.xls',header=None)\n",
    "\n",
    "df13_f = pd.read_excel('./single_model_dataset/df17/val_F.xls',header=None)\n",
    "df14_f = pd.read_excel('./single_model_dataset/df18/val_F.xls',header=None)\n",
    "df15_f = pd.read_excel('./single_model_dataset/df19/val_F.xls',header=None)\n",
    "df16_f = pd.read_excel('./single_model_dataset/df20/val_F.xls',header=None)\n",
    "df17_f = pd.read_excel('./single_model_dataset/df21/val_F.xls',header=None)\n",
    "df18_f = pd.read_excel('./single_model_dataset/df22/val_F.xls',header=None)\n",
    "df19_f = pd.read_excel('./single_model_dataset/df23/val_F.xls',header=None)\n",
    "df20_f = pd.read_excel('./single_model_dataset/df24/val_F.xls',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df1_f1.append(df1_f2).append(df1_f3).append(df1_f4).append(df1_f5).append(df2_f1).append(df2_f2).append(df2_f3).append(df2_f4).append(df2_f5).append(df3_f1).append(df3_f2).append(df3_f3).append(df3_f4).append(df3_f5).append(df4_f1).append(df4_f2).append(df4_f3).append(df4_f4).append(df4_f5).append(df5_f1).append(df5_f2).append(df5_f3).append(df5_f4).append(df5_f5).append(df6_f1).append(df6_f2).append(df6_f3).append(df6_f4).append(df6_f5).append(df7_f1).append(df7_f2).append(df7_f3).append(df7_f4).append(df8_f1).append(df8_f2).append(df8_f3).append(df8_f4).append(df9_f1).append(df9_f2).append(df9_f3).append(df9_f4).append(df9_f5).append(df10_f1).append(df10_f2).append(df10_f3).append(df10_f4).append(df10_f5).append(df11_f1).append(df11_f2).append(df11_f3).append(df11_f4).append(df11_f5).append(df12_f1).append(df12_f2).append(df12_f3).append(df13_f).append(df14_f).append(df15_f).append(df16_f).append(df17_f).append(df18_f).append(df19_f).append(df20_f)\n",
    "y_renamed = y.rename(columns={0:\"F\"}).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to single data frame\n",
    "x = df1_x1.append(df1_x2).append(df1_x3).append(df1_x4).append(df1_x5).append(df2_x1).append(df2_x2).append(df2_x3).append(df2_x4).append(df2_x5).append(df3_x1).append(df3_x2).append(df3_x3).append(df3_x4).append(df3_x5).append(df4_x1).append(df4_x2).append(df4_x3).append(df4_x4).append(df4_x5).append(df5_x1).append(df5_x2).append(df5_x3).append(df5_x4).append(df5_x5).append(df6_x1).append(df6_x2).append(df6_x3).append(df6_x4).append(df6_x5).append(df7_x1).append(df7_x2).append(df7_x3).append(df7_x4).append(df7_x5).append(df8_x1).append(df8_x2).append(df8_x3).append(df8_x4).append(df8_x5).append(df9_x1).append(df9_x2).append(df9_x3).append(df9_x4).append(df9_x5).append(df10_x1).append(df10_x2).append(df10_x3).append(df10_x4).append(df10_x5).append(df11_x1).append(df11_x2).append(df11_x3).append(df11_x4).append(df11_x5).append(df12_x1).append(df12_x2).append(df12_x3).append(df12_x4).append(df12_x5).append(df13_x1).append(df13_x2).append(df13_x3).append(df13_x4).append(df13_x5).append(df14_x1).append(df14_x2).append(df14_x3).append(df14_x4).append(df14_x5).append(df15_x1).append(df15_x2).append(df15_x3).append(df15_x4).append(df15_x5).append(df16_x1).append(df16_x2).append(df16_x3).append(df17_x).append(df18_x).append(df19_x).append(df20_x).append(df21_x).append(df22_x).append(df23_x).append(df24_x).append(df25_x1).append(df25_x2).append(df25_x3).append(df25_x4).append(df25_x5).append(df26_x1).append(df26_x2).append(df26_x3).append(df26_x4).append(df26_x5).append(df27_x1).append(df27_x2).append(df27_x3).append(df27_x4).append(df28_x1).append(df28_x2).append(df28_x3).append(df28_x4).append(df29_x1).append(df29_x2).append(df29_x3).append(df29_x4).append(df29_x5).append(df30_x1).append(df30_x2).append(df30_x3).append(df30_x4).append(df30_x5).append(df31_x1).append(df31_x2).append(df31_x3).append(df31_x4).append(df31_x5).append(df32_x1).append(df32_x2).append(df32_x3).append(df32_x4).append(df32_x5).append(df33_x1).append(df33_x2).append(df33_x3).append(df33_x4).append(df33_x5).append(df34_x1).append(df34_x2).append(df34_x3).append(df34_x4).append(df35_x1).append(df35_x2).append(df35_x3).append(df35_x4).append(df35_x5).append(df36_x1).append(df36_x2).append(df36_x3).append(df36_x4).append(df37_x1).append(df37_x2).append(df37_x3).append(df37_x4).append(df38_x1).append(df38_x2).append(df38_x3).append(df38_x4).append(df38_x5).append(df39_x1).append(df39_x2).append(df39_x3).append(df40_x).append(df41_x).append(df42_x).append(df43_x).append(df44_x).append(df45_x).append(df46_x).append(df47_x).append(df48_x).append(df49_x).append(df50_x).append(df51_x).append(df52_x).append(df53_x).append(df54_x).append(df55_x).append(df56_x).append(df57_x).append(df58_x).append(df59_x).append(df60_x).append(df61_x).append(df62_x1).append(df62_x2).append(df62_x3).append(df62_x4).append(df62_x5).append(df62_x6).append(df62_x7).append(df62_x8)\n",
    "\n",
    "y = df1_f1.append(df1_f2).append(df1_f3).append(df1_f4).append(df1_f5).append(df2_f1).append(df2_f2).append(df2_f3).append(df2_f4).append(df2_f5).append(df3_f1).append(df3_f2).append(df3_f3).append(df3_f4).append(df3_f5).append(df4_f1).append(df4_f2).append(df4_f3).append(df4_f4).append(df4_f5).append(df5_f1).append(df5_f2).append(df5_f3).append(df5_f4).append(df5_f5).append(df6_f1).append(df6_f2).append(df6_f3).append(df6_f4).append(df6_f5).append(df7_f1).append(df7_f2).append(df7_f3).append(df7_f4).append(df7_f5).append(df8_f1).append(df8_f2).append(df8_f3).append(df8_f4).append(df8_f5).append(df9_f1).append(df9_f2).append(df9_f3).append(df9_f4).append(df9_f5).append(df10_f1).append(df10_f2).append(df10_f3).append(df10_f4).append(df10_f5).append(df11_f1).append(df11_f2).append(df11_f3).append(df11_f4).append(df11_f5).append(df12_f1).append(df12_f2).append(df12_f3).append(df12_f4).append(df12_f5).append(df13_f1).append(df13_f2).append(df13_f3).append(df13_f4).append(df13_f5).append(df14_f1).append(df14_f2).append(df14_f3).append(df14_f4).append(df14_f5).append(df15_f1).append(df15_f2).append(df15_f3).append(df15_f4).append(df15_f5).append(df16_f1).append(df16_f2).append(df16_f3).append(df17_f).append(df18_f).append(df19_f).append(df20_f).append(df21_f).append(df22_f).append(df23_f).append(df24_f).append(df25_f1).append(df25_f2).append(df25_f3).append(df25_f4).append(df25_f5).append(df26_f1).append(df26_f2).append(df26_f3).append(df26_f4).append(df26_f5).append(df27_f1).append(df27_f2).append(df27_f3).append(df27_f4).append(df28_f1).append(df28_f2).append(df28_f3).append(df28_f4).append(df29_f1).append(df29_f2).append(df29_f3).append(df29_f4).append(df29_f5).append(df30_f1).append(df30_f2).append(df30_f3).append(df30_f4).append(df30_f5).append(df31_f1).append(df31_f2).append(df31_f3).append(df31_f4).append(df31_f5).append(df32_f1).append(df32_f2).append(df32_f3).append(df32_f4).append(df32_f5).append(df33_f1).append(df33_f2).append(df33_f3).append(df33_f4).append(df33_f5).append(df34_f1).append(df34_f2).append(df34_f3).append(df34_f4).append(df35_f1).append(df35_f2).append(df35_f3).append(df35_f4).append(df35_f5).append(df36_f1).append(df36_f2).append(df36_f3).append(df36_f4).append(df37_f1).append(df37_f2).append(df37_f3).append(df37_f4).append(df38_f1).append(df38_f2).append(df38_f3).append(df38_f4).append(df38_f5).append(df39_f1).append(df39_f2).append(df39_f3).append(df40_f).append(df41_f).append(df42_f).append(df43_f).append(df44_f).append(df45_f).append(df46_f).append(df47_f).append(df48_f).append(df49_f).append(df50_f).append(df51_f).append(df52_f).append(df53_f).append(df54_f).append(df55_f).append(df56_f).append(df57_f).append(df58_f).append(df59_f).append(df60_f).append(df61_f).append(df62_f1).append(df62_f2).append(df62_f3).append(df62_f4).append(df62_f5).append(df62_f6).append(df62_f7).append(df62_f8)\n",
    "#renaming column names\n",
    "x_renamed = x.rename(columns={0:\"x\",1:\"theta1\",2:\"theta2\",3:\"v\",4:\"dtheta1\",5:\"dtheta2\"})\n",
    "y_renamed = y.rename(columns={0:\"F\"}).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining into single data frame\n",
    "x_renamed['F'] = y_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "data_filtered = x_renamed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_filtered, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['x', 'theta1', 'theta2', 'v', 'dtheta1', 'dtheta2']]\n",
    "y_train = train[['F']] \n",
    "\n",
    "x_test = test[['x', 'theta1', 'theta2', 'v', 'dtheta1', 'dtheta2']]\n",
    "y_test = test[['F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(99) # Seeding to get reproducable results\n",
    "\n",
    "# Variant 2: For the sake of completeness \n",
    "# this is an alternative way to write the sequential model.\n",
    "Imitation_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer(input_shape=(6,), name='input'),\n",
    "        keras.layers.Dense(64, activation='tanh', name='hidden_1'),\n",
    "        keras.layers.Dense(32, activation='tanh', name='hidden_2'),\n",
    "        keras.layers.Dense(64, activation='tanh', name='hidden_3'),\n",
    "        keras.layers.Dense(256, activation='tanh', name='hidden_4'),\n",
    "        keras.layers.Dense(128, activation='tanh', name='hidden_5'),\n",
    "        keras.layers.Dense(64, activation='tanh', name='hidden_6'),\n",
    "        keras.layers.Dense(128, activation='tanh', name='hidden_7'),\n",
    "        #keras.layers.Dense(256, activation='tanh', name='hidden_8'),\n",
    "        #keras.layers.Dense(256, activation='tanh', name='hidden_9'),\n",
    "        keras.layers.Dense(1 , name='output'),\n",
    "    ],\n",
    "    name='simple_model'\n",
    ")\n",
    "#activation='linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 64)                448       \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "hidden_3 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "hidden_4 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "hidden_5 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_6 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_7 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 70,881\n",
      "Trainable params: 70,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Imitation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scalers\n",
    "input_scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "output_scaler = preprocessing.StandardScaler().fit(y_train)\n",
    "\n",
    "input_scaled = input_scaler.transform(x_train)\n",
    "output_scaled = output_scaler.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imitation_model.compile(\n",
    "    # Optimization algorithm\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.MSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callback = [tf.keras.callbacks.ModelCheckpoint('./best_model.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "157/157 [==============================] - 2s 6ms/step - loss: 1.2376 - val_loss: 3.1225\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.12246, saving model to .\\best_model.h5\n",
      "Epoch 2/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0200 - val_loss: 3.3308\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.12246\n",
      "Epoch 3/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0284 - val_loss: 3.2317\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.12246\n",
      "Epoch 4/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0266 - val_loss: 3.1731\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.12246\n",
      "Epoch 5/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0838 - val_loss: 3.1575\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.12246\n",
      "Epoch 6/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0504 - val_loss: 3.2283\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.12246\n",
      "Epoch 7/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0301 - val_loss: 3.2945\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.12246\n",
      "Epoch 8/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0444 - val_loss: 3.1794\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.12246\n",
      "Epoch 9/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0244 - val_loss: 3.7648\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.12246\n",
      "Epoch 10/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0375 - val_loss: 3.1644\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.12246\n",
      "Epoch 11/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0407 - val_loss: 3.1941\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.12246\n",
      "Epoch 12/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0232 - val_loss: 3.1639\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.12246\n",
      "Epoch 13/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0335 - val_loss: 3.1855\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.12246\n",
      "Epoch 14/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0480 - val_loss: 3.1645\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.12246\n",
      "Epoch 15/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0288 - val_loss: 3.2229\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.12246\n",
      "Epoch 16/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0451 - val_loss: 3.2103\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.12246\n",
      "Epoch 17/2000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.0606 - val_loss: 3.2151\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.12246\n",
      "Epoch 18/2000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.0596 - val_loss: 3.3558\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.12246\n",
      "Epoch 19/2000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.0567 - val_loss: 3.1947\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.12246\n",
      "Epoch 20/2000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.1110 - val_loss: 3.3285\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.12246\n",
      "Epoch 21/2000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.0610 - val_loss: 3.1889\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.12246\n",
      "Epoch 22/2000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.0674 - val_loss: 3.2890\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.12246\n",
      "Epoch 23/2000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.0670 - val_loss: 3.2345\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.12246\n",
      "Epoch 24/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 3.2393\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.12246\n",
      "Epoch 25/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0580 - val_loss: 3.2084\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.12246\n",
      "Epoch 26/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0248 - val_loss: 3.4018\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.12246\n",
      "Epoch 27/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1072 - val_loss: 3.2530\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.12246\n",
      "Epoch 28/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0477 - val_loss: 3.2042\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.12246\n",
      "Epoch 29/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0426 - val_loss: 3.2541\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.12246\n",
      "Epoch 30/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0503 - val_loss: 3.1770\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.12246\n",
      "Epoch 31/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0594 - val_loss: 3.1981\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.12246\n",
      "Epoch 32/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0738 - val_loss: 3.2484\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.12246\n",
      "Epoch 33/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0343 - val_loss: 3.1966\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.12246\n",
      "Epoch 34/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0449 - val_loss: 3.2172\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.12246\n",
      "Epoch 35/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0767 - val_loss: 4.0472\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.12246\n",
      "Epoch 36/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0659 - val_loss: 3.3269\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.12246\n",
      "Epoch 37/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0611 - val_loss: 3.2670\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.12246\n",
      "Epoch 38/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0569 - val_loss: 3.4662\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.12246\n",
      "Epoch 39/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0468 - val_loss: 3.1772\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.12246\n",
      "Epoch 40/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1224 - val_loss: 3.2541\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.12246\n",
      "Epoch 41/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1034 - val_loss: 3.2103\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.12246\n",
      "Epoch 42/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0847 - val_loss: 3.2862\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.12246\n",
      "Epoch 43/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0787 - val_loss: 3.4391\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.12246\n",
      "Epoch 44/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0425 - val_loss: 3.2882\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.12246\n",
      "Epoch 45/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0721 - val_loss: 3.1757\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.12246\n",
      "Epoch 46/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0415 - val_loss: 3.2109\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.12246\n",
      "Epoch 47/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0315 - val_loss: 3.7840\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.12246\n",
      "Epoch 48/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1103 - val_loss: 3.1909\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.12246\n",
      "Epoch 49/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0160 - val_loss: 3.1859\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.12246\n",
      "Epoch 50/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0224 - val_loss: 3.1847\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.12246\n",
      "Epoch 51/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0457 - val_loss: 3.2667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.12246\n",
      "Epoch 52/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0931 - val_loss: 3.3531\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.12246\n",
      "Epoch 53/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0302 - val_loss: 3.1846\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.12246\n",
      "Epoch 54/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0386 - val_loss: 3.3728\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.12246\n",
      "Epoch 55/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0970 - val_loss: 3.2463\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.12246\n",
      "Epoch 56/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0747 - val_loss: 3.1861\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.12246\n",
      "Epoch 57/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0486 - val_loss: 3.3268\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.12246\n",
      "Epoch 58/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0584 - val_loss: 3.2327\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.12246\n",
      "Epoch 59/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0526 - val_loss: 3.1886\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.12246\n",
      "Epoch 60/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0623 - val_loss: 3.1827\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.12246\n",
      "Epoch 61/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0533 - val_loss: 3.2019\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.12246\n",
      "Epoch 62/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0284 - val_loss: 3.3671\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.12246\n",
      "Epoch 63/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0391 - val_loss: 3.5664\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.12246\n",
      "Epoch 64/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0687 - val_loss: 3.1840\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.12246\n",
      "Epoch 65/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0930 - val_loss: 3.3665\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.12246\n",
      "Epoch 66/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0647 - val_loss: 3.1898\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.12246\n",
      "Epoch 67/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0531 - val_loss: 3.3695\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.12246\n",
      "Epoch 68/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0472 - val_loss: 3.1859\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.12246\n",
      "Epoch 69/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0481 - val_loss: 3.1782\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.12246\n",
      "Epoch 70/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0818 - val_loss: 3.2862\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.12246\n",
      "Epoch 71/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0357 - val_loss: 3.1833\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.12246\n",
      "Epoch 72/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0493 - val_loss: 3.2847\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.12246\n",
      "Epoch 73/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0380 - val_loss: 3.3125\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.12246\n",
      "Epoch 74/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0661 - val_loss: 3.1846\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.12246\n",
      "Epoch 75/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0375 - val_loss: 3.4832\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.12246\n",
      "Epoch 76/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0998 - val_loss: 3.3838\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.12246\n",
      "Epoch 77/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0716 - val_loss: 3.3059\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.12246\n",
      "Epoch 78/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0312 - val_loss: 3.3252\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.12246\n",
      "Epoch 79/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0509 - val_loss: 3.1856\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.12246\n",
      "Epoch 80/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0711 - val_loss: 3.1805\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.12246\n",
      "Epoch 81/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0772 - val_loss: 3.4430\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.12246\n",
      "Epoch 82/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0310 - val_loss: 3.2076\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.12246\n",
      "Epoch 83/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0202 - val_loss: 3.1895\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.12246\n",
      "Epoch 84/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0705 - val_loss: 3.2262\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.12246\n",
      "Epoch 85/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0623 - val_loss: 3.2110\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.12246\n",
      "Epoch 86/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0594 - val_loss: 3.3909\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.12246\n",
      "Epoch 87/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1011 - val_loss: 3.1804\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.12246\n",
      "Epoch 88/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0772 - val_loss: 3.2855\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.12246\n",
      "Epoch 89/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.1014 - val_loss: 3.1796\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.12246\n",
      "Epoch 90/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0301 - val_loss: 3.1958\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.12246\n",
      "Epoch 91/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0580 - val_loss: 3.1937\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.12246\n",
      "Epoch 92/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0473 - val_loss: 3.1826\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.12246\n",
      "Epoch 93/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0465 - val_loss: 3.1822\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.12246\n",
      "Epoch 94/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0309 - val_loss: 3.2212\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.12246\n",
      "Epoch 95/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0423 - val_loss: 3.5110\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.12246\n",
      "Epoch 96/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0919 - val_loss: 3.1850\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.12246\n",
      "Epoch 97/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0106 - val_loss: 3.1794\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.12246\n",
      "Epoch 98/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0645 - val_loss: 3.2414\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.12246\n",
      "Epoch 99/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0520 - val_loss: 3.3139\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.12246\n",
      "Epoch 100/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0600 - val_loss: 3.4749\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.12246\n",
      "Epoch 101/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0237 - val_loss: 3.4925\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3.12246\n",
      "Epoch 102/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0440 - val_loss: 3.1815\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 3.12246\n",
      "Epoch 103/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0604 - val_loss: 3.2797\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3.12246\n",
      "Epoch 104/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0484 - val_loss: 3.1965\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3.12246\n",
      "Epoch 105/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0541 - val_loss: 3.1748\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3.12246\n",
      "Epoch 106/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0318 - val_loss: 3.3460\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3.12246\n",
      "Epoch 107/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0615 - val_loss: 3.3021\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.12246\n",
      "Epoch 108/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0615 - val_loss: 3.2065\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3.12246\n",
      "Epoch 109/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0411 - val_loss: 3.2366\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.12246\n",
      "Epoch 110/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0878 - val_loss: 3.3394\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3.12246\n",
      "Epoch 111/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0349 - val_loss: 3.2468\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.12246\n",
      "Epoch 112/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0812 - val_loss: 3.2899\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3.12246\n",
      "Epoch 113/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0543 - val_loss: 3.5652\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3.12246\n",
      "Epoch 114/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0896 - val_loss: 3.5083\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.12246\n",
      "Epoch 115/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0331 - val_loss: 3.1872\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.12246\n",
      "Epoch 116/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0692 - val_loss: 3.5793\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3.12246\n",
      "Epoch 117/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0640 - val_loss: 3.1947\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3.12246\n",
      "Epoch 118/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0408 - val_loss: 3.1910\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.12246\n",
      "Epoch 119/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0358 - val_loss: 3.1793\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3.12246\n",
      "Epoch 120/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0556 - val_loss: 3.2466\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3.12246\n",
      "Epoch 121/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0559 - val_loss: 3.1866\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3.12246\n",
      "Epoch 122/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0440 - val_loss: 3.1933\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3.12246\n",
      "Epoch 123/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0532 - val_loss: 3.1756\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3.12246\n",
      "Epoch 124/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0377 - val_loss: 3.1859\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3.12246\n",
      "Epoch 125/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0604 - val_loss: 3.2226\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3.12246\n",
      "Epoch 126/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0775 - val_loss: 3.2251\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3.12246\n",
      "Epoch 127/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0480 - val_loss: 3.2117\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3.12246\n",
      "Epoch 128/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0866 - val_loss: 3.2720\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3.12246\n",
      "Epoch 129/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0824 - val_loss: 3.2342\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 3.12246\n",
      "Epoch 130/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0564 - val_loss: 3.1815\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 3.12246\n",
      "Epoch 131/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0615 - val_loss: 3.2112\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 3.12246\n",
      "Epoch 132/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1477 - val_loss: 3.3249\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3.12246\n",
      "Epoch 133/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0732 - val_loss: 3.4912\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3.12246\n",
      "Epoch 134/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0948 - val_loss: 3.2966\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 3.12246\n",
      "Epoch 135/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0641 - val_loss: 3.1821\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3.12246\n",
      "Epoch 136/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0783 - val_loss: 3.2871\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3.12246\n",
      "Epoch 137/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0941 - val_loss: 3.2030\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3.12246\n",
      "Epoch 138/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0888 - val_loss: 3.1955\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3.12246\n",
      "Epoch 139/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0898 - val_loss: 3.1428\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 3.12246\n",
      "Epoch 140/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0513 - val_loss: 3.1711\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 3.12246\n",
      "Epoch 141/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0579 - val_loss: 3.3258\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 3.12246\n",
      "Epoch 142/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0628 - val_loss: 3.2028\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 3.12246\n",
      "Epoch 143/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0626 - val_loss: 3.1987\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 3.12246\n",
      "Epoch 144/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0677 - val_loss: 3.4841\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 3.12246\n",
      "Epoch 145/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1077 - val_loss: 3.2032\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 3.12246\n",
      "Epoch 146/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0846 - val_loss: 3.2246\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 3.12246\n",
      "Epoch 147/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0769 - val_loss: 3.3666\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 3.12246\n",
      "Epoch 148/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0887 - val_loss: 3.2010\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 3.12246\n",
      "Epoch 149/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0524 - val_loss: 3.3446\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 3.12246\n",
      "Epoch 150/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0975 - val_loss: 3.3385\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 3.12246\n",
      "Epoch 151/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0710 - val_loss: 3.1675\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 3.12246\n",
      "Epoch 152/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0745 - val_loss: 3.2935\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 3.12246\n",
      "Epoch 153/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0564 - val_loss: 3.1493\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 3.12246\n",
      "Epoch 154/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0640 - val_loss: 3.1030\n",
      "\n",
      "Epoch 00154: val_loss improved from 3.12246 to 3.10296, saving model to .\\best_model.h5\n",
      "Epoch 155/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0816 - val_loss: 3.0879\n",
      "\n",
      "Epoch 00155: val_loss improved from 3.10296 to 3.08786, saving model to .\\best_model.h5\n",
      "Epoch 156/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0524 - val_loss: 3.3885\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 3.08786\n",
      "Epoch 157/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1625 - val_loss: 3.2778\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 3.08786\n",
      "Epoch 158/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0787 - val_loss: 3.1750\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 3.08786\n",
      "Epoch 159/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0760 - val_loss: 3.1547\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 3.08786\n",
      "Epoch 160/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0935 - val_loss: 3.1905\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 3.08786\n",
      "Epoch 161/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0626 - val_loss: 3.2831\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 3.08786\n",
      "Epoch 162/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0994 - val_loss: 3.1994\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 3.08786\n",
      "Epoch 163/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0733 - val_loss: 3.1670\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 3.08786\n",
      "Epoch 164/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0856 - val_loss: 3.1939\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 3.08786\n",
      "Epoch 165/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0791 - val_loss: 3.2127\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 3.08786\n",
      "Epoch 166/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0655 - val_loss: 3.2775\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 3.08786\n",
      "Epoch 167/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0671 - val_loss: 3.1450\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 3.08786\n",
      "Epoch 168/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0509 - val_loss: 3.1755\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 3.08786\n",
      "Epoch 169/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0441 - val_loss: 3.3159\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 3.08786\n",
      "Epoch 170/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0947 - val_loss: 3.2001\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 3.08786\n",
      "Epoch 171/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0784 - val_loss: 3.2676\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3.08786\n",
      "Epoch 172/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0541 - val_loss: 3.1730\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 3.08786\n",
      "Epoch 173/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0829 - val_loss: 3.1797\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 3.08786\n",
      "Epoch 174/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1009 - val_loss: 3.3589\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 3.08786\n",
      "Epoch 175/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0838 - val_loss: 3.2931\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 3.08786\n",
      "Epoch 176/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0409 - val_loss: 3.1726\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 3.08786\n",
      "Epoch 177/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1067 - val_loss: 3.2067\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 3.08786\n",
      "Epoch 178/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0236 - val_loss: 3.1990\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 3.08786\n",
      "Epoch 179/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0776 - val_loss: 3.3202\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 3.08786\n",
      "Epoch 180/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0928 - val_loss: 3.1897\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 3.08786\n",
      "Epoch 181/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0644 - val_loss: 3.2035\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 3.08786\n",
      "Epoch 182/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0659 - val_loss: 3.2337\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 3.08786\n",
      "Epoch 183/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0646 - val_loss: 3.8939\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 3.08786\n",
      "Epoch 184/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0922 - val_loss: 3.1818\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 3.08786\n",
      "Epoch 185/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0538 - val_loss: 3.3300\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 3.08786\n",
      "Epoch 186/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0579 - val_loss: 3.2081\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 3.08786\n",
      "Epoch 187/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0768 - val_loss: 3.2174\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 3.08786\n",
      "Epoch 188/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1292 - val_loss: 3.4263\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 3.08786\n",
      "Epoch 189/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0480 - val_loss: 3.1874\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 3.08786\n",
      "Epoch 190/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0715 - val_loss: 3.2768\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 3.08786\n",
      "Epoch 191/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0525 - val_loss: 3.3578\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3.08786\n",
      "Epoch 192/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0858 - val_loss: 3.1689\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 3.08786\n",
      "Epoch 193/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0921 - val_loss: 3.1721\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 3.08786\n",
      "Epoch 194/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0751 - val_loss: 3.2392\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 3.08786\n",
      "Epoch 195/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0747 - val_loss: 3.4255\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 3.08786\n",
      "Epoch 196/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1119 - val_loss: 3.2330\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 3.08786\n",
      "Epoch 197/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0452 - val_loss: 3.2615\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 3.08786\n",
      "Epoch 198/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0641 - val_loss: 3.2016\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 3.08786\n",
      "Epoch 199/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1056 - val_loss: 3.2600\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 3.08786\n",
      "Epoch 200/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0488 - val_loss: 3.1771\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 3.08786\n",
      "Epoch 201/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0726 - val_loss: 3.1815\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 3.08786\n",
      "Epoch 202/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0335 - val_loss: 3.1728\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 3.08786\n",
      "Epoch 203/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0674 - val_loss: 3.2120\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 3.08786\n",
      "Epoch 204/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0551 - val_loss: 3.1686\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 3.08786\n",
      "Epoch 205/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0618 - val_loss: 3.1901\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 3.08786\n",
      "Epoch 206/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0660 - val_loss: 3.1725\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 3.08786\n",
      "Epoch 207/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0565 - val_loss: 3.1705\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 3.08786\n",
      "Epoch 208/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0530 - val_loss: 3.1797\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 3.08786\n",
      "Epoch 209/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0749 - val_loss: 3.1701\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 3.08786\n",
      "Epoch 210/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0692 - val_loss: 3.1975\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 3.08786\n",
      "Epoch 211/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0566 - val_loss: 3.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00211: val_loss did not improve from 3.08786\n",
      "Epoch 212/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0531 - val_loss: 3.2133\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 3.08786\n",
      "Epoch 213/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0455 - val_loss: 3.2083\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 3.08786\n",
      "Epoch 214/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0498 - val_loss: 3.7119\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 3.08786\n",
      "Epoch 215/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1203 - val_loss: 3.3000\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 3.08786\n",
      "Epoch 216/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1225 - val_loss: 3.1738\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 3.08786\n",
      "Epoch 217/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0504 - val_loss: 3.1743\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 3.08786\n",
      "Epoch 218/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0618 - val_loss: 3.1871\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 3.08786\n",
      "Epoch 219/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0452 - val_loss: 3.1791\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 3.08786\n",
      "Epoch 220/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0598 - val_loss: 3.1786\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 3.08786\n",
      "Epoch 221/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0574 - val_loss: 3.1755\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 3.08786\n",
      "Epoch 222/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0742 - val_loss: 3.2103\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 3.08786\n",
      "Epoch 223/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0744 - val_loss: 3.1783\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 3.08786\n",
      "Epoch 224/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0561 - val_loss: 3.1837\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 3.08786\n",
      "Epoch 225/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0459 - val_loss: 3.1788\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 3.08786\n",
      "Epoch 226/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0837 - val_loss: 3.1724\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 3.08786\n",
      "Epoch 227/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0546 - val_loss: 3.1843\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 3.08786\n",
      "Epoch 228/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1018 - val_loss: 3.2281\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 3.08786\n",
      "Epoch 229/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0994 - val_loss: 3.1901\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 3.08786\n",
      "Epoch 230/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0837 - val_loss: 3.2181\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 3.08786\n",
      "Epoch 231/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0439 - val_loss: 3.3664\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 3.08786\n",
      "Epoch 232/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0627 - val_loss: 3.4572\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 3.08786\n",
      "Epoch 233/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0695 - val_loss: 3.2112\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 3.08786\n",
      "Epoch 234/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0685 - val_loss: 3.2229\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 3.08786\n",
      "Epoch 235/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0375 - val_loss: 3.2507\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 3.08786\n",
      "Epoch 236/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0483 - val_loss: 3.2057\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 3.08786\n",
      "Epoch 237/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0345 - val_loss: 3.3658\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 3.08786\n",
      "Epoch 238/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1179 - val_loss: 3.6253\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 3.08786\n",
      "Epoch 239/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0619 - val_loss: 3.2655\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 3.08786\n",
      "Epoch 240/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0698 - val_loss: 3.3936\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 3.08786\n",
      "Epoch 241/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0842 - val_loss: 3.2568\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 3.08786\n",
      "Epoch 242/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1056 - val_loss: 3.2331\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 3.08786\n",
      "Epoch 243/2000\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.072 - 1s 4ms/step - loss: 1.0621 - val_loss: 3.1376\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 3.08786\n",
      "Epoch 244/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0605 - val_loss: 3.2774\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 3.08786\n",
      "Epoch 245/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0582 - val_loss: 3.1915\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 3.08786\n",
      "Epoch 246/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0793 - val_loss: 3.3722\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 3.08786\n",
      "Epoch 247/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0712 - val_loss: 3.1893\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 3.08786\n",
      "Epoch 248/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0591 - val_loss: 3.2127\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 3.08786\n",
      "Epoch 249/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0611 - val_loss: 3.2536\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 3.08786\n",
      "Epoch 250/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0690 - val_loss: 3.4021\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 3.08786\n",
      "Epoch 251/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0696 - val_loss: 3.2182\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 3.08786\n",
      "Epoch 252/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0308 - val_loss: 3.6103\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 3.08786\n",
      "Epoch 253/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0644 - val_loss: 3.2398\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 3.08786\n",
      "Epoch 254/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0350 - val_loss: 3.9938\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 3.08786\n",
      "Epoch 255/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0593 - val_loss: 3.1568\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 3.08786\n",
      "Epoch 256/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0452 - val_loss: 3.1941\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 3.08786\n",
      "Epoch 257/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0969 - val_loss: 3.2054\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 3.08786\n",
      "Epoch 258/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0437 - val_loss: 3.2776\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 3.08786\n",
      "Epoch 259/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0716 - val_loss: 3.1636\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 3.08786\n",
      "Epoch 260/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0754 - val_loss: 3.1915\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 3.08786\n",
      "Epoch 261/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0441 - val_loss: 3.3625\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 3.08786\n",
      "Epoch 262/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0517 - val_loss: 3.1186\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 3.08786\n",
      "Epoch 263/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0569 - val_loss: 3.1219\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 3.08786\n",
      "Epoch 264/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0717 - val_loss: 3.1383\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 3.08786\n",
      "Epoch 265/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0632 - val_loss: 3.1511\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 3.08786\n",
      "Epoch 266/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0558 - val_loss: 3.1243\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 3.08786\n",
      "Epoch 267/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0531 - val_loss: 4.0840\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 3.08786\n",
      "Epoch 268/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0879 - val_loss: 3.4035\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 3.08786\n",
      "Epoch 269/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0554 - val_loss: 4.2328\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 3.08786\n",
      "Epoch 270/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0172 - val_loss: 3.4346\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 3.08786\n",
      "Epoch 271/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9831 - val_loss: 3.2873\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 3.08786\n",
      "Epoch 272/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0471 - val_loss: 3.2046\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 3.08786\n",
      "Epoch 273/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0102 - val_loss: 3.2745\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 3.08786\n",
      "Epoch 274/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9916 - val_loss: 3.3764\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 3.08786\n",
      "Epoch 275/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0279 - val_loss: 3.4799\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 3.08786\n",
      "Epoch 276/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0136 - val_loss: 3.2673\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 3.08786\n",
      "Epoch 277/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9798 - val_loss: 3.5002\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 3.08786\n",
      "Epoch 278/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9958 - val_loss: 3.4703\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 3.08786\n",
      "Epoch 279/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0310 - val_loss: 3.5833\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 3.08786\n",
      "Epoch 280/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9942 - val_loss: 3.4251\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 3.08786\n",
      "Epoch 281/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0045 - val_loss: 3.3276\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 3.08786\n",
      "Epoch 282/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9927 - val_loss: 3.4550\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 3.08786\n",
      "Epoch 283/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0130 - val_loss: 3.4370\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 3.08786\n",
      "Epoch 284/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0204 - val_loss: 3.2689\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 3.08786\n",
      "Epoch 285/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0179 - val_loss: 3.3324\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 3.08786\n",
      "Epoch 286/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0633 - val_loss: 3.4956\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 3.08786\n",
      "Epoch 287/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0062 - val_loss: 3.3011\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 3.08786\n",
      "Epoch 288/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0664 - val_loss: 3.4270\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 3.08786\n",
      "Epoch 289/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1041 - val_loss: 3.3025\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 3.08786\n",
      "Epoch 290/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0460 - val_loss: 3.2710\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 3.08786\n",
      "Epoch 291/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0735 - val_loss: 3.4318\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 3.08786\n",
      "Epoch 292/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0207 - val_loss: 3.3435\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 3.08786\n",
      "Epoch 293/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0381 - val_loss: 3.2990\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 3.08786\n",
      "Epoch 294/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0861 - val_loss: 3.3170\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 3.08786\n",
      "Epoch 295/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0155 - val_loss: 3.7290\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 3.08786\n",
      "Epoch 296/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0333 - val_loss: 3.3694\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 3.08786\n",
      "Epoch 297/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9877 - val_loss: 3.4518\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 3.08786\n",
      "Epoch 298/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0070 - val_loss: 3.4341\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 3.08786\n",
      "Epoch 299/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0083 - val_loss: 3.4811\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 3.08786\n",
      "Epoch 300/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0089 - val_loss: 3.3334\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 3.08786\n",
      "Epoch 301/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0330 - val_loss: 3.2671\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 3.08786\n",
      "Epoch 302/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0396 - val_loss: 3.2476\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 3.08786\n",
      "Epoch 303/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0406 - val_loss: 3.4490\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 3.08786\n",
      "Epoch 304/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0607 - val_loss: 3.3629\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 3.08786\n",
      "Epoch 305/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0629 - val_loss: 3.3848\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 3.08786\n",
      "Epoch 306/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0536 - val_loss: 3.5628\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 3.08786\n",
      "Epoch 307/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0585 - val_loss: 3.8278\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 3.08786\n",
      "Epoch 308/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0326 - val_loss: 3.5320\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 3.08786\n",
      "Epoch 309/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0271 - val_loss: 3.5771\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 3.08786\n",
      "Epoch 310/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0210 - val_loss: 3.5170\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 3.08786\n",
      "Epoch 311/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0104 - val_loss: 3.4296\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 3.08786\n",
      "Epoch 312/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0233 - val_loss: 3.2939\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 3.08786\n",
      "Epoch 313/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0504 - val_loss: 3.3291\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 3.08786\n",
      "Epoch 314/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0546 - val_loss: 3.4418\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 3.08786\n",
      "Epoch 315/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0205 - val_loss: 3.4380\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 3.08786\n",
      "Epoch 316/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0155 - val_loss: 3.3835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00316: val_loss did not improve from 3.08786\n",
      "Epoch 317/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0289 - val_loss: 3.3861\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 3.08786\n",
      "Epoch 318/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0017 - val_loss: 3.3830\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 3.08786\n",
      "Epoch 319/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0513 - val_loss: 3.7099\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 3.08786\n",
      "Epoch 320/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0396 - val_loss: 3.5080\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 3.08786\n",
      "Epoch 321/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0024 - val_loss: 3.6100\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 3.08786\n",
      "Epoch 322/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0309 - val_loss: 3.4821\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 3.08786\n",
      "Epoch 323/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0231 - val_loss: 3.8544\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 3.08786\n",
      "Epoch 324/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0434 - val_loss: 3.2750\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 3.08786\n",
      "Epoch 325/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0654 - val_loss: 3.2865\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 3.08786\n",
      "Epoch 326/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0315 - val_loss: 3.2608\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 3.08786\n",
      "Epoch 327/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0182 - val_loss: 3.4298\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 3.08786\n",
      "Epoch 328/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0636 - val_loss: 3.1926\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 3.08786\n",
      "Epoch 329/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0312 - val_loss: 3.1949\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 3.08786\n",
      "Epoch 330/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0681 - val_loss: 3.2647\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 3.08786\n",
      "Epoch 331/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0489 - val_loss: 3.2977\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 3.08786\n",
      "Epoch 332/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0552 - val_loss: 3.2785\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 3.08786\n",
      "Epoch 333/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0680 - val_loss: 3.3566\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 3.08786\n",
      "Epoch 334/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0869 - val_loss: 3.1986\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 3.08786\n",
      "Epoch 335/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0510 - val_loss: 3.2253\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 3.08786\n",
      "Epoch 336/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0984 - val_loss: 3.3187\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 3.08786\n",
      "Epoch 337/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0406 - val_loss: 3.2161\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 3.08786\n",
      "Epoch 338/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0618 - val_loss: 3.1999\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 3.08786\n",
      "Epoch 339/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0761 - val_loss: 3.2115\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 3.08786\n",
      "Epoch 340/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0429 - val_loss: 3.2192\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 3.08786\n",
      "Epoch 341/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0047 - val_loss: 3.2335\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 3.08786\n",
      "Epoch 342/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0150 - val_loss: 3.2239\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 3.08786\n",
      "Epoch 343/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0556 - val_loss: 3.6599\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 3.08786\n",
      "Epoch 344/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.1058 - val_loss: 3.5536\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 3.08786\n",
      "Epoch 345/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0654 - val_loss: 3.2514\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 3.08786\n",
      "Epoch 346/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0210 - val_loss: 3.2093\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 3.08786\n",
      "Epoch 347/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0351 - val_loss: 3.2241\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 3.08786\n",
      "Epoch 348/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9964 - val_loss: 3.1886\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 3.08786\n",
      "Epoch 349/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0174 - val_loss: 3.3870\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 3.08786\n",
      "Epoch 350/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9597 - val_loss: 3.1729\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 3.08786\n",
      "Epoch 351/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9686 - val_loss: 3.1242\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 3.08786\n",
      "Epoch 352/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9901 - val_loss: 3.1559\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 3.08786\n",
      "Epoch 353/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9953 - val_loss: 3.1652\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 3.08786\n",
      "Epoch 354/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9339 - val_loss: 3.1891\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 3.08786\n",
      "Epoch 355/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9338 - val_loss: 3.1786\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 3.08786\n",
      "Epoch 356/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9758 - val_loss: 3.3568\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 3.08786\n",
      "Epoch 357/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9901 - val_loss: 3.6223\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 3.08786\n",
      "Epoch 358/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9868 - val_loss: 3.3036\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 3.08786\n",
      "Epoch 359/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9907 - val_loss: 3.4486\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 3.08786\n",
      "Epoch 360/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9650 - val_loss: 3.1867\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 3.08786\n",
      "Epoch 361/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0228 - val_loss: 3.1100\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 3.08786\n",
      "Epoch 362/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9857 - val_loss: 3.1845\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 3.08786\n",
      "Epoch 363/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0090 - val_loss: 3.4446\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 3.08786\n",
      "Epoch 364/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9919 - val_loss: 3.1425\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 3.08786\n",
      "Epoch 365/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9497 - val_loss: 3.3475\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 3.08786\n",
      "Epoch 366/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9652 - val_loss: 3.1404\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 3.08786\n",
      "Epoch 367/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9585 - val_loss: 3.2231\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 3.08786\n",
      "Epoch 368/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9678 - val_loss: 3.2617\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 3.08786\n",
      "Epoch 369/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9565 - val_loss: 3.2779\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 3.08786\n",
      "Epoch 370/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9834 - val_loss: 3.2080\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 3.08786\n",
      "Epoch 371/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9589 - val_loss: 3.2422\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 3.08786\n",
      "Epoch 372/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9484 - val_loss: 3.1194\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 3.08786\n",
      "Epoch 373/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9695 - val_loss: 3.2186\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 3.08786\n",
      "Epoch 374/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9656 - val_loss: 3.0671\n",
      "\n",
      "Epoch 00374: val_loss improved from 3.08786 to 3.06712, saving model to .\\best_model.h5\n",
      "Epoch 375/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9463 - val_loss: 3.5568\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 3.06712\n",
      "Epoch 376/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9715 - val_loss: 3.1513\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 3.06712\n",
      "Epoch 377/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9975 - val_loss: 3.3049\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 3.06712\n",
      "Epoch 378/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9634 - val_loss: 3.0802\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 3.06712\n",
      "Epoch 379/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9306 - val_loss: 3.2860\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 3.06712\n",
      "Epoch 380/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9895 - val_loss: 3.1600\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 3.06712\n",
      "Epoch 381/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9749 - val_loss: 3.1762\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 3.06712\n",
      "Epoch 382/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9696 - val_loss: 3.2867\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 3.06712\n",
      "Epoch 383/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9879 - val_loss: 3.2052\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 3.06712\n",
      "Epoch 384/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9642 - val_loss: 3.1415\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 3.06712\n",
      "Epoch 385/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9719 - val_loss: 3.1768\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 3.06712\n",
      "Epoch 386/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9759 - val_loss: 3.3414\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 3.06712\n",
      "Epoch 387/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9756 - val_loss: 3.1422\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 3.06712\n",
      "Epoch 388/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9580 - val_loss: 3.3352\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 3.06712\n",
      "Epoch 389/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9841 - val_loss: 3.2005\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 3.06712\n",
      "Epoch 390/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9762 - val_loss: 3.3604\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 3.06712\n",
      "Epoch 391/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0662 - val_loss: 3.2010\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 3.06712\n",
      "Epoch 392/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0043 - val_loss: 3.2270\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 3.06712\n",
      "Epoch 393/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0122 - val_loss: 3.1936\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 3.06712\n",
      "Epoch 394/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9989 - val_loss: 3.5457\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 3.06712\n",
      "Epoch 395/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0385 - val_loss: 3.1791\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 3.06712\n",
      "Epoch 396/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0121 - val_loss: 3.2673\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 3.06712\n",
      "Epoch 397/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9995 - val_loss: 3.3221\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 3.06712\n",
      "Epoch 398/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9496 - val_loss: 3.1754\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 3.06712\n",
      "Epoch 399/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9699 - val_loss: 3.1764\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 3.06712\n",
      "Epoch 400/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9830 - val_loss: 3.1634\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 3.06712\n",
      "Epoch 401/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9784 - val_loss: 3.1284\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 3.06712\n",
      "Epoch 402/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9619 - val_loss: 3.1535\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 3.06712\n",
      "Epoch 403/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0088 - val_loss: 3.2841\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 3.06712\n",
      "Epoch 404/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9597 - val_loss: 3.1669\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 3.06712\n",
      "Epoch 405/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9659 - val_loss: 3.1680\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 3.06712\n",
      "Epoch 406/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9744 - val_loss: 3.1964\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 3.06712\n",
      "Epoch 407/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0166 - val_loss: 3.2366\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 3.06712\n",
      "Epoch 408/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9733 - val_loss: 3.2314\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 3.06712\n",
      "Epoch 409/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9373 - val_loss: 3.1607\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 3.06712\n",
      "Epoch 410/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9850 - val_loss: 3.1777\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 3.06712\n",
      "Epoch 411/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9708 - val_loss: 3.1097\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 3.06712\n",
      "Epoch 412/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9255 - val_loss: 3.0919\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 3.06712\n",
      "Epoch 413/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9488 - val_loss: 3.0958\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 3.06712\n",
      "Epoch 414/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9801 - val_loss: 3.1738\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 3.06712\n",
      "Epoch 415/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9353 - val_loss: 3.1195\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 3.06712\n",
      "Epoch 416/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9324 - val_loss: 3.1346\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 3.06712\n",
      "Epoch 417/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9649 - val_loss: 3.2124\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 3.06712\n",
      "Epoch 418/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9575 - val_loss: 3.1300\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 3.06712\n",
      "Epoch 419/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9561 - val_loss: 3.4109\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 3.06712\n",
      "Epoch 420/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9590 - val_loss: 3.2817\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 3.06712\n",
      "Epoch 421/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9467 - val_loss: 3.4341\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 3.06712\n",
      "Epoch 422/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9680 - val_loss: 3.1809\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 3.06712\n",
      "Epoch 423/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9273 - val_loss: 3.1390\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 3.06712\n",
      "Epoch 424/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9745 - val_loss: 3.2372\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 3.06712\n",
      "Epoch 425/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9789 - val_loss: 3.5906\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 3.06712\n",
      "Epoch 426/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9718 - val_loss: 3.1449\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 3.06712\n",
      "Epoch 427/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9920 - val_loss: 3.2365\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 3.06712\n",
      "Epoch 428/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9673 - val_loss: 3.4001\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 3.06712\n",
      "Epoch 429/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9426 - val_loss: 3.1573\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 3.06712\n",
      "Epoch 430/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9478 - val_loss: 3.1251\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 3.06712\n",
      "Epoch 431/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9646 - val_loss: 3.1091\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 3.06712\n",
      "Epoch 432/2000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.9647 - val_loss: 3.5720\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 3.06712\n",
      "Epoch 433/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9515 - val_loss: 3.2758\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 3.06712\n",
      "Epoch 434/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9650 - val_loss: 3.5155\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 3.06712\n",
      "Epoch 435/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9978 - val_loss: 3.4101\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 3.06712\n",
      "Epoch 436/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9678 - val_loss: 3.2773\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 3.06712\n",
      "Epoch 437/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9990 - val_loss: 3.4129\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 3.06712\n",
      "Epoch 438/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9792 - val_loss: 3.4489\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 3.06712\n",
      "Epoch 439/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9898 - val_loss: 3.3617\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 3.06712\n",
      "Epoch 440/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9420 - val_loss: 3.3774\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 3.06712\n",
      "Epoch 441/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9968 - val_loss: 3.2647\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 3.06712\n",
      "Epoch 442/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9590 - val_loss: 3.3528\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 3.06712\n",
      "Epoch 443/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9758 - val_loss: 3.1288\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 3.06712\n",
      "Epoch 444/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9428 - val_loss: 3.2506\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 3.06712\n",
      "Epoch 445/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0003 - val_loss: 3.1662\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 3.06712\n",
      "Epoch 446/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0180 - val_loss: 3.3303\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 3.06712\n",
      "Epoch 447/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0365 - val_loss: 3.1462\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 3.06712\n",
      "Epoch 448/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9963 - val_loss: 3.1865\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 3.06712\n",
      "Epoch 449/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0660 - val_loss: 3.1466\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 3.06712\n",
      "Epoch 450/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0519 - val_loss: 3.1813\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 3.06712\n",
      "Epoch 451/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0768 - val_loss: 3.2240\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 3.06712\n",
      "Epoch 452/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0560 - val_loss: 3.4502\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 3.06712\n",
      "Epoch 453/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0856 - val_loss: 3.2108\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 3.06712\n",
      "Epoch 454/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0190 - val_loss: 3.2401\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 3.06712\n",
      "Epoch 455/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0293 - val_loss: 3.2395\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 3.06712\n",
      "Epoch 456/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0421 - val_loss: 3.1745\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 3.06712\n",
      "Epoch 457/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0287 - val_loss: 3.3246\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 3.06712\n",
      "Epoch 458/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0412 - val_loss: 3.3113\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 3.06712\n",
      "Epoch 459/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0295 - val_loss: 3.3095\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 3.06712\n",
      "Epoch 460/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0588 - val_loss: 3.3656\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 3.06712\n",
      "Epoch 461/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0091 - val_loss: 3.2553\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 3.06712\n",
      "Epoch 462/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9991 - val_loss: 3.2898\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 3.06712\n",
      "Epoch 463/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9912 - val_loss: 3.2745\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 3.06712\n",
      "Epoch 464/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1027 - val_loss: 3.4558\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 3.06712\n",
      "Epoch 465/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0569 - val_loss: 3.3856\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 3.06712\n",
      "Epoch 466/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0020 - val_loss: 3.3055\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 3.06712\n",
      "Epoch 467/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0148 - val_loss: 3.2619\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 3.06712\n",
      "Epoch 468/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9924 - val_loss: 3.1023\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 3.06712\n",
      "Epoch 469/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0132 - val_loss: 3.2649\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 3.06712\n",
      "Epoch 470/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0371 - val_loss: 3.4201\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 3.06712\n",
      "Epoch 471/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0823 - val_loss: 3.1599\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 3.06712\n",
      "Epoch 472/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0465 - val_loss: 3.2554\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 3.06712\n",
      "Epoch 473/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0149 - val_loss: 3.2954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00473: val_loss did not improve from 3.06712\n",
      "Epoch 474/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9763 - val_loss: 3.1758\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 3.06712\n",
      "Epoch 475/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9624 - val_loss: 3.1237\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 3.06712\n",
      "Epoch 476/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9625 - val_loss: 3.2131\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 3.06712\n",
      "Epoch 477/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0118 - val_loss: 4.1584\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 3.06712\n",
      "Epoch 478/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0455 - val_loss: 3.4390\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 3.06712\n",
      "Epoch 479/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0003 - val_loss: 3.2379\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 3.06712\n",
      "Epoch 480/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9793 - val_loss: 3.3944\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 3.06712\n",
      "Epoch 481/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9863 - val_loss: 3.2358\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 3.06712\n",
      "Epoch 482/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0350 - val_loss: 3.3168\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 3.06712\n",
      "Epoch 483/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0153 - val_loss: 3.3101\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 3.06712\n",
      "Epoch 484/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9597 - val_loss: 3.2478\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 3.06712\n",
      "Epoch 485/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9758 - val_loss: 3.3061\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 3.06712\n",
      "Epoch 486/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9736 - val_loss: 3.3232\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 3.06712\n",
      "Epoch 487/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9769 - val_loss: 3.3304\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 3.06712\n",
      "Epoch 488/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9920 - val_loss: 3.6051\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 3.06712\n",
      "Epoch 489/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0162 - val_loss: 3.3613\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 3.06712\n",
      "Epoch 490/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0204 - val_loss: 3.2322\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 3.06712\n",
      "Epoch 491/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9807 - val_loss: 3.2677\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 3.06712\n",
      "Epoch 492/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9846 - val_loss: 3.6338\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 3.06712\n",
      "Epoch 493/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0429 - val_loss: 3.9227\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 3.06712\n",
      "Epoch 494/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0124 - val_loss: 3.3238\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 3.06712\n",
      "Epoch 495/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9972 - val_loss: 3.4259\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 3.06712\n",
      "Epoch 496/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0455 - val_loss: 3.3415\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 3.06712\n",
      "Epoch 497/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0154 - val_loss: 3.3439\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 3.06712\n",
      "Epoch 498/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0030 - val_loss: 3.2327\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 3.06712\n",
      "Epoch 499/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0022 - val_loss: 3.3148\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 3.06712\n",
      "Epoch 500/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0135 - val_loss: 3.1943\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 3.06712\n",
      "Epoch 501/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0251 - val_loss: 3.3070\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 3.06712\n",
      "Epoch 502/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9617 - val_loss: 3.3069\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 3.06712\n",
      "Epoch 503/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9974 - val_loss: 3.3349\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 3.06712\n",
      "Epoch 504/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0007 - val_loss: 3.7725\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 3.06712\n",
      "Epoch 505/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0623 - val_loss: 3.2618\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 3.06712\n",
      "Epoch 506/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0116 - val_loss: 3.2646\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 3.06712\n",
      "Epoch 507/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0008 - val_loss: 3.4006\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 3.06712\n",
      "Epoch 508/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0398 - val_loss: 3.2295\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 3.06712\n",
      "Epoch 509/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0377 - val_loss: 3.1673\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 3.06712\n",
      "Epoch 510/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0217 - val_loss: 3.3365\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 3.06712\n",
      "Epoch 511/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0390 - val_loss: 3.1417\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 3.06712\n",
      "Epoch 512/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0249 - val_loss: 3.2148\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 3.06712\n",
      "Epoch 513/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0348 - val_loss: 3.6225\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 3.06712\n",
      "Epoch 514/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0300 - val_loss: 3.3025\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 3.06712\n",
      "Epoch 515/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0626 - val_loss: 3.2542\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 3.06712\n",
      "Epoch 516/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0573 - val_loss: 3.4048\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 3.06712\n",
      "Epoch 517/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0472 - val_loss: 3.4632\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 3.06712\n",
      "Epoch 518/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0397 - val_loss: 3.2876\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 3.06712\n",
      "Epoch 519/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0321 - val_loss: 3.3378\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 3.06712\n",
      "Epoch 520/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0266 - val_loss: 3.1872\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 3.06712\n",
      "Epoch 521/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9871 - val_loss: 3.4065\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 3.06712\n",
      "Epoch 522/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0802 - val_loss: 3.2830\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 3.06712\n",
      "Epoch 523/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0399 - val_loss: 3.3446\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 3.06712\n",
      "Epoch 524/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0338 - val_loss: 3.2333\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 3.06712\n",
      "Epoch 525/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0594 - val_loss: 3.3287\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 3.06712\n",
      "Epoch 526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0266 - val_loss: 3.3531\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 3.06712\n",
      "Epoch 527/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0111 - val_loss: 3.2860\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 3.06712\n",
      "Epoch 528/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0482 - val_loss: 3.1017\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 3.06712\n",
      "Epoch 529/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0092 - val_loss: 3.2949\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 3.06712\n",
      "Epoch 530/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0197 - val_loss: 3.1791\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 3.06712\n",
      "Epoch 531/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0035 - val_loss: 3.2237\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 3.06712\n",
      "Epoch 532/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0443 - val_loss: 3.5312\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 3.06712\n",
      "Epoch 533/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9975 - val_loss: 3.1125\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 3.06712\n",
      "Epoch 534/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9992 - val_loss: 3.1406\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 3.06712\n",
      "Epoch 535/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0342 - val_loss: 3.2191\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 3.06712\n",
      "Epoch 536/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0228 - val_loss: 3.2499\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 3.06712\n",
      "Epoch 537/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0275 - val_loss: 3.1587\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 3.06712\n",
      "Epoch 538/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.0529 - val_loss: 3.2560\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 3.06712\n",
      "Epoch 539/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0500 - val_loss: 3.6542\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 3.06712\n",
      "Epoch 540/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0845 - val_loss: 3.3552\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 3.06712\n",
      "Epoch 541/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0354 - val_loss: 3.1754\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 3.06712\n",
      "Epoch 542/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1108 - val_loss: 3.1539\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 3.06712\n",
      "Epoch 543/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0174 - val_loss: 3.6661\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 3.06712\n",
      "Epoch 544/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0153 - val_loss: 3.8494\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 3.06712\n",
      "Epoch 545/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1026 - val_loss: 3.2281\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 3.06712\n",
      "Epoch 546/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0066 - val_loss: 3.2644\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 3.06712\n",
      "Epoch 547/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0541 - val_loss: 3.2486\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 3.06712\n",
      "Epoch 548/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0589 - val_loss: 3.2920\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 3.06712\n",
      "Epoch 549/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0756 - val_loss: 3.7676\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 3.06712\n",
      "Epoch 550/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0346 - val_loss: 3.2746\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 3.06712\n",
      "Epoch 551/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0104 - val_loss: 3.3862\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 3.06712\n",
      "Epoch 552/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0477 - val_loss: 3.2867\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 3.06712\n",
      "Epoch 553/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0172 - val_loss: 3.2243\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 3.06712\n",
      "Epoch 554/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0051 - val_loss: 3.1991\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 3.06712\n",
      "Epoch 555/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0313 - val_loss: 3.2022\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 3.06712\n",
      "Epoch 556/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0070 - val_loss: 3.3850\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 3.06712\n",
      "Epoch 557/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0529 - val_loss: 3.3750\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 3.06712\n",
      "Epoch 558/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9999 - val_loss: 3.2776\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 3.06712\n",
      "Epoch 559/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0131 - val_loss: 3.3716\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 3.06712\n",
      "Epoch 560/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0008 - val_loss: 3.3132\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 3.06712\n",
      "Epoch 561/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0463 - val_loss: 3.1988\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 3.06712\n",
      "Epoch 562/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9880 - val_loss: 3.2312\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 3.06712\n",
      "Epoch 563/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9878 - val_loss: 3.3579\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 3.06712\n",
      "Epoch 564/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0630 - val_loss: 3.2517\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 3.06712\n",
      "Epoch 565/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0184 - val_loss: 3.1793\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 3.06712\n",
      "Epoch 566/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9844 - val_loss: 3.2606\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 3.06712\n",
      "Epoch 567/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0145 - val_loss: 3.1745\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 3.06712\n",
      "Epoch 568/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0248 - val_loss: 3.3689\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 3.06712\n",
      "Epoch 569/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0295 - val_loss: 3.0953\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 3.06712\n",
      "Epoch 570/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0138 - val_loss: 3.0939\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 3.06712\n",
      "Epoch 571/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0476 - val_loss: 3.1850\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 3.06712\n",
      "Epoch 572/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0607 - val_loss: 3.1646\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 3.06712\n",
      "Epoch 573/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0385 - val_loss: 3.1368\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 3.06712\n",
      "Epoch 574/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0632 - val_loss: 3.3502\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 3.06712\n",
      "Epoch 575/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0312 - val_loss: 3.1917\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 3.06712\n",
      "Epoch 576/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0067 - val_loss: 3.2827\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 3.06712\n",
      "Epoch 577/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0052 - val_loss: 3.1968\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 3.06712\n",
      "Epoch 578/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0007 - val_loss: 3.0621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00578: val_loss improved from 3.06712 to 3.06211, saving model to .\\best_model.h5\n",
      "Epoch 579/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0235 - val_loss: 3.2397\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 3.06211\n",
      "Epoch 580/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9920 - val_loss: 3.0327\n",
      "\n",
      "Epoch 00580: val_loss improved from 3.06211 to 3.03265, saving model to .\\best_model.h5\n",
      "Epoch 581/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9873 - val_loss: 3.0566\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 3.03265\n",
      "Epoch 582/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0335 - val_loss: 3.1063\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 3.03265\n",
      "Epoch 583/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9870 - val_loss: 3.1464\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 3.03265\n",
      "Epoch 584/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9827 - val_loss: 3.1231\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 3.03265\n",
      "Epoch 585/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9969 - val_loss: 3.0876\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 3.03265\n",
      "Epoch 586/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0064 - val_loss: 3.1349\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 3.03265\n",
      "Epoch 587/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9885 - val_loss: 3.1084\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 3.03265\n",
      "Epoch 588/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9794 - val_loss: 3.2102\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 3.03265\n",
      "Epoch 589/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9863 - val_loss: 3.2132\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 3.03265\n",
      "Epoch 590/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9854 - val_loss: 3.1376\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 3.03265\n",
      "Epoch 591/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0346 - val_loss: 3.4537\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 3.03265\n",
      "Epoch 592/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0000 - val_loss: 3.1569\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 3.03265\n",
      "Epoch 593/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9537 - val_loss: 3.4880\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 3.03265\n",
      "Epoch 594/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9595 - val_loss: 3.1053\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 3.03265\n",
      "Epoch 595/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0139 - val_loss: 3.4515\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 3.03265\n",
      "Epoch 596/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0357 - val_loss: 3.1404\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 3.03265\n",
      "Epoch 597/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0249 - val_loss: 3.1237\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 3.03265\n",
      "Epoch 598/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 3.1841\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 3.03265\n",
      "Epoch 599/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9946 - val_loss: 3.2262\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 3.03265\n",
      "Epoch 600/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9738 - val_loss: 3.6460\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 3.03265\n",
      "Epoch 601/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0076 - val_loss: 3.4068\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 3.03265\n",
      "Epoch 602/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9675 - val_loss: 3.2503\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 3.03265\n",
      "Epoch 603/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9807 - val_loss: 3.3550\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 3.03265\n",
      "Epoch 604/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9984 - val_loss: 3.1506\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 3.03265\n",
      "Epoch 605/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9748 - val_loss: 3.2894\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 3.03265\n",
      "Epoch 606/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0197 - val_loss: 3.4339\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 3.03265\n",
      "Epoch 607/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9908 - val_loss: 3.6316\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 3.03265\n",
      "Epoch 608/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0220 - val_loss: 4.3943\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 3.03265\n",
      "Epoch 609/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9914 - val_loss: 3.3915\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 3.03265\n",
      "Epoch 610/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0085 - val_loss: 3.6385\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 3.03265\n",
      "Epoch 611/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0219 - val_loss: 3.5074\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 3.03265\n",
      "Epoch 612/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0075 - val_loss: 3.8959\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 3.03265\n",
      "Epoch 613/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9941 - val_loss: 3.5951\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 3.03265\n",
      "Epoch 614/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0382 - val_loss: 3.3709\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 3.03265\n",
      "Epoch 615/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0453 - val_loss: 3.7377\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 3.03265\n",
      "Epoch 616/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0104 - val_loss: 3.2536\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 3.03265\n",
      "Epoch 617/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0270 - val_loss: 3.4586\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 3.03265\n",
      "Epoch 618/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0230 - val_loss: 3.3146\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 3.03265\n",
      "Epoch 619/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0205 - val_loss: 3.2717\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 3.03265\n",
      "Epoch 620/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9613 - val_loss: 3.1588\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 3.03265\n",
      "Epoch 621/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9858 - val_loss: 3.4730\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 3.03265\n",
      "Epoch 622/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0278 - val_loss: 3.2906\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 3.03265\n",
      "Epoch 623/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9882 - val_loss: 3.2083\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 3.03265\n",
      "Epoch 624/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9477 - val_loss: 3.3759\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 3.03265\n",
      "Epoch 625/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9422 - val_loss: 3.3281\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 3.03265\n",
      "Epoch 626/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9910 - val_loss: 3.6242\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 3.03265\n",
      "Epoch 627/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9540 - val_loss: 3.4936\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 3.03265\n",
      "Epoch 628/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9515 - val_loss: 3.5196\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 3.03265\n",
      "Epoch 629/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9651 - val_loss: 3.2868\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 3.03265\n",
      "Epoch 630/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9729 - val_loss: 3.3827\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 3.03265\n",
      "Epoch 631/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9666 - val_loss: 3.4655\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 3.03265\n",
      "Epoch 632/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9852 - val_loss: 3.5579\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 3.03265\n",
      "Epoch 633/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9576 - val_loss: 3.2878\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 3.03265\n",
      "Epoch 634/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9365 - val_loss: 3.2279\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 3.03265\n",
      "Epoch 635/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9706 - val_loss: 3.1607\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 3.03265\n",
      "Epoch 636/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9698 - val_loss: 3.4563\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 3.03265\n",
      "Epoch 637/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9806 - val_loss: 3.4321\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 3.03265\n",
      "Epoch 638/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9726 - val_loss: 3.2387\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 3.03265\n",
      "Epoch 639/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9890 - val_loss: 3.2555\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 3.03265\n",
      "Epoch 640/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9816 - val_loss: 3.6557\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 3.03265\n",
      "Epoch 641/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9639 - val_loss: 3.2680\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 3.03265\n",
      "Epoch 642/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0079 - val_loss: 3.3226\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 3.03265\n",
      "Epoch 643/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9991 - val_loss: 3.3950\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 3.03265\n",
      "Epoch 644/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9815 - val_loss: 3.6948\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 3.03265\n",
      "Epoch 645/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9982 - val_loss: 3.6371\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 3.03265\n",
      "Epoch 646/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9941 - val_loss: 3.3279\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 3.03265\n",
      "Epoch 647/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9728 - val_loss: 3.3819\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 3.03265\n",
      "Epoch 648/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9818 - val_loss: 3.5332\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 3.03265\n",
      "Epoch 649/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0049 - val_loss: 3.4988\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 3.03265\n",
      "Epoch 650/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9973 - val_loss: 3.4797\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 3.03265\n",
      "Epoch 651/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0249 - val_loss: 3.3626\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 3.03265\n",
      "Epoch 652/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0097 - val_loss: 3.5200\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 3.03265\n",
      "Epoch 653/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9967 - val_loss: 3.4669\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 3.03265\n",
      "Epoch 654/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9814 - val_loss: 3.4561\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 3.03265\n",
      "Epoch 655/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9916 - val_loss: 3.4340\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 3.03265\n",
      "Epoch 656/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0116 - val_loss: 3.7144\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 3.03265\n",
      "Epoch 657/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9864 - val_loss: 3.5460\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 3.03265\n",
      "Epoch 658/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0196 - val_loss: 3.7317\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 3.03265\n",
      "Epoch 659/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0382 - val_loss: 3.1641\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 3.03265\n",
      "Epoch 660/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9824 - val_loss: 3.6198\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 3.03265\n",
      "Epoch 661/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0078 - val_loss: 3.3373\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 3.03265\n",
      "Epoch 662/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0153 - val_loss: 3.5725\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 3.03265\n",
      "Epoch 663/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9796 - val_loss: 4.4454\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 3.03265\n",
      "Epoch 664/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9839 - val_loss: 3.7959\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 3.03265\n",
      "Epoch 665/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0164 - val_loss: 3.7234\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 3.03265\n",
      "Epoch 666/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9646 - val_loss: 3.4410\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 3.03265\n",
      "Epoch 667/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9823 - val_loss: 3.4706\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 3.03265\n",
      "Epoch 668/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9586 - val_loss: 3.2539\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 3.03265\n",
      "Epoch 669/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9817 - val_loss: 3.3526\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 3.03265\n",
      "Epoch 670/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0435 - val_loss: 3.3861\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 3.03265\n",
      "Epoch 671/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0023 - val_loss: 3.5202\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 3.03265\n",
      "Epoch 672/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9854 - val_loss: 3.2914\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 3.03265\n",
      "Epoch 673/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.0369 - val_loss: 3.3045\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 3.03265\n",
      "Epoch 674/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 3.2433\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 3.03265\n",
      "Epoch 675/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 3.3215\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 3.03265\n",
      "Epoch 676/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 3.3955\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 3.03265\n",
      "Epoch 677/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0470 - val_loss: 3.3695\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 3.03265\n",
      "Epoch 678/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0094 - val_loss: 3.2965\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 3.03265\n",
      "Epoch 679/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0158 - val_loss: 3.3554\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 3.03265\n",
      "Epoch 680/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 3.2878\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 3.03265\n",
      "Epoch 681/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0488 - val_loss: 3.3583\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 3.03265\n",
      "Epoch 682/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0167 - val_loss: 3.2966\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 3.03265\n",
      "Epoch 683/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0384 - val_loss: 3.2380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00683: val_loss did not improve from 3.03265\n",
      "Epoch 684/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0365 - val_loss: 3.2313\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 3.03265\n",
      "Epoch 685/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.0494 - val_loss: 3.1949\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 3.03265\n",
      "Epoch 686/2000\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 1.0187 - val_loss: 3.3205 - ETA: 0s - loss: 1.\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 3.03265\n",
      "Epoch 687/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0435 - val_loss: 3.3792 ETA: 1s - loss: 1\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 3.03265\n",
      "Epoch 688/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.0287 - val_loss: 3.2553\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 3.03265\n",
      "Epoch 689/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0426 - val_loss: 3.1429\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 3.03265\n",
      "Epoch 690/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0730 - val_loss: 3.2195\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 3.03265\n",
      "Epoch 691/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9860 - val_loss: 3.5773\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 3.03265\n",
      "Epoch 692/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0252 - val_loss: 3.4102\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 3.03265\n",
      "Epoch 693/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0227 - val_loss: 3.2214\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 3.03265\n",
      "Epoch 694/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9811 - val_loss: 3.1739\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 3.03265\n",
      "Epoch 695/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 3.2494\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 3.03265\n",
      "Epoch 696/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 3.3416\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 3.03265\n",
      "Epoch 697/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9838 - val_loss: 3.2636\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 3.03265\n",
      "Epoch 698/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9684 - val_loss: 3.2630\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 3.03265\n",
      "Epoch 699/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 3.2396\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 3.03265\n",
      "Epoch 700/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 3.0960\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 3.03265\n",
      "Epoch 701/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 3.2476\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 3.03265\n",
      "Epoch 702/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 3.3027\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 3.03265\n",
      "Epoch 703/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 3.1848\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 3.03265\n",
      "Epoch 704/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 3.2558\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 3.03265\n",
      "Epoch 705/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 3.1538\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 3.03265\n",
      "Epoch 706/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 3.3018\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 3.03265\n",
      "Epoch 707/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 3.1879\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 3.03265\n",
      "Epoch 708/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9981 - val_loss: 3.3561\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 3.03265\n",
      "Epoch 709/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 3.2480\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 3.03265\n",
      "Epoch 710/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9220 - val_loss: 3.1481\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 3.03265\n",
      "Epoch 711/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 3.1642\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 3.03265\n",
      "Epoch 712/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 3.1188\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 3.03265\n",
      "Epoch 713/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 3.3094\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 3.03265\n",
      "Epoch 714/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 3.3819\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 3.03265\n",
      "Epoch 715/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 3.3256\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 3.03265\n",
      "Epoch 716/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9748 - val_loss: 3.2276\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 3.03265\n",
      "Epoch 717/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 3.1541\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 3.03265\n",
      "Epoch 718/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 3.0230\n",
      "\n",
      "Epoch 00718: val_loss improved from 3.03265 to 3.02298, saving model to .\\best_model.h5\n",
      "Epoch 719/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 3.3645\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 3.02298\n",
      "Epoch 720/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 3.8698\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 3.02298\n",
      "Epoch 721/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 3.1801\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 3.02298\n",
      "Epoch 722/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0305 - val_loss: 3.2096\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 3.02298\n",
      "Epoch 723/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9765 - val_loss: 3.2673\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 3.02298\n",
      "Epoch 724/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 3.1948\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 3.02298\n",
      "Epoch 725/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 3.1105\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 3.02298\n",
      "Epoch 726/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.0114 - val_loss: 3.3049\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 3.02298\n",
      "Epoch 727/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 3.3103\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 3.02298\n",
      "Epoch 728/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 3.1125\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 3.02298\n",
      "Epoch 729/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 3.1227\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 3.02298\n",
      "Epoch 730/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 3.0755\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 3.02298\n",
      "Epoch 731/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 3.4546\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 3.02298\n",
      "Epoch 732/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 3.0541\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 3.02298\n",
      "Epoch 733/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 3.0653\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 3.02298\n",
      "Epoch 734/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 3.1677\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 3.02298\n",
      "Epoch 735/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9767 - val_loss: 3.2726\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 3.02298\n",
      "Epoch 736/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 3.2093\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 3.02298\n",
      "Epoch 737/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9757 - val_loss: 3.2088\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 3.02298\n",
      "Epoch 738/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 3.6397\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 3.02298\n",
      "Epoch 739/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0126 - val_loss: 3.4758\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 3.02298\n",
      "Epoch 740/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 3.2541\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 3.02298\n",
      "Epoch 741/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9844 - val_loss: 3.2674\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 3.02298\n",
      "Epoch 742/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9662 - val_loss: 3.1899\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 3.02298\n",
      "Epoch 743/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9729 - val_loss: 3.5146\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 3.02298\n",
      "Epoch 744/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 3.1510\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 3.02298\n",
      "Epoch 745/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 3.5568\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 3.02298\n",
      "Epoch 746/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 3.3995\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 3.02298\n",
      "Epoch 747/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0191 - val_loss: 3.7164\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 3.02298\n",
      "Epoch 748/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 3.6480\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 3.02298\n",
      "Epoch 749/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 4.1724\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 3.02298\n",
      "Epoch 750/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 3.9951\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 3.02298\n",
      "Epoch 751/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 3.5323\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 3.02298\n",
      "Epoch 752/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 3.5681\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 3.02298\n",
      "Epoch 753/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 3.4315\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 3.02298\n",
      "Epoch 754/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 3.4510\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 3.02298\n",
      "Epoch 755/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 3.9454\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 3.02298\n",
      "Epoch 756/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 3.8600\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 3.02298\n",
      "Epoch 757/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 3.5430\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 3.02298\n",
      "Epoch 758/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9712 - val_loss: 3.4738\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 3.02298\n",
      "Epoch 759/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 3.5872\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 3.02298\n",
      "Epoch 760/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 3.2572\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 3.02298\n",
      "Epoch 761/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9636 - val_loss: 3.2194\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 3.02298\n",
      "Epoch 762/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 3.1860\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 3.02298\n",
      "Epoch 763/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 3.3845\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 3.02298\n",
      "Epoch 764/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9557 - val_loss: 3.3255\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 3.02298\n",
      "Epoch 765/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9888 - val_loss: 3.2604\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 3.02298\n",
      "Epoch 766/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9829 - val_loss: 3.6810\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 3.02298\n",
      "Epoch 767/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 3.3720\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 3.02298\n",
      "Epoch 768/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 3.3932\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 3.02298\n",
      "Epoch 769/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 3.1414\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 3.02298\n",
      "Epoch 770/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 3.3621\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 3.02298\n",
      "Epoch 771/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9881 - val_loss: 3.5210\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 3.02298\n",
      "Epoch 772/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9727 - val_loss: 3.1305\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 3.02298\n",
      "Epoch 773/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0264 - val_loss: 3.2188\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 3.02298\n",
      "Epoch 774/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 3.4244\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 3.02298\n",
      "Epoch 775/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9716 - val_loss: 3.2188\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 3.02298\n",
      "Epoch 776/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 3.6346\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 3.02298\n",
      "Epoch 777/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 3.7330\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 3.02298\n",
      "Epoch 778/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9972 - val_loss: 3.2698\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 3.02298\n",
      "Epoch 779/2000\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 1.0025 - val_loss: 3.3448\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 3.02298\n",
      "Epoch 780/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9442 - val_loss: 3.1455\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 3.02298\n",
      "Epoch 781/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 3.6333\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 3.02298\n",
      "Epoch 782/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 3.1870\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 3.02298\n",
      "Epoch 783/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 3.3343\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 3.02298\n",
      "Epoch 784/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 3.2375\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 3.02298\n",
      "Epoch 785/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9767 - val_loss: 3.3055\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 3.02298\n",
      "Epoch 786/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9859 - val_loss: 3.1718\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 3.02298\n",
      "Epoch 787/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 3.1771\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 3.02298\n",
      "Epoch 788/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 3.2913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00788: val_loss did not improve from 3.02298\n",
      "Epoch 789/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9669 - val_loss: 3.1939\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 3.02298\n",
      "Epoch 790/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9088 - val_loss: 3.3196\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 3.02298\n",
      "Epoch 791/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9479 - val_loss: 3.5498\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 3.02298\n",
      "Epoch 792/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9504 - val_loss: 3.6113\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 3.02298\n",
      "Epoch 793/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9834 - val_loss: 3.4599\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 3.02298\n",
      "Epoch 794/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9834 - val_loss: 3.5682\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 3.02298\n",
      "Epoch 795/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0092 - val_loss: 3.2289\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 3.02298\n",
      "Epoch 796/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9797 - val_loss: 3.2642\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 3.02298\n",
      "Epoch 797/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9326 - val_loss: 3.4283\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 3.02298\n",
      "Epoch 798/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9802 - val_loss: 3.4352\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 3.02298\n",
      "Epoch 799/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9569 - val_loss: 3.4049\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 3.02298\n",
      "Epoch 800/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9909 - val_loss: 3.2336\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 3.02298\n",
      "Epoch 801/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0011 - val_loss: 3.3538\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 3.02298\n",
      "Epoch 802/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9580 - val_loss: 3.1091\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 3.02298\n",
      "Epoch 803/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9524 - val_loss: 3.2280\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 3.02298\n",
      "Epoch 804/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9894 - val_loss: 3.1798\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 3.02298\n",
      "Epoch 805/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9906 - val_loss: 3.1587\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 3.02298\n",
      "Epoch 806/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9589 - val_loss: 3.4577\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 3.02298\n",
      "Epoch 807/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9613 - val_loss: 3.3269\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 3.02298\n",
      "Epoch 808/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9231 - val_loss: 3.3062\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 3.02298\n",
      "Epoch 809/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9340 - val_loss: 3.5232\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 3.02298\n",
      "Epoch 810/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9544 - val_loss: 3.2907\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 3.02298\n",
      "Epoch 811/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9587 - val_loss: 3.3611\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 3.02298\n",
      "Epoch 812/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9813 - val_loss: 3.1052\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 3.02298\n",
      "Epoch 813/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9603 - val_loss: 3.2843\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 3.02298\n",
      "Epoch 814/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9625 - val_loss: 3.2625\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 3.02298\n",
      "Epoch 815/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0087 - val_loss: 3.4479\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 3.02298\n",
      "Epoch 816/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9537 - val_loss: 3.7770\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 3.02298\n",
      "Epoch 817/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9714 - val_loss: 3.9173\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 3.02298\n",
      "Epoch 818/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9854 - val_loss: 3.6723\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 3.02298\n",
      "Epoch 819/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9550 - val_loss: 3.4606\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 3.02298\n",
      "Epoch 820/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9736 - val_loss: 3.4163\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 3.02298\n",
      "Epoch 821/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9566 - val_loss: 3.5605\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 3.02298\n",
      "Epoch 822/2000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9782 - val_loss: 3.3649\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 3.02298\n",
      "Epoch 823/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9792 - val_loss: 3.6411\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 3.02298\n",
      "Epoch 824/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9767 - val_loss: 3.4499\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 3.02298\n",
      "Epoch 825/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9771 - val_loss: 3.5761\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 3.02298\n",
      "Epoch 826/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9776 - val_loss: 3.5704\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 3.02298\n",
      "Epoch 827/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9783 - val_loss: 3.4319\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 3.02298\n",
      "Epoch 828/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9872 - val_loss: 3.3789\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 3.02298\n",
      "Epoch 829/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9558 - val_loss: 3.8008\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 3.02298\n",
      "Epoch 830/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9489 - val_loss: 3.1516\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 3.02298\n",
      "Epoch 831/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9552 - val_loss: 3.3408\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 3.02298\n",
      "Epoch 832/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9495 - val_loss: 3.3525\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 3.02298\n",
      "Epoch 833/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9580 - val_loss: 3.6239\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 3.02298\n",
      "Epoch 834/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9441 - val_loss: 3.2349\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 3.02298\n",
      "Epoch 835/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9596 - val_loss: 3.3174\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 3.02298\n",
      "Epoch 836/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9957 - val_loss: 3.4680\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 3.02298\n",
      "Epoch 837/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9673 - val_loss: 3.3098\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 3.02298\n",
      "Epoch 838/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9669 - val_loss: 3.3899\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 3.02298\n",
      "Epoch 839/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9796 - val_loss: 3.4659\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 3.02298\n",
      "Epoch 840/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0074 - val_loss: 3.2967\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 3.02298\n",
      "Epoch 841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9833 - val_loss: 3.2502\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 3.02298\n",
      "Epoch 842/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9847 - val_loss: 3.5126\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 3.02298\n",
      "Epoch 843/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9986 - val_loss: 3.1974\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 3.02298\n",
      "Epoch 844/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9544 - val_loss: 3.1931\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 3.02298\n",
      "Epoch 845/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9703 - val_loss: 3.0813\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 3.02298\n",
      "Epoch 846/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9790 - val_loss: 3.0664\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 3.02298\n",
      "Epoch 847/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9739 - val_loss: 3.5174\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 3.02298\n",
      "Epoch 848/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9667 - val_loss: 3.2210\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 3.02298\n",
      "Epoch 849/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9586 - val_loss: 3.2758\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 3.02298\n",
      "Epoch 850/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9685 - val_loss: 3.2773\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 3.02298\n",
      "Epoch 851/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9731 - val_loss: 3.4027\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 3.02298\n",
      "Epoch 852/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9414 - val_loss: 3.3188\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 3.02298\n",
      "Epoch 853/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9374 - val_loss: 3.1276\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 3.02298\n",
      "Epoch 854/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9800 - val_loss: 3.6542\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 3.02298\n",
      "Epoch 855/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9570 - val_loss: 3.2568\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 3.02298\n",
      "Epoch 856/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9364 - val_loss: 3.7040\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 3.02298\n",
      "Epoch 857/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9417 - val_loss: 3.2264\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 3.02298\n",
      "Epoch 858/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9498 - val_loss: 3.5228\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 3.02298\n",
      "Epoch 859/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9449 - val_loss: 3.3276\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 3.02298\n",
      "Epoch 860/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9583 - val_loss: 3.3527\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 3.02298\n",
      "Epoch 861/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9328 - val_loss: 3.2295\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 3.02298\n",
      "Epoch 862/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9008 - val_loss: 3.3338\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 3.02298\n",
      "Epoch 863/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9106 - val_loss: 3.0990\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 3.02298\n",
      "Epoch 864/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9129 - val_loss: 3.3063\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 3.02298\n",
      "Epoch 865/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9640 - val_loss: 3.3783\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 3.02298\n",
      "Epoch 866/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9691 - val_loss: 3.1404\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 3.02298\n",
      "Epoch 867/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9557 - val_loss: 3.1004\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 3.02298\n",
      "Epoch 868/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9705 - val_loss: 3.2568\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 3.02298\n",
      "Epoch 869/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9284 - val_loss: 3.4420\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 3.02298\n",
      "Epoch 870/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9469 - val_loss: 3.1695\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 3.02298\n",
      "Epoch 871/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9484 - val_loss: 3.2156\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 3.02298\n",
      "Epoch 872/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9260 - val_loss: 3.1280\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 3.02298\n",
      "Epoch 873/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9293 - val_loss: 3.0443\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 3.02298\n",
      "Epoch 874/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9023 - val_loss: 3.2796\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 3.02298\n",
      "Epoch 875/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9568 - val_loss: 3.7892\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 3.02298\n",
      "Epoch 876/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9330 - val_loss: 3.2763\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 3.02298\n",
      "Epoch 877/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9474 - val_loss: 3.1454\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 3.02298\n",
      "Epoch 878/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9353 - val_loss: 3.2568\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 3.02298\n",
      "Epoch 879/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9532 - val_loss: 3.2020\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 3.02298\n",
      "Epoch 880/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9590 - val_loss: 3.2976\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 3.02298\n",
      "Epoch 881/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9774 - val_loss: 3.2980\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 3.02298\n",
      "Epoch 882/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9228 - val_loss: 3.1651\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 3.02298\n",
      "Epoch 883/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9091 - val_loss: 3.0951\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 3.02298\n",
      "Epoch 884/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9430 - val_loss: 3.3387\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 3.02298\n",
      "Epoch 885/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9416 - val_loss: 3.1183\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 3.02298\n",
      "Epoch 886/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9371 - val_loss: 3.2524\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 3.02298\n",
      "Epoch 887/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9332 - val_loss: 3.1902\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 3.02298\n",
      "Epoch 888/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9159 - val_loss: 3.1207\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 3.02298\n",
      "Epoch 889/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9476 - val_loss: 3.0747\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 3.02298\n",
      "Epoch 890/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9530 - val_loss: 3.5053\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 3.02298\n",
      "Epoch 891/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9447 - val_loss: 3.2033\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 3.02298\n",
      "Epoch 892/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9287 - val_loss: 3.2008\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 3.02298\n",
      "Epoch 893/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9115 - val_loss: 3.3412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00893: val_loss did not improve from 3.02298\n",
      "Epoch 894/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9550 - val_loss: 3.1555\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 3.02298\n",
      "Epoch 895/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9429 - val_loss: 3.1000\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 3.02298\n",
      "Epoch 896/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9366 - val_loss: 3.5805\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 3.02298\n",
      "Epoch 897/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9094 - val_loss: 3.3011\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 3.02298\n",
      "Epoch 898/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.8690 - val_loss: 3.4428\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 3.02298\n",
      "Epoch 899/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9153 - val_loss: 3.4912\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 3.02298\n",
      "Epoch 900/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8999 - val_loss: 3.2932\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 3.02298\n",
      "Epoch 901/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9297 - val_loss: 3.1922\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 3.02298\n",
      "Epoch 902/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9285 - val_loss: 3.2264\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 3.02298\n",
      "Epoch 903/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9284 - val_loss: 3.3826\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 3.02298\n",
      "Epoch 904/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9287 - val_loss: 3.3319\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 3.02298\n",
      "Epoch 905/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9158 - val_loss: 3.3668\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 3.02298\n",
      "Epoch 906/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9394 - val_loss: 3.3352\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 3.02298\n",
      "Epoch 907/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8941 - val_loss: 3.4316\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 3.02298\n",
      "Epoch 908/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8868 - val_loss: 3.4950\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 3.02298\n",
      "Epoch 909/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9405 - val_loss: 3.3065\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 3.02298\n",
      "Epoch 910/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9425 - val_loss: 3.1340\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 3.02298\n",
      "Epoch 911/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9325 - val_loss: 3.4110\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 3.02298\n",
      "Epoch 912/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9323 - val_loss: 3.3978\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 3.02298\n",
      "Epoch 913/2000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9281 - val_loss: 3.1993\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 3.02298\n",
      "Epoch 914/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9349 - val_loss: 3.3116\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 3.02298\n",
      "Epoch 915/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9171 - val_loss: 3.2621\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 3.02298\n",
      "Epoch 916/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9262 - val_loss: 3.1917\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 3.02298\n",
      "Epoch 917/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9222 - val_loss: 3.1496\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 3.02298\n",
      "Epoch 918/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9523 - val_loss: 3.2948\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 3.02298\n",
      "Epoch 919/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9209 - val_loss: 3.4397\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 3.02298\n",
      "Epoch 920/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9181 - val_loss: 3.5147\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 3.02298\n",
      "Epoch 921/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9251 - val_loss: 3.3075\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 3.02298\n",
      "Epoch 922/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9197 - val_loss: 3.2684\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 3.02298\n",
      "Epoch 923/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9327 - val_loss: 3.3262\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 3.02298\n",
      "Epoch 924/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9429 - val_loss: 3.1903\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 3.02298\n",
      "Epoch 925/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9202 - val_loss: 3.1999\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 3.02298\n",
      "Epoch 926/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9080 - val_loss: 3.1951\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 3.02298\n",
      "Epoch 927/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9569 - val_loss: 3.7723\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 3.02298\n",
      "Epoch 928/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9288 - val_loss: 3.2439\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 3.02298\n",
      "Epoch 929/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9572 - val_loss: 3.4345\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 3.02298\n",
      "Epoch 930/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9548 - val_loss: 3.4284\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 3.02298\n",
      "Epoch 931/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9211 - val_loss: 3.5525\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 3.02298\n",
      "Epoch 932/2000\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.961 - 1s 3ms/step - loss: 0.9641 - val_loss: 3.0426\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 3.02298\n",
      "Epoch 933/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9434 - val_loss: 3.2212\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 3.02298\n",
      "Epoch 934/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9312 - val_loss: 3.1367\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 3.02298\n",
      "Epoch 935/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9106 - val_loss: 3.3040\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 3.02298\n",
      "Epoch 936/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9603 - val_loss: 3.5420\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 3.02298\n",
      "Epoch 937/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9528 - val_loss: 3.5405\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 3.02298\n",
      "Epoch 938/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9418 - val_loss: 3.1233\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 3.02298\n",
      "Epoch 939/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9387 - val_loss: 3.2715\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 3.02298\n",
      "Epoch 940/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9186 - val_loss: 3.1224\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 3.02298\n",
      "Epoch 941/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9581 - val_loss: 3.1399\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 3.02298\n",
      "Epoch 942/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9231 - val_loss: 3.1709\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 3.02298\n",
      "Epoch 943/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9184 - val_loss: 3.2467\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 3.02298\n",
      "Epoch 944/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9848 - val_loss: 3.2896\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 3.02298\n",
      "Epoch 945/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9526 - val_loss: 3.2242\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 3.02298\n",
      "Epoch 946/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9625 - val_loss: 3.0493\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 3.02298\n",
      "Epoch 947/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9918 - val_loss: 3.4881\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 3.02298\n",
      "Epoch 948/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9460 - val_loss: 3.0080\n",
      "\n",
      "Epoch 00948: val_loss improved from 3.02298 to 3.00798, saving model to .\\best_model.h5\n",
      "Epoch 949/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9452 - val_loss: 3.1745\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 3.00798\n",
      "Epoch 950/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9040 - val_loss: 3.0972\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 3.00798\n",
      "Epoch 951/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9442 - val_loss: 3.2627\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 3.00798\n",
      "Epoch 952/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9449 - val_loss: 3.3175\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 3.00798\n",
      "Epoch 953/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9505 - val_loss: 3.2385\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 3.00798\n",
      "Epoch 954/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9652 - val_loss: 3.3436\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 3.00798\n",
      "Epoch 955/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9304 - val_loss: 3.2313\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 3.00798\n",
      "Epoch 956/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9153 - val_loss: 3.3329\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 3.00798\n",
      "Epoch 957/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9467 - val_loss: 3.0650\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 3.00798\n",
      "Epoch 958/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9655 - val_loss: 3.3705\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 3.00798\n",
      "Epoch 959/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9558 - val_loss: 3.3865\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 3.00798\n",
      "Epoch 960/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9398 - val_loss: 3.2109\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 3.00798\n",
      "Epoch 961/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9525 - val_loss: 3.3000\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 3.00798\n",
      "Epoch 962/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9428 - val_loss: 3.6185\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 3.00798\n",
      "Epoch 963/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9452 - val_loss: 3.2339\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 3.00798\n",
      "Epoch 964/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9096 - val_loss: 3.3607\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 3.00798\n",
      "Epoch 965/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9515 - val_loss: 3.1187\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 3.00798\n",
      "Epoch 966/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9033 - val_loss: 4.0579\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 3.00798\n",
      "Epoch 967/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9420 - val_loss: 3.2520\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 3.00798\n",
      "Epoch 968/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9527 - val_loss: 3.3546\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 3.00798\n",
      "Epoch 969/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9510 - val_loss: 3.0988\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 3.00798\n",
      "Epoch 970/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9650 - val_loss: 3.3771\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 3.00798\n",
      "Epoch 971/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9434 - val_loss: 3.3450\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 3.00798\n",
      "Epoch 972/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9748 - val_loss: 3.3081\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 3.00798\n",
      "Epoch 973/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9701 - val_loss: 3.4135\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 3.00798\n",
      "Epoch 974/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9179 - val_loss: 3.0536\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 3.00798\n",
      "Epoch 975/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8905 - val_loss: 3.1260\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 3.00798\n",
      "Epoch 976/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9226 - val_loss: 3.0676\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 3.00798\n",
      "Epoch 977/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9209 - val_loss: 3.2353\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 3.00798\n",
      "Epoch 978/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9109 - val_loss: 3.1786\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 3.00798\n",
      "Epoch 979/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9192 - val_loss: 3.1089\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 3.00798\n",
      "Epoch 980/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9518 - val_loss: 3.1854\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 3.00798\n",
      "Epoch 981/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9377 - val_loss: 3.0808\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 3.00798\n",
      "Epoch 982/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9469 - val_loss: 3.0573\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 3.00798\n",
      "Epoch 983/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9207 - val_loss: 3.2621\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 3.00798\n",
      "Epoch 984/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9141 - val_loss: 3.3366\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 3.00798\n",
      "Epoch 985/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8979 - val_loss: 3.2134\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 3.00798\n",
      "Epoch 986/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9107 - val_loss: 3.1673\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 3.00798\n",
      "Epoch 987/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9175 - val_loss: 3.3517\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 3.00798\n",
      "Epoch 988/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9460 - val_loss: 3.1393\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 3.00798\n",
      "Epoch 989/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9640 - val_loss: 3.2268\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 3.00798\n",
      "Epoch 990/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9221 - val_loss: 3.3236\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 3.00798\n",
      "Epoch 991/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9444 - val_loss: 3.0618\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 3.00798\n",
      "Epoch 992/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9253 - val_loss: 3.0168\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 3.00798\n",
      "Epoch 993/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9210 - val_loss: 3.1882\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 3.00798\n",
      "Epoch 994/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9285 - val_loss: 3.1232\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 3.00798\n",
      "Epoch 995/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9428 - val_loss: 3.2336\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 3.00798\n",
      "Epoch 996/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9545 - val_loss: 3.1772\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 3.00798\n",
      "Epoch 997/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9199 - val_loss: 3.0326\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 3.00798\n",
      "Epoch 998/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9489 - val_loss: 3.3671\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 3.00798\n",
      "Epoch 999/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9760 - val_loss: 3.1792\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 3.00798\n",
      "Epoch 1000/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9475 - val_loss: 3.2219\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 3.00798\n",
      "Epoch 1001/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9858 - val_loss: 3.5973\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 3.00798\n",
      "Epoch 1002/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9942 - val_loss: 3.0631\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 3.00798\n",
      "Epoch 1003/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9842 - val_loss: 2.9997\n",
      "\n",
      "Epoch 01003: val_loss improved from 3.00798 to 2.99973, saving model to .\\best_model.h5\n",
      "Epoch 1004/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9815 - val_loss: 3.2906\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 2.99973\n",
      "Epoch 1005/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9471 - val_loss: 3.0571\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 2.99973\n",
      "Epoch 1006/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9980 - val_loss: 3.0065\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 2.99973\n",
      "Epoch 1007/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9617 - val_loss: 3.1558\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 2.99973\n",
      "Epoch 1008/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0176 - val_loss: 3.0546\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 2.99973\n",
      "Epoch 1009/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9597 - val_loss: 3.0518\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 2.99973\n",
      "Epoch 1010/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9732 - val_loss: 3.1190\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 2.99973\n",
      "Epoch 1011/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9569 - val_loss: 3.1397\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 2.99973\n",
      "Epoch 1012/2000\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.9499 - val_loss: 3.4249\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 2.99973\n",
      "Epoch 1013/2000\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9782 - val_loss: 3.1436\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 2.99973\n",
      "Epoch 1014/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 3.1609\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 2.99973\n",
      "Epoch 1015/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9128 - val_loss: 3.0465\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 2.99973\n",
      "Epoch 1016/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9361 - val_loss: 3.3726\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 2.99973\n",
      "Epoch 1017/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 3.3593\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 2.99973\n",
      "Epoch 1018/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 3.2140\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 2.99973\n",
      "Epoch 1019/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 3.3474\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 2.99973\n",
      "Epoch 1020/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 3.2715\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 2.99973\n",
      "Epoch 1021/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 3.1887\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 2.99973\n",
      "Epoch 1022/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 3.1010\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 2.99973\n",
      "Epoch 1023/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9025 - val_loss: 3.2762\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 2.99973\n",
      "Epoch 1024/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 3.2900\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 2.99973\n",
      "Epoch 1025/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 3.3661\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 2.99973\n",
      "Epoch 1026/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9076 - val_loss: 3.1412\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 2.99973\n",
      "Epoch 1027/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 3.2247\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 2.99973\n",
      "Epoch 1028/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 3.0788\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 2.99973\n",
      "Epoch 1029/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 3.4316\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 2.99973\n",
      "Epoch 1030/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 3.1408\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 2.99973\n",
      "Epoch 1031/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9072 - val_loss: 3.0874\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 2.99973\n",
      "Epoch 1032/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 3.0750\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 2.99973\n",
      "Epoch 1033/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 3.0195\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 2.99973\n",
      "Epoch 1034/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8962 - val_loss: 3.1403\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 2.99973\n",
      "Epoch 1035/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9121 - val_loss: 3.2065\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 2.99973\n",
      "Epoch 1036/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 3.0491\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 2.99973\n",
      "Epoch 1037/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 3.0867\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 2.99973\n",
      "Epoch 1038/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 3.0276\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 2.99973\n",
      "Epoch 1039/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9103 - val_loss: 3.3405\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 2.99973\n",
      "Epoch 1040/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 3.1569\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 2.99973\n",
      "Epoch 1041/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9041 - val_loss: 3.0640\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 2.99973\n",
      "Epoch 1042/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 3.3382\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 2.99973\n",
      "Epoch 1043/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9074 - val_loss: 3.1116\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 2.99973\n",
      "Epoch 1044/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 3.3946\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 2.99973\n",
      "Epoch 1045/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 3.1990\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 2.99973\n",
      "Epoch 1046/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 3.2505\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 2.99973\n",
      "Epoch 1047/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 3.3055\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 2.99973\n",
      "Epoch 1048/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 3.3886\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 2.99973\n",
      "Epoch 1049/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9008 - val_loss: 3.1015\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 2.99973\n",
      "Epoch 1050/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8992 - val_loss: 3.1678\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 2.99973\n",
      "Epoch 1051/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8965 - val_loss: 3.0704\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 2.99973\n",
      "Epoch 1052/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 3.2898\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 2.99973\n",
      "Epoch 1053/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8988 - val_loss: 3.4504\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 2.99973\n",
      "Epoch 1054/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9067 - val_loss: 3.1711\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 2.99973\n",
      "Epoch 1055/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8754 - val_loss: 3.1137\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 2.99973\n",
      "Epoch 1056/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 3.1280\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 2.99973\n",
      "Epoch 1057/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8985 - val_loss: 2.9958\n",
      "\n",
      "Epoch 01057: val_loss improved from 2.99973 to 2.99578, saving model to .\\best_model.h5\n",
      "Epoch 1058/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9130 - val_loss: 3.2447\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 2.99578\n",
      "Epoch 1059/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9117 - val_loss: 3.1687\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 2.99578\n",
      "Epoch 1060/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 3.4932\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 2.99578\n",
      "Epoch 1061/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9683 - val_loss: 3.4518\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 2.99578\n",
      "Epoch 1062/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 3.2474\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 2.99578\n",
      "Epoch 1063/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 4.1564\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 2.99578\n",
      "Epoch 1064/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0143 - val_loss: 3.4324\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 2.99578\n",
      "Epoch 1065/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 3.2242\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 2.99578\n",
      "Epoch 1066/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9044 - val_loss: 3.0582\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 2.99578\n",
      "Epoch 1067/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9015 - val_loss: 3.6911\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 2.99578\n",
      "Epoch 1068/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 3.3350\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 2.99578\n",
      "Epoch 1069/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 3.2708\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 2.99578\n",
      "Epoch 1070/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8995 - val_loss: 3.2905\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 2.99578\n",
      "Epoch 1071/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9115 - val_loss: 3.0851\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 2.99578\n",
      "Epoch 1072/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 3.0489\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 2.99578\n",
      "Epoch 1073/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 3.2347\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 2.99578\n",
      "Epoch 1074/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 3.6071\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 2.99578\n",
      "Epoch 1075/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 3.3279\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 2.99578\n",
      "Epoch 1076/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9029 - val_loss: 3.2187\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 2.99578\n",
      "Epoch 1077/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 3.2860\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 2.99578\n",
      "Epoch 1078/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 3.4119\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 2.99578\n",
      "Epoch 1079/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8919 - val_loss: 3.3384\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 2.99578\n",
      "Epoch 1080/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9052 - val_loss: 4.0350\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 2.99578\n",
      "Epoch 1081/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 3.2111\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 2.99578\n",
      "Epoch 1082/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 3.6786\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 2.99578\n",
      "Epoch 1083/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 3.6819\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 2.99578\n",
      "Epoch 1084/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8883 - val_loss: 3.9154\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 2.99578\n",
      "Epoch 1085/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9055 - val_loss: 4.1316\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 2.99578\n",
      "Epoch 1086/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 3.1301\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 2.99578\n",
      "Epoch 1087/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8672 - val_loss: 3.3839\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 2.99578\n",
      "Epoch 1088/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8705 - val_loss: 3.1878\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 2.99578\n",
      "Epoch 1089/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9087 - val_loss: 3.1566\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 2.99578\n",
      "Epoch 1090/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 3.2015\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 2.99578\n",
      "Epoch 1091/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 3.3922\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 2.99578\n",
      "Epoch 1092/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8983 - val_loss: 3.3425\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 2.99578\n",
      "Epoch 1093/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8790 - val_loss: 3.2948\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 2.99578\n",
      "Epoch 1094/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 3.0996\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 2.99578\n",
      "Epoch 1095/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9078 - val_loss: 3.1526\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 2.99578\n",
      "Epoch 1096/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 3.1622\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 2.99578\n",
      "Epoch 1097/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8845 - val_loss: 3.1942\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 2.99578\n",
      "Epoch 1098/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8878 - val_loss: 3.2026\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 2.99578\n",
      "Epoch 1099/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8972 - val_loss: 3.1533\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 2.99578\n",
      "Epoch 1100/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 3.2564\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 2.99578\n",
      "Epoch 1101/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8837 - val_loss: 3.3135\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 2.99578\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8863 - val_loss: 3.1770\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 2.99578\n",
      "Epoch 1103/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8681 - val_loss: 3.2862\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 2.99578\n",
      "Epoch 1104/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8941 - val_loss: 3.1328\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 2.99578\n",
      "Epoch 1105/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 3.1774\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 2.99578\n",
      "Epoch 1106/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8772 - val_loss: 3.2148\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 2.99578\n",
      "Epoch 1107/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 3.3150\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 2.99578\n",
      "Epoch 1108/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 3.2393\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 2.99578\n",
      "Epoch 1109/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 3.2450\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 2.99578\n",
      "Epoch 1110/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 3.3380\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 2.99578\n",
      "Epoch 1111/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8886 - val_loss: 3.1963\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 2.99578\n",
      "Epoch 1112/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8803 - val_loss: 3.2736\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 2.99578\n",
      "Epoch 1113/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8746 - val_loss: 3.4416\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 2.99578\n",
      "Epoch 1114/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8630 - val_loss: 3.5263\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 2.99578\n",
      "Epoch 1115/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9017 - val_loss: 3.2834\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 2.99578\n",
      "Epoch 1116/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9077 - val_loss: 3.4924\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 2.99578\n",
      "Epoch 1117/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8776 - val_loss: 3.4723\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 2.99578\n",
      "Epoch 1118/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 3.5132\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 2.99578\n",
      "Epoch 1119/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9081 - val_loss: 3.3580\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 2.99578\n",
      "Epoch 1120/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9041 - val_loss: 3.5249\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 2.99578\n",
      "Epoch 1121/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8959 - val_loss: 3.3564\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 2.99578\n",
      "Epoch 1122/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9654 - val_loss: 3.5065\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 2.99578\n",
      "Epoch 1123/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 3.3998\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 2.99578\n",
      "Epoch 1124/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9133 - val_loss: 3.2401\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 2.99578\n",
      "Epoch 1125/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 3.2059\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 2.99578\n",
      "Epoch 1126/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9078 - val_loss: 3.1401\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 2.99578\n",
      "Epoch 1127/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 3.0916\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 2.99578\n",
      "Epoch 1128/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 3.1102\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 2.99578\n",
      "Epoch 1129/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9137 - val_loss: 3.1701\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 2.99578\n",
      "Epoch 1130/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8905 - val_loss: 2.9499\n",
      "\n",
      "Epoch 01130: val_loss improved from 2.99578 to 2.94990, saving model to .\\best_model.h5\n",
      "Epoch 1131/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8746 - val_loss: 3.0366\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 2.94990\n",
      "Epoch 1132/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8575 - val_loss: 3.4334\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 2.94990\n",
      "Epoch 1133/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8702 - val_loss: 3.2884\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 2.94990\n",
      "Epoch 1134/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 2.9655\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 2.94990\n",
      "Epoch 1135/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9052 - val_loss: 3.2126\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 2.94990\n",
      "Epoch 1136/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9010 - val_loss: 3.1817\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 2.94990\n",
      "Epoch 1137/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9003 - val_loss: 3.5903\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 2.94990\n",
      "Epoch 1138/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 3.5694\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 2.94990\n",
      "Epoch 1139/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9075 - val_loss: 3.1130\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 2.94990\n",
      "Epoch 1140/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 3.2687\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 2.94990\n",
      "Epoch 1141/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 3.2892\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 2.94990\n",
      "Epoch 1142/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 3.1630\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 2.94990\n",
      "Epoch 1143/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9010 - val_loss: 3.3848\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 2.94990\n",
      "Epoch 1144/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 3.1705\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 2.94990\n",
      "Epoch 1145/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 4.0755\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 2.94990\n",
      "Epoch 1146/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 3.3131\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 2.94990\n",
      "Epoch 1147/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 3.3596\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 2.94990\n",
      "Epoch 1148/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 3.5365\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 2.94990\n",
      "Epoch 1149/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 3.4903\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 2.94990\n",
      "Epoch 1150/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 3.2831\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 2.94990\n",
      "Epoch 1151/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 3.3263\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 2.94990\n",
      "Epoch 1152/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 3.5018\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 2.94990\n",
      "Epoch 1153/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 3.5507\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 2.94990\n",
      "Epoch 1154/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 3.4033\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 2.94990\n",
      "Epoch 1155/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 3.2476\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 2.94990\n",
      "Epoch 1156/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 3.2762\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 2.94990\n",
      "Epoch 1157/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 3.7609\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 2.94990\n",
      "Epoch 1158/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8983 - val_loss: 3.6333\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 2.94990\n",
      "Epoch 1159/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9285 - val_loss: 3.0252\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 2.94990\n",
      "Epoch 1160/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 3.2628\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 2.94990\n",
      "Epoch 1161/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 3.2402\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 2.94990\n",
      "Epoch 1162/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8968 - val_loss: 3.2432\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 2.94990\n",
      "Epoch 1163/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 3.3341\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 2.94990\n",
      "Epoch 1164/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8901 - val_loss: 3.7481\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 2.94990\n",
      "Epoch 1165/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8923 - val_loss: 3.4426\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 2.94990\n",
      "Epoch 1166/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8973 - val_loss: 3.2046\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 2.94990\n",
      "Epoch 1167/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8664 - val_loss: 3.0484\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 2.94990\n",
      "Epoch 1168/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9060 - val_loss: 3.1859\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 2.94990\n",
      "Epoch 1169/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 3.1907\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 2.94990\n",
      "Epoch 1170/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8716 - val_loss: 3.2551\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 2.94990\n",
      "Epoch 1171/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8812 - val_loss: 3.1609\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 2.94990\n",
      "Epoch 1172/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8760 - val_loss: 4.0379\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 2.94990\n",
      "Epoch 1173/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8900 - val_loss: 3.5944\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 2.94990\n",
      "Epoch 1174/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8919 - val_loss: 3.1542\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 2.94990\n",
      "Epoch 1175/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 3.1103\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 2.94990\n",
      "Epoch 1176/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8784 - val_loss: 3.3472\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 2.94990\n",
      "Epoch 1177/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9024 - val_loss: 3.0428\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 2.94990\n",
      "Epoch 1178/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9130 - val_loss: 3.0951\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 2.94990\n",
      "Epoch 1179/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 3.1965\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 2.94990\n",
      "Epoch 1180/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9034 - val_loss: 3.5256\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 2.94990\n",
      "Epoch 1181/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 3.5101\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 2.94990\n",
      "Epoch 1182/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8618 - val_loss: 3.3383\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 2.94990\n",
      "Epoch 1183/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8685 - val_loss: 3.3409\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 2.94990\n",
      "Epoch 1184/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8575 - val_loss: 2.9949\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 2.94990\n",
      "Epoch 1185/2000\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.913 - 0s 2ms/step - loss: 0.9152 - val_loss: 3.2958\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 2.94990\n",
      "Epoch 1186/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 3.3259\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 2.94990\n",
      "Epoch 1187/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8623 - val_loss: 3.4250\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 2.94990\n",
      "Epoch 1188/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8711 - val_loss: 3.2896\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 2.94990\n",
      "Epoch 1189/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8939 - val_loss: 3.4072\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 2.94990\n",
      "Epoch 1190/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 3.3225\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 2.94990\n",
      "Epoch 1191/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8563 - val_loss: 3.4899\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 2.94990\n",
      "Epoch 1192/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8953 - val_loss: 3.1442\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 2.94990\n",
      "Epoch 1193/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 3.3282\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 2.94990\n",
      "Epoch 1194/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 3.4611\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 2.94990\n",
      "Epoch 1195/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8824 - val_loss: 3.9506\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 2.94990\n",
      "Epoch 1196/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 3.0885\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 2.94990\n",
      "Epoch 1197/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8959 - val_loss: 3.2051\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 2.94990\n",
      "Epoch 1198/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8848 - val_loss: 3.1020\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 2.94990\n",
      "Epoch 1199/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 3.4617\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 2.94990\n",
      "Epoch 1200/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9062 - val_loss: 3.4702\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 2.94990\n",
      "Epoch 1201/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9085 - val_loss: 3.3340\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 2.94990\n",
      "Epoch 1202/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 3.2088\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 2.94990\n",
      "Epoch 1203/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 3.4727\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 2.94990\n",
      "Epoch 1204/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 3.5740\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 2.94990\n",
      "Epoch 1205/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 3.3797\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 2.94990\n",
      "Epoch 1206/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 3.3017\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 2.94990\n",
      "Epoch 1207/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 3.4408\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 2.94990\n",
      "Epoch 1208/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 3.4244\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 2.94990\n",
      "Epoch 1209/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 3.2662\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 2.94990\n",
      "Epoch 1210/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 3.3824\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 2.94990\n",
      "Epoch 1211/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9055 - val_loss: 3.5714\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 2.94990\n",
      "Epoch 1212/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 3.7028\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 2.94990\n",
      "Epoch 1213/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 3.9401\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 2.94990\n",
      "Epoch 1214/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9108 - val_loss: 3.5089\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 2.94990\n",
      "Epoch 1215/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8993 - val_loss: 3.1040\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 2.94990\n",
      "Epoch 1216/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 3.1395\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 2.94990\n",
      "Epoch 1217/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 3.9809\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 2.94990\n",
      "Epoch 1218/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 3.3862\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 2.94990\n",
      "Epoch 1219/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8843 - val_loss: 3.6200\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 2.94990\n",
      "Epoch 1220/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 3.3369\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 2.94990\n",
      "Epoch 1221/2000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.9078 - val_loss: 4.2656\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 2.94990\n",
      "Epoch 1222/2000\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.9496 - val_loss: 4.0171- ETA: 0s - loss: 0.9 - ETA: 0s -\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 2.94990\n",
      "Epoch 1223/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 3.3931\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 2.94990\n",
      "Epoch 1224/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 3.3341\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 2.94990\n",
      "Epoch 1225/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 3.3907\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 2.94990\n",
      "Epoch 1226/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9076 - val_loss: 3.2299\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 2.94990\n",
      "Epoch 1227/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9140 - val_loss: 3.7425\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 2.94990\n",
      "Epoch 1228/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 3.4123\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 2.94990\n",
      "Epoch 1229/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9145 - val_loss: 3.4384\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 2.94990\n",
      "Epoch 1230/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9091 - val_loss: 3.5193\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 2.94990\n",
      "Epoch 1231/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 3.6116\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 2.94990\n",
      "Epoch 1232/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9149 - val_loss: 4.2888\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 2.94990\n",
      "Epoch 1233/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9069 - val_loss: 3.2560\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 2.94990\n",
      "Epoch 1234/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8726 - val_loss: 3.4698\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 2.94990\n",
      "Epoch 1235/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 3.6206\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 2.94990\n",
      "Epoch 1236/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8990 - val_loss: 3.1142\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 2.94990\n",
      "Epoch 1237/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8722 - val_loss: 3.3553\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 2.94990\n",
      "Epoch 1238/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9023 - val_loss: 3.0717\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 2.94990\n",
      "Epoch 1239/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8983 - val_loss: 3.4163\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 2.94990\n",
      "Epoch 1240/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8922 - val_loss: 3.7417\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 2.94990\n",
      "Epoch 1241/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 3.2445\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 2.94990\n",
      "Epoch 1242/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 2.9357\n",
      "\n",
      "Epoch 01242: val_loss improved from 2.94990 to 2.93572, saving model to .\\best_model.h5\n",
      "Epoch 1243/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 3.0651\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 2.93572\n",
      "Epoch 1244/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 3.1922\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 2.93572\n",
      "Epoch 1245/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 3.3947\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 2.93572\n",
      "Epoch 1246/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 3.3088\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 2.93572\n",
      "Epoch 1247/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 3.2641\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 2.93572\n",
      "Epoch 1248/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8770 - val_loss: 3.3579\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 2.93572\n",
      "Epoch 1249/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 3.5964\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 2.93572\n",
      "Epoch 1250/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9072 - val_loss: 3.0741\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 2.93572\n",
      "Epoch 1251/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 3.3455\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 2.93572\n",
      "Epoch 1252/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 3.1094\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 2.93572\n",
      "Epoch 1253/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9010 - val_loss: 3.2648\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 2.93572\n",
      "Epoch 1254/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 3.5274\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 2.93572\n",
      "Epoch 1255/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 3.2851\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 2.93572\n",
      "Epoch 1256/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 2.9936\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 2.93572\n",
      "Epoch 1257/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8851 - val_loss: 4.2629\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 2.93572\n",
      "Epoch 1258/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9036 - val_loss: 4.1432\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 2.93572\n",
      "Epoch 1259/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 3.9287\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 2.93572\n",
      "Epoch 1260/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 3.3270\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 2.93572\n",
      "Epoch 1261/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 3.8822\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 2.93572\n",
      "Epoch 1262/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8741 - val_loss: 4.5010\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 2.93572\n",
      "Epoch 1263/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9532 - val_loss: 3.8685\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 2.93572\n",
      "Epoch 1264/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 3.6051\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 2.93572\n",
      "Epoch 1265/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 4.0931\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 2.93572\n",
      "Epoch 1266/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 3.4584\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 2.93572\n",
      "Epoch 1267/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 3.3516\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 2.93572\n",
      "Epoch 1268/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 3.5045\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 2.93572\n",
      "Epoch 1269/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 3.6090\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 2.93572\n",
      "Epoch 1270/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 3.1728\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 2.93572\n",
      "Epoch 1271/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9022 - val_loss: 3.5389\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 2.93572\n",
      "Epoch 1272/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 3.4465\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 2.93572\n",
      "Epoch 1273/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8978 - val_loss: 3.5801\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 2.93572\n",
      "Epoch 1274/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 3.5834\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 2.93572\n",
      "Epoch 1275/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 3.5858\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 2.93572\n",
      "Epoch 1276/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9473 - val_loss: 3.1899\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 2.93572\n",
      "Epoch 1277/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 3.4174\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 2.93572\n",
      "Epoch 1278/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 3.1604\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 2.93572\n",
      "Epoch 1279/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 3.0359\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 2.93572\n",
      "Epoch 1280/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 3.0426\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 2.93572\n",
      "Epoch 1281/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9843 - val_loss: 3.0479\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 2.93572\n",
      "Epoch 1282/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 3.0720\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 2.93572\n",
      "Epoch 1283/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 3.0807\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 2.93572\n",
      "Epoch 1284/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 3.2042\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 2.93572\n",
      "Epoch 1285/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 3.2438\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 2.93572\n",
      "Epoch 1286/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9675 - val_loss: 2.9983\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 2.93572\n",
      "Epoch 1287/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 3.0238\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 2.93572\n",
      "Epoch 1288/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 3.1038\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 2.93572\n",
      "Epoch 1289/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9823 - val_loss: 3.1345\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 2.93572\n",
      "Epoch 1290/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 3.0832\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 2.93572\n",
      "Epoch 1291/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 3.0818\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 2.93572\n",
      "Epoch 1292/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 3.3698\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 2.93572\n",
      "Epoch 1293/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 3.1638\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 2.93572\n",
      "Epoch 1294/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 3.4644\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 2.93572\n",
      "Epoch 1295/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 3.2976\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 2.93572\n",
      "Epoch 1296/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 3.0759\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 2.93572\n",
      "Epoch 1297/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 2.9668\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 2.93572\n",
      "Epoch 1298/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 3.3874\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 2.93572\n",
      "Epoch 1299/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 3.0049\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 2.93572\n",
      "Epoch 1300/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 3.4864\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 2.93572\n",
      "Epoch 1301/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 3.4580\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 2.93572\n",
      "Epoch 1302/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 3.7347\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 2.93572\n",
      "Epoch 1303/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9853 - val_loss: 3.3069\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 2.93572\n",
      "Epoch 1304/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 3.3720\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 2.93572\n",
      "Epoch 1305/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 3.2746\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 2.93572\n",
      "Epoch 1306/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 3.1073\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 2.93572\n",
      "Epoch 1307/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 3.2235\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 2.93572\n",
      "Epoch 1308/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9766 - val_loss: 2.9545\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 2.93572\n",
      "Epoch 1309/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 3.1863\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 2.93572\n",
      "Epoch 1310/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 3.0441\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 2.93572\n",
      "Epoch 1311/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 3.1967\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 2.93572\n",
      "Epoch 1312/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 2.9539\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 2.93572\n",
      "Epoch 1313/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 3.0478\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 2.93572\n",
      "Epoch 1314/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8987 - val_loss: 3.6147\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 2.93572\n",
      "Epoch 1315/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 3.3936\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 2.93572\n",
      "Epoch 1316/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 3.1426\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 2.93572\n",
      "Epoch 1317/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0518 - val_loss: 3.0569\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 2.93572\n",
      "Epoch 1318/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 3.1557\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 2.93572\n",
      "Epoch 1319/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 3.1558\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 2.93572\n",
      "Epoch 1320/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 3.6224\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 2.93572\n",
      "Epoch 1321/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9705 - val_loss: 3.2020\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 2.93572\n",
      "Epoch 1322/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 3.6766\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 2.93572\n",
      "Epoch 1323/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9783 - val_loss: 3.1005\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 2.93572\n",
      "Epoch 1324/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 3.5272\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 2.93572\n",
      "Epoch 1325/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 3.2272\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 2.93572\n",
      "Epoch 1326/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 3.1323\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 2.93572\n",
      "Epoch 1327/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 3.2467\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 2.93572\n",
      "Epoch 1328/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 3.0888\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 2.93572\n",
      "Epoch 1329/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 3.1260\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 2.93572\n",
      "Epoch 1330/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 3.1403\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 2.93572\n",
      "Epoch 1331/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 3.0655\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 2.93572\n",
      "Epoch 1332/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 3.1540\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 2.93572\n",
      "Epoch 1333/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8998 - val_loss: 3.0389\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 2.93572\n",
      "Epoch 1334/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 3.2922\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 2.93572\n",
      "Epoch 1335/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 3.1253\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 2.93572\n",
      "Epoch 1336/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 3.1190\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 2.93572\n",
      "Epoch 1337/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 3.1633\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 2.93572\n",
      "Epoch 1338/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9104 - val_loss: 3.1436\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 2.93572\n",
      "Epoch 1339/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9140 - val_loss: 3.1337\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 2.93572\n",
      "Epoch 1340/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8976 - val_loss: 2.9914\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 2.93572\n",
      "Epoch 1341/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9035 - val_loss: 3.0501\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 2.93572\n",
      "Epoch 1342/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9473 - val_loss: 3.0360\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 2.93572\n",
      "Epoch 1343/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 3.1449\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 2.93572\n",
      "Epoch 1344/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 3.2535\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 2.93572\n",
      "Epoch 1345/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 4.1947\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 2.93572\n",
      "Epoch 1346/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 3.0821\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 2.93572\n",
      "Epoch 1347/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9061 - val_loss: 3.0898\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 2.93572\n",
      "Epoch 1348/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 3.4397\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 2.93572\n",
      "Epoch 1349/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 3.3873\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 2.93572\n",
      "Epoch 1350/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9830 - val_loss: 3.2900\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 2.93572\n",
      "Epoch 1351/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 3.1744\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 2.93572\n",
      "Epoch 1352/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9082 - val_loss: 3.1781\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 2.93572\n",
      "Epoch 1353/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 3.0432\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 2.93572\n",
      "Epoch 1354/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8999 - val_loss: 3.1739\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 2.93572\n",
      "Epoch 1355/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9082 - val_loss: 3.0096\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 2.93572\n",
      "Epoch 1356/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 3.0253\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 2.93572\n",
      "Epoch 1357/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9036 - val_loss: 3.0669\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 2.93572\n",
      "Epoch 1358/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 3.2033\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 2.93572\n",
      "Epoch 1359/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9034 - val_loss: 3.0614\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 2.93572\n",
      "Epoch 1360/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8718 - val_loss: 2.9701\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 2.93572\n",
      "Epoch 1361/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8829 - val_loss: 3.0196\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 2.93572\n",
      "Epoch 1362/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 3.0166\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 2.93572\n",
      "Epoch 1363/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9067 - val_loss: 3.1553\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 2.93572\n",
      "Epoch 1364/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 3.2962\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 2.93572\n",
      "Epoch 1365/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8654 - val_loss: 3.2016\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 2.93572\n",
      "Epoch 1366/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8909 - val_loss: 3.1211\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 2.93572\n",
      "Epoch 1367/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8757 - val_loss: 3.2590\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 2.93572\n",
      "Epoch 1368/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 3.0419\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 2.93572\n",
      "Epoch 1369/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 3.0549\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 2.93572\n",
      "Epoch 1370/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 3.5019\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 2.93572\n",
      "Epoch 1371/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 3.3390\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 2.93572\n",
      "Epoch 1372/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 3.1412\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 2.93572\n",
      "Epoch 1373/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 3.4119\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 2.93572\n",
      "Epoch 1374/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9511 - val_loss: 3.5039\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 2.93572\n",
      "Epoch 1375/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8928 - val_loss: 3.2217\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 2.93572\n",
      "Epoch 1376/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8838 - val_loss: 2.9715\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 2.93572\n",
      "Epoch 1377/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8879 - val_loss: 3.2795\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 2.93572\n",
      "Epoch 1378/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8772 - val_loss: 3.7186\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 2.93572\n",
      "Epoch 1379/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8566 - val_loss: 3.1412\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 2.93572\n",
      "Epoch 1380/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8425 - val_loss: 3.2781\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 2.93572\n",
      "Epoch 1381/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8314 - val_loss: 3.1983\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 2.93572\n",
      "Epoch 1382/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8567 - val_loss: 3.6952\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 2.93572\n",
      "Epoch 1383/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8750 - val_loss: 2.9947\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 2.93572\n",
      "Epoch 1384/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8670 - val_loss: 3.1257\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 2.93572\n",
      "Epoch 1385/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8557 - val_loss: 2.9582\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 2.93572\n",
      "Epoch 1386/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8606 - val_loss: 3.1546\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 2.93572\n",
      "Epoch 1387/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8482 - val_loss: 3.0785\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 2.93572\n",
      "Epoch 1388/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8670 - val_loss: 3.6770\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 2.93572\n",
      "Epoch 1389/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8374 - val_loss: 3.1780\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 2.93572\n",
      "Epoch 1390/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8914 - val_loss: 3.0069\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 2.93572\n",
      "Epoch 1391/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8496 - val_loss: 3.1358\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 2.93572\n",
      "Epoch 1392/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8698 - val_loss: 3.2061\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 2.93572\n",
      "Epoch 1393/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8915 - val_loss: 3.1927\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 2.93572\n",
      "Epoch 1394/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8475 - val_loss: 3.1877\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 2.93572\n",
      "Epoch 1395/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8936 - val_loss: 3.2442\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 2.93572\n",
      "Epoch 1396/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9018 - val_loss: 3.1298\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 2.93572\n",
      "Epoch 1397/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9065 - val_loss: 3.7710\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 2.93572\n",
      "Epoch 1398/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9019 - val_loss: 3.2340\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 2.93572\n",
      "Epoch 1399/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8543 - val_loss: 3.1943\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 2.93572\n",
      "Epoch 1400/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9142 - val_loss: 3.1226\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 2.93572\n",
      "Epoch 1401/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8676 - val_loss: 3.3718\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 2.93572\n",
      "Epoch 1402/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8612 - val_loss: 3.3200\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 2.93572\n",
      "Epoch 1403/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8546 - val_loss: 3.2730\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 2.93572\n",
      "Epoch 1404/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8701 - val_loss: 3.0738\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 2.93572\n",
      "Epoch 1405/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8546 - val_loss: 3.2588\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 2.93572\n",
      "Epoch 1406/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8392 - val_loss: 3.2305\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 2.93572\n",
      "Epoch 1407/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8829 - val_loss: 3.1943\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 2.93572\n",
      "Epoch 1408/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8613 - val_loss: 3.2974\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 2.93572\n",
      "Epoch 1409/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8824 - val_loss: 3.2214\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 2.93572\n",
      "Epoch 1410/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8814 - val_loss: 3.3100\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 2.93572\n",
      "Epoch 1411/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8658 - val_loss: 3.2451\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 2.93572\n",
      "Epoch 1412/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8776 - val_loss: 3.1954\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 2.93572\n",
      "Epoch 1413/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 3.1546\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 2.93572\n",
      "Epoch 1414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8465 - val_loss: 3.1620\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 2.93572\n",
      "Epoch 1415/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8755 - val_loss: 3.2249\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 2.93572\n",
      "Epoch 1416/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 3.3114\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 2.93572\n",
      "Epoch 1417/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9355 - val_loss: 3.1161\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 2.93572\n",
      "Epoch 1418/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 3.1935\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 2.93572\n",
      "Epoch 1419/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8997 - val_loss: 3.1550\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 2.93572\n",
      "Epoch 1420/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 3.1205\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 2.93572\n",
      "Epoch 1421/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8704 - val_loss: 3.2667\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 2.93572\n",
      "Epoch 1422/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8659 - val_loss: 3.1728\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 2.93572\n",
      "Epoch 1423/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 3.4536\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 2.93572\n",
      "Epoch 1424/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8833 - val_loss: 3.2945\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 2.93572\n",
      "Epoch 1425/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8844 - val_loss: 3.8683\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 2.93572\n",
      "Epoch 1426/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8930 - val_loss: 3.1488\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 2.93572\n",
      "Epoch 1427/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8938 - val_loss: 3.2653\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 2.93572\n",
      "Epoch 1428/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 3.2092\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 2.93572\n",
      "Epoch 1429/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8758 - val_loss: 3.2185\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 2.93572\n",
      "Epoch 1430/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9695 - val_loss: 3.1604\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 2.93572\n",
      "Epoch 1431/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 3.0447\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 2.93572\n",
      "Epoch 1432/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 3.1187\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 2.93572\n",
      "Epoch 1433/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8893 - val_loss: 2.9318\n",
      "\n",
      "Epoch 01433: val_loss improved from 2.93572 to 2.93179, saving model to .\\best_model.h5\n",
      "Epoch 1434/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8704 - val_loss: 3.2594\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 2.93179\n",
      "Epoch 1435/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8820 - val_loss: 3.4622\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 2.93179\n",
      "Epoch 1436/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8926 - val_loss: 3.5860\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 2.93179\n",
      "Epoch 1437/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 2.9291\n",
      "\n",
      "Epoch 01437: val_loss improved from 2.93179 to 2.92905, saving model to .\\best_model.h5\n",
      "Epoch 1438/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8998 - val_loss: 3.2312\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 2.92905\n",
      "Epoch 1439/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9705 - val_loss: 3.3004\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 2.92905\n",
      "Epoch 1440/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 3.0203\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 2.92905\n",
      "Epoch 1441/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 3.1980\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 2.92905\n",
      "Epoch 1442/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 3.1386\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 2.92905\n",
      "Epoch 1443/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 3.0145\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 2.92905\n",
      "Epoch 1444/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 3.1621\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 2.92905\n",
      "Epoch 1445/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 3.0862\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 2.92905\n",
      "Epoch 1446/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 3.4290\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 2.92905\n",
      "Epoch 1447/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 3.2614\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 2.92905\n",
      "Epoch 1448/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 3.4237\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 2.92905\n",
      "Epoch 1449/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 3.7997\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 2.92905\n",
      "Epoch 1450/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 3.4137\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 2.92905\n",
      "Epoch 1451/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9634 - val_loss: 3.0170\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 2.92905\n",
      "Epoch 1452/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 3.2724\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 2.92905\n",
      "Epoch 1453/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9705 - val_loss: 3.1831\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 2.92905\n",
      "Epoch 1454/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 3.2711\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 2.92905\n",
      "Epoch 1455/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9762 - val_loss: 3.2561\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 2.92905\n",
      "Epoch 1456/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 3.3533\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 2.92905\n",
      "Epoch 1457/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 3.1448\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 2.92905\n",
      "Epoch 1458/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 3.0828\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 2.92905\n",
      "Epoch 1459/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 3.2464\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 2.92905\n",
      "Epoch 1460/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0161 - val_loss: 3.3175\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 2.92905\n",
      "Epoch 1461/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 3.3197\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 2.92905\n",
      "Epoch 1462/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 3.2181\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 2.92905\n",
      "Epoch 1463/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 3.8675\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 2.92905\n",
      "Epoch 1464/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 4.1863\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 2.92905\n",
      "Epoch 1465/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8971 - val_loss: 3.2255\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 2.92905\n",
      "Epoch 1466/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 3.0261\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 2.92905\n",
      "Epoch 1467/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 2.9705\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 2.92905\n",
      "Epoch 1468/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 3.1046\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 2.92905\n",
      "Epoch 1469/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 3.2665\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 2.92905\n",
      "Epoch 1470/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 2.9692\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 2.92905\n",
      "Epoch 1471/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 3.3117\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 2.92905\n",
      "Epoch 1472/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 3.0863\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 2.92905\n",
      "Epoch 1473/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 3.0949\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 2.92905\n",
      "Epoch 1474/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9649 - val_loss: 3.0740\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 2.92905\n",
      "Epoch 1475/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9646 - val_loss: 3.0994\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 2.92905\n",
      "Epoch 1476/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 3.2477\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 2.92905\n",
      "Epoch 1477/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 3.7997\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 2.92905\n",
      "Epoch 1478/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9059 - val_loss: 3.1666\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 2.92905\n",
      "Epoch 1479/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8962 - val_loss: 2.8904\n",
      "\n",
      "Epoch 01479: val_loss improved from 2.92905 to 2.89044, saving model to .\\best_model.h5\n",
      "Epoch 1480/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8936 - val_loss: 3.1493\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 2.89044\n",
      "Epoch 1481/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 3.3641\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 2.89044\n",
      "Epoch 1482/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9149 - val_loss: 3.0668\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 2.89044\n",
      "Epoch 1483/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9085 - val_loss: 3.2388\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 2.89044\n",
      "Epoch 1484/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9068 - val_loss: 3.5790\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 2.89044\n",
      "Epoch 1485/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 3.4447\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 2.89044\n",
      "Epoch 1486/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 3.2085\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 2.89044\n",
      "Epoch 1487/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8918 - val_loss: 3.1469\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 2.89044\n",
      "Epoch 1488/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 3.0101\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 2.89044\n",
      "Epoch 1489/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 3.1752\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 2.89044\n",
      "Epoch 1490/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 4.0102\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 2.89044\n",
      "Epoch 1491/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8950 - val_loss: 3.1160\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 2.89044\n",
      "Epoch 1492/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 3.3585\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 2.89044\n",
      "Epoch 1493/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8736 - val_loss: 3.1422\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 2.89044\n",
      "Epoch 1494/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8867 - val_loss: 3.2145\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 2.89044\n",
      "Epoch 1495/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 3.5619\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 2.89044\n",
      "Epoch 1496/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 3.0681\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 2.89044\n",
      "Epoch 1497/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9076 - val_loss: 3.3268\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 2.89044\n",
      "Epoch 1498/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 2.9898\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 2.89044\n",
      "Epoch 1499/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 2.9261\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 2.89044\n",
      "Epoch 1500/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9584 - val_loss: 2.9941\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 2.89044\n",
      "Epoch 1501/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 3.0354\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 2.89044\n",
      "Epoch 1502/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 3.1507\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 2.89044\n",
      "Epoch 1503/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9217 - val_loss: 2.9900\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 2.89044\n",
      "Epoch 1504/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9550 - val_loss: 4.0191\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 2.89044\n",
      "Epoch 1505/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9504 - val_loss: 3.0195\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 2.89044\n",
      "Epoch 1506/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 2.9865\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 2.89044\n",
      "Epoch 1507/2000\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9235 - val_loss: 2.8927\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 2.89044\n",
      "Epoch 1508/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 3.0364\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 2.89044\n",
      "Epoch 1509/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 3.0535\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 2.89044\n",
      "Epoch 1510/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 3.0975\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 2.89044\n",
      "Epoch 1511/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9832 - val_loss: 3.3817\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 2.89044\n",
      "Epoch 1512/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 3.2536\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 2.89044\n",
      "Epoch 1513/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 3.2392\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 2.89044\n",
      "Epoch 1514/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 3.0890\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 2.89044\n",
      "Epoch 1515/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 3.0473\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 2.89044\n",
      "Epoch 1516/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 3.0960\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 2.89044\n",
      "Epoch 1517/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 3.2400\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 2.89044\n",
      "Epoch 1518/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 3.1112\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 2.89044\n",
      "Epoch 1519/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 2.9316\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 2.89044\n",
      "Epoch 1520/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 2.9443\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 2.89044\n",
      "Epoch 1521/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 2.9950\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 2.89044\n",
      "Epoch 1522/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9103 - val_loss: 2.9603\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 2.89044\n",
      "Epoch 1523/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 3.0287\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 2.89044\n",
      "Epoch 1524/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9079 - val_loss: 3.0345\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 2.89044\n",
      "Epoch 1525/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8972 - val_loss: 3.2504\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 2.89044\n",
      "Epoch 1526/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 3.1304\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 2.89044\n",
      "Epoch 1527/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 3.5775\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 2.89044\n",
      "Epoch 1528/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 3.0717\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 2.89044\n",
      "Epoch 1529/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8879 - val_loss: 3.1696\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 2.89044\n",
      "Epoch 1530/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8979 - val_loss: 3.1864\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 2.89044\n",
      "Epoch 1531/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8734 - val_loss: 3.0189\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 2.89044\n",
      "Epoch 1532/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8835 - val_loss: 3.2743\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 2.89044\n",
      "Epoch 1533/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8813 - val_loss: 3.1555\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 2.89044\n",
      "Epoch 1534/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8572 - val_loss: 3.0685\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 2.89044\n",
      "Epoch 1535/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8593 - val_loss: 3.1279\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 2.89044\n",
      "Epoch 1536/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9156 - val_loss: 3.0818\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 2.89044\n",
      "Epoch 1537/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8819 - val_loss: 3.2376\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 2.89044\n",
      "Epoch 1538/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8529 - val_loss: 3.1379\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 2.89044\n",
      "Epoch 1539/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8466 - val_loss: 3.2022\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 2.89044\n",
      "Epoch 1540/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9080 - val_loss: 3.2221\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 2.89044\n",
      "Epoch 1541/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8921 - val_loss: 3.1261\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 2.89044\n",
      "Epoch 1542/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8414 - val_loss: 3.0023\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 2.89044\n",
      "Epoch 1543/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8653 - val_loss: 3.1075\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 2.89044\n",
      "Epoch 1544/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8941 - val_loss: 2.9120\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 2.89044\n",
      "Epoch 1545/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8348 - val_loss: 3.1808\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 2.89044\n",
      "Epoch 1546/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8134 - val_loss: 3.0796\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 2.89044\n",
      "Epoch 1547/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8745 - val_loss: 2.9369\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 2.89044\n",
      "Epoch 1548/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8288 - val_loss: 2.9223\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 2.89044\n",
      "Epoch 1549/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8561 - val_loss: 2.9564\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 2.89044\n",
      "Epoch 1550/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8559 - val_loss: 3.4710\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 2.89044\n",
      "Epoch 1551/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9029 - val_loss: 3.1709\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 2.89044\n",
      "Epoch 1552/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8831 - val_loss: 3.1557\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 2.89044\n",
      "Epoch 1553/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8216 - val_loss: 3.1901\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 2.89044\n",
      "Epoch 1554/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8693 - val_loss: 3.0088\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 2.89044\n",
      "Epoch 1555/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8703 - val_loss: 3.0049\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 2.89044\n",
      "Epoch 1556/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8970 - val_loss: 2.9161\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 2.89044\n",
      "Epoch 1557/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8889 - val_loss: 3.2621\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 2.89044\n",
      "Epoch 1558/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 2.9548\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 2.89044\n",
      "Epoch 1559/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8658 - val_loss: 3.0465\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 2.89044\n",
      "Epoch 1560/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8911 - val_loss: 2.9891\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 2.89044\n",
      "Epoch 1561/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8593 - val_loss: 3.0593\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 2.89044\n",
      "Epoch 1562/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8821 - val_loss: 2.9395\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 2.89044\n",
      "Epoch 1563/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8804 - val_loss: 3.0435\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 2.89044\n",
      "Epoch 1564/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8670 - val_loss: 2.9754\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 2.89044\n",
      "Epoch 1565/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 2.9986\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 2.89044\n",
      "Epoch 1566/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9025 - val_loss: 2.8947\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 2.89044\n",
      "Epoch 1567/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8733 - val_loss: 2.8742\n",
      "\n",
      "Epoch 01567: val_loss improved from 2.89044 to 2.87420, saving model to .\\best_model.h5\n",
      "Epoch 1568/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8817 - val_loss: 3.1389\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 2.87420\n",
      "Epoch 1569/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8718 - val_loss: 3.6174\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 2.87420\n",
      "Epoch 1570/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 3.0717\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 2.87420\n",
      "Epoch 1571/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8873 - val_loss: 3.0991\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 2.87420\n",
      "Epoch 1572/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8801 - val_loss: 3.3269\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 2.87420\n",
      "Epoch 1573/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8860 - val_loss: 3.9006\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 2.87420\n",
      "Epoch 1574/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8902 - val_loss: 3.6237\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 2.87420\n",
      "Epoch 1575/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 3.2652\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 2.87420\n",
      "Epoch 1576/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9060 - val_loss: 3.0174\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 2.87420\n",
      "Epoch 1577/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 3.2487\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 2.87420\n",
      "Epoch 1578/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 3.3004\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 2.87420\n",
      "Epoch 1579/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8956 - val_loss: 3.7094\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 2.87420\n",
      "Epoch 1580/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8785 - val_loss: 3.0359\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 2.87420\n",
      "Epoch 1581/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8867 - val_loss: 3.1322\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 2.87420\n",
      "Epoch 1582/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8756 - val_loss: 3.4003\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 2.87420\n",
      "Epoch 1583/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8983 - val_loss: 2.9953\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 2.87420\n",
      "Epoch 1584/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9034 - val_loss: 3.0536\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 2.87420\n",
      "Epoch 1585/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8810 - val_loss: 3.1140\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 2.87420\n",
      "Epoch 1586/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9090 - val_loss: 3.1039\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 2.87420\n",
      "Epoch 1587/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8799 - val_loss: 3.1814\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 2.87420\n",
      "Epoch 1588/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9043 - val_loss: 3.1330\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 2.87420\n",
      "Epoch 1589/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9122 - val_loss: 3.0956\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 2.87420\n",
      "Epoch 1590/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 3.1528\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 2.87420\n",
      "Epoch 1591/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 3.0164\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 2.87420\n",
      "Epoch 1592/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 3.0191\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 2.87420\n",
      "Epoch 1593/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 3.1235\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 2.87420\n",
      "Epoch 1594/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 3.0444\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 2.87420\n",
      "Epoch 1595/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8965 - val_loss: 3.0913\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 2.87420\n",
      "Epoch 1596/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8799 - val_loss: 3.2991\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 2.87420\n",
      "Epoch 1597/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8918 - val_loss: 2.8960\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 2.87420\n",
      "Epoch 1598/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8843 - val_loss: 3.4786\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 2.87420\n",
      "Epoch 1599/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8303 - val_loss: 3.3984\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 2.87420\n",
      "Epoch 1600/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8765 - val_loss: 3.2843\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 2.87420\n",
      "Epoch 1601/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8658 - val_loss: 3.3452\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 2.87420\n",
      "Epoch 1602/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8836 - val_loss: 3.2734\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 2.87420\n",
      "Epoch 1603/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 3.1920\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 2.87420\n",
      "Epoch 1604/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9025 - val_loss: 3.3489\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 2.87420\n",
      "Epoch 1605/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8789 - val_loss: 3.1470\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 2.87420\n",
      "Epoch 1606/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8623 - val_loss: 3.1960\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 2.87420\n",
      "Epoch 1607/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8462 - val_loss: 3.5102\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 2.87420\n",
      "Epoch 1608/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8553 - val_loss: 3.2856\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 2.87420\n",
      "Epoch 1609/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 3.3182\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 2.87420\n",
      "Epoch 1610/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8688 - val_loss: 3.0634\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 2.87420\n",
      "Epoch 1611/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8582 - val_loss: 3.1982\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 2.87420\n",
      "Epoch 1612/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8717 - val_loss: 3.1343\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 2.87420\n",
      "Epoch 1613/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8936 - val_loss: 3.1138\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 2.87420\n",
      "Epoch 1614/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8322 - val_loss: 3.7376\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 2.87420\n",
      "Epoch 1615/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8455 - val_loss: 2.9716\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 2.87420\n",
      "Epoch 1616/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8644 - val_loss: 3.0123\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 2.87420\n",
      "Epoch 1617/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8696 - val_loss: 3.1052\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 2.87420\n",
      "Epoch 1618/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8673 - val_loss: 3.0158\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 2.87420\n",
      "Epoch 1619/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8529 - val_loss: 3.0669\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 2.87420\n",
      "Epoch 1620/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9073 - val_loss: 3.0273\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 2.87420\n",
      "Epoch 1621/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8529 - val_loss: 3.1702\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 2.87420\n",
      "Epoch 1622/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8448 - val_loss: 3.1536\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 2.87420\n",
      "Epoch 1623/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8577 - val_loss: 3.1348\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 2.87420\n",
      "Epoch 1624/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8648 - val_loss: 3.5262\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 2.87420\n",
      "Epoch 1625/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8676 - val_loss: 3.2813\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 2.87420\n",
      "Epoch 1626/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8551 - val_loss: 3.0311\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 2.87420\n",
      "Epoch 1627/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8574 - val_loss: 3.1613\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 2.87420\n",
      "Epoch 1628/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8868 - val_loss: 3.1405\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 2.87420\n",
      "Epoch 1629/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8861 - val_loss: 3.6282\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 2.87420\n",
      "Epoch 1630/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8659 - val_loss: 3.2249\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 2.87420\n",
      "Epoch 1631/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 3.4678\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 2.87420\n",
      "Epoch 1632/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8676 - val_loss: 3.0576\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 2.87420\n",
      "Epoch 1633/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8718 - val_loss: 3.2358\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 2.87420\n",
      "Epoch 1634/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8894 - val_loss: 3.7780\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 2.87420\n",
      "Epoch 1635/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8921 - val_loss: 3.0434\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 2.87420\n",
      "Epoch 1636/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8699 - val_loss: 3.0507\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 2.87420\n",
      "Epoch 1637/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 3.2199\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 2.87420\n",
      "Epoch 1638/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 3.1074\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 2.87420\n",
      "Epoch 1639/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8667 - val_loss: 3.2262\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 2.87420\n",
      "Epoch 1640/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9094 - val_loss: 3.2981\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 2.87420\n",
      "Epoch 1641/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 3.7026\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 2.87420\n",
      "Epoch 1642/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 3.6596\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 2.87420\n",
      "Epoch 1643/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9079 - val_loss: 3.6784\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 2.87420\n",
      "Epoch 1644/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8780 - val_loss: 3.1852\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 2.87420\n",
      "Epoch 1645/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8820 - val_loss: 3.1160\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 2.87420\n",
      "Epoch 1646/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8793 - val_loss: 3.3860\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 2.87420\n",
      "Epoch 1647/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 3.1135\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 2.87420\n",
      "Epoch 1648/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8937 - val_loss: 3.1009\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 2.87420\n",
      "Epoch 1649/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 3.1343\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 2.87420\n",
      "Epoch 1650/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9024 - val_loss: 3.2141\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 2.87420\n",
      "Epoch 1651/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8776 - val_loss: 3.1124\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 2.87420\n",
      "Epoch 1652/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9020 - val_loss: 3.0466\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 2.87420\n",
      "Epoch 1653/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9094 - val_loss: 3.3403\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 2.87420\n",
      "Epoch 1654/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8886 - val_loss: 3.6436\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 2.87420\n",
      "Epoch 1655/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8860 - val_loss: 3.2646\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 2.87420\n",
      "Epoch 1656/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 3.2387\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 2.87420\n",
      "Epoch 1657/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 4.5773\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 2.87420\n",
      "Epoch 1658/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 4.1987\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 2.87420\n",
      "Epoch 1659/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8681 - val_loss: 3.1586\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 2.87420\n",
      "Epoch 1660/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8692 - val_loss: 3.3469\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 2.87420\n",
      "Epoch 1661/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8828 - val_loss: 3.8597\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 2.87420\n",
      "Epoch 1662/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8840 - val_loss: 3.7524\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 2.87420\n",
      "Epoch 1663/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8973 - val_loss: 3.5265\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 2.87420\n",
      "Epoch 1664/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 3.8316\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 2.87420\n",
      "Epoch 1665/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8902 - val_loss: 3.2210\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 2.87420\n",
      "Epoch 1666/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9044 - val_loss: 3.3224\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 2.87420\n",
      "Epoch 1667/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9030 - val_loss: 3.5584\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 2.87420\n",
      "Epoch 1668/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8818 - val_loss: 3.4559\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 2.87420\n",
      "Epoch 1669/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 3.4753\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 2.87420\n",
      "Epoch 1670/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9107 - val_loss: 3.4873\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 2.87420\n",
      "Epoch 1671/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8922 - val_loss: 3.7990\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 2.87420\n",
      "Epoch 1672/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8519 - val_loss: 3.2100\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 2.87420\n",
      "Epoch 1673/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 3.2442\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 2.87420\n",
      "Epoch 1674/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8898 - val_loss: 3.0662\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 2.87420\n",
      "Epoch 1675/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8812 - val_loss: 3.4194\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 2.87420\n",
      "Epoch 1676/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8960 - val_loss: 3.4491\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 2.87420\n",
      "Epoch 1677/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8698 - val_loss: 3.1969\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 2.87420\n",
      "Epoch 1678/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8687 - val_loss: 3.5201\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 2.87420\n",
      "Epoch 1679/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8734 - val_loss: 3.9182\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 2.87420\n",
      "Epoch 1680/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 3.5607\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 2.87420\n",
      "Epoch 1681/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 3.5130\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 2.87420\n",
      "Epoch 1682/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9119 - val_loss: 3.4593\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 2.87420\n",
      "Epoch 1683/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 3.1427\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 2.87420\n",
      "Epoch 1684/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8780 - val_loss: 3.5928\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 2.87420\n",
      "Epoch 1685/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 3.3043\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 2.87420\n",
      "Epoch 1686/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8791 - val_loss: 3.5033\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 2.87420\n",
      "Epoch 1687/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8567 - val_loss: 3.4154\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 2.87420\n",
      "Epoch 1688/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 3.0661\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 2.87420\n",
      "Epoch 1689/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 3.1826\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 2.87420\n",
      "Epoch 1690/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8862 - val_loss: 3.1996\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 2.87420\n",
      "Epoch 1691/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8680 - val_loss: 4.1323\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 2.87420\n",
      "Epoch 1692/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9044 - val_loss: 3.0472\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 2.87420\n",
      "Epoch 1693/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8858 - val_loss: 3.2582\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 2.87420\n",
      "Epoch 1694/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8952 - val_loss: 4.4337\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 2.87420\n",
      "Epoch 1695/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 3.2424\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 2.87420\n",
      "Epoch 1696/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 3.0562\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 2.87420\n",
      "Epoch 1697/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8996 - val_loss: 3.1411\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 2.87420\n",
      "Epoch 1698/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8700 - val_loss: 3.5075\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 2.87420\n",
      "Epoch 1699/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 3.2288\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 2.87420\n",
      "Epoch 1700/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 3.0841\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 2.87420\n",
      "Epoch 1701/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 3.0377\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 2.87420\n",
      "Epoch 1702/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 3.1385\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 2.87420\n",
      "Epoch 1703/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 3.2959\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 2.87420\n",
      "Epoch 1704/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 3.0566\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 2.87420\n",
      "Epoch 1705/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 3.1419\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 2.87420\n",
      "Epoch 1706/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 3.7137\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 2.87420\n",
      "Epoch 1707/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9660 - val_loss: 4.0663\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 2.87420\n",
      "Epoch 1708/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9028 - val_loss: 3.5134\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 2.87420\n",
      "Epoch 1709/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8949 - val_loss: 3.4542\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 2.87420\n",
      "Epoch 1710/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9790 - val_loss: 3.2500\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 2.87420\n",
      "Epoch 1711/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 3.3661\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 2.87420\n",
      "Epoch 1712/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 3.3272\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 2.87420\n",
      "Epoch 1713/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9111 - val_loss: 3.5856\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 2.87420\n",
      "Epoch 1714/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8970 - val_loss: 4.4348\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 2.87420\n",
      "Epoch 1715/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 3.5648\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 2.87420\n",
      "Epoch 1716/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8989 - val_loss: 3.9218\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 2.87420\n",
      "Epoch 1717/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9006 - val_loss: 3.7494\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 2.87420\n",
      "Epoch 1718/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9076 - val_loss: 3.6161\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 2.87420\n",
      "Epoch 1719/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9079 - val_loss: 3.2784\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 2.87420\n",
      "Epoch 1720/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 3.8406\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 2.87420\n",
      "Epoch 1721/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 3.2420\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 2.87420\n",
      "Epoch 1722/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 3.7022\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 2.87420\n",
      "Epoch 1723/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8913 - val_loss: 3.1660\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 2.87420\n",
      "Epoch 1724/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8962 - val_loss: 3.5606\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 2.87420\n",
      "Epoch 1725/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9018 - val_loss: 3.9801\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 2.87420\n",
      "Epoch 1726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 2.9380\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 2.87420\n",
      "Epoch 1727/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 3.3347\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 2.87420\n",
      "Epoch 1728/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 3.6877\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 2.87420\n",
      "Epoch 1729/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 3.0565\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 2.87420\n",
      "Epoch 1730/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 3.1323\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 2.87420\n",
      "Epoch 1731/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 2.9179\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 2.87420\n",
      "Epoch 1732/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 3.6690\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 2.87420\n",
      "Epoch 1733/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 3.6465\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 2.87420\n",
      "Epoch 1734/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 3.7137\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 2.87420\n",
      "Epoch 1735/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 3.3220\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 2.87420\n",
      "Epoch 1736/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 3.3930\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 2.87420\n",
      "Epoch 1737/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 3.3639\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 2.87420\n",
      "Epoch 1738/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9056 - val_loss: 3.1707\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 2.87420\n",
      "Epoch 1739/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9137 - val_loss: 3.0317\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 2.87420\n",
      "Epoch 1740/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 3.0738\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 2.87420\n",
      "Epoch 1741/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 3.0908\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 2.87420\n",
      "Epoch 1742/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 3.1947\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 2.87420\n",
      "Epoch 1743/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8959 - val_loss: 3.0667\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 2.87420\n",
      "Epoch 1744/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9089 - val_loss: 3.0511\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 2.87420\n",
      "Epoch 1745/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 2.9981\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 2.87420\n",
      "Epoch 1746/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 3.0952\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 2.87420\n",
      "Epoch 1747/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 3.0230\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 2.87420\n",
      "Epoch 1748/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8944 - val_loss: 2.9974\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 2.87420\n",
      "Epoch 1749/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9122 - val_loss: 2.9536\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 2.87420\n",
      "Epoch 1750/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 2.9391\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 2.87420\n",
      "Epoch 1751/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 2.9139\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 2.87420\n",
      "Epoch 1752/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 3.0362\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 2.87420\n",
      "Epoch 1753/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 2.9179\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 2.87420\n",
      "Epoch 1754/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8963 - val_loss: 3.0326\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 2.87420\n",
      "Epoch 1755/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 3.1024\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 2.87420\n",
      "Epoch 1756/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 3.0972\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 2.87420\n",
      "Epoch 1757/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 3.0424\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 2.87420\n",
      "Epoch 1758/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 3.0038\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 2.87420\n",
      "Epoch 1759/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 3.3764\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 2.87420\n",
      "Epoch 1760/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9110 - val_loss: 3.2112\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 2.87420\n",
      "Epoch 1761/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 2.9820\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 2.87420\n",
      "Epoch 1762/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9142 - val_loss: 3.5790\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 2.87420\n",
      "Epoch 1763/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 2.9917\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 2.87420\n",
      "Epoch 1764/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9748 - val_loss: 3.2015\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 2.87420\n",
      "Epoch 1765/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8894 - val_loss: 3.3018\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 2.87420\n",
      "Epoch 1766/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9084 - val_loss: 3.0415\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 2.87420\n",
      "Epoch 1767/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 3.1285\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 2.87420\n",
      "Epoch 1768/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8929 - val_loss: 2.9627\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 2.87420\n",
      "Epoch 1769/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 3.0752\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 2.87420\n",
      "Epoch 1770/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8984 - val_loss: 3.6200\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 2.87420\n",
      "Epoch 1771/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 3.9680\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 2.87420\n",
      "Epoch 1772/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 3.0505\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 2.87420\n",
      "Epoch 1773/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 3.0424\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 2.87420\n",
      "Epoch 1774/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9100 - val_loss: 3.0057\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 2.87420\n",
      "Epoch 1775/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8910 - val_loss: 3.1220\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 2.87420\n",
      "Epoch 1776/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 3.0530\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 2.87420\n",
      "Epoch 1777/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8886 - val_loss: 2.9604\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 2.87420\n",
      "Epoch 1778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8616 - val_loss: 3.0470\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 2.87420\n",
      "Epoch 1779/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9095 - val_loss: 3.0298\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 2.87420\n",
      "Epoch 1780/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8898 - val_loss: 3.0508\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 2.87420\n",
      "Epoch 1781/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8980 - val_loss: 3.0960\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 2.87420\n",
      "Epoch 1782/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 3.0517\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 2.87420\n",
      "Epoch 1783/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 3.1283\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 2.87420\n",
      "Epoch 1784/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8917 - val_loss: 3.1462\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 2.87420\n",
      "Epoch 1785/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8977 - val_loss: 3.1956\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 2.87420\n",
      "Epoch 1786/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8955 - val_loss: 3.1331\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 2.87420\n",
      "Epoch 1787/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8987 - val_loss: 3.0984\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 2.87420\n",
      "Epoch 1788/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9315 - val_loss: 3.1275\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 2.87420\n",
      "Epoch 1789/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8930 - val_loss: 3.2358\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 2.87420\n",
      "Epoch 1790/2000\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.920 - 0s 2ms/step - loss: 0.9375 - val_loss: 3.0981\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 2.87420\n",
      "Epoch 1791/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9018 - val_loss: 3.2208\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 2.87420\n",
      "Epoch 1792/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 3.1185\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 2.87420\n",
      "Epoch 1793/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8987 - val_loss: 3.2016\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 2.87420\n",
      "Epoch 1794/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9145 - val_loss: 2.9778\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 2.87420\n",
      "Epoch 1795/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 3.4587\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 2.87420\n",
      "Epoch 1796/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8666 - val_loss: 3.3599\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 2.87420\n",
      "Epoch 1797/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9075 - val_loss: 2.9173\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 2.87420\n",
      "Epoch 1798/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 3.0051\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 2.87420\n",
      "Epoch 1799/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 3.1774\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 2.87420\n",
      "Epoch 1800/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8989 - val_loss: 3.1331\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 2.87420\n",
      "Epoch 1801/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 3.0625\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 2.87420\n",
      "Epoch 1802/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9078 - val_loss: 3.1131\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 2.87420\n",
      "Epoch 1803/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8837 - val_loss: 3.2743\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 2.87420\n",
      "Epoch 1804/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8811 - val_loss: 3.2723\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 2.87420\n",
      "Epoch 1805/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 3.3724\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 2.87420\n",
      "Epoch 1806/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 3.6119\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 2.87420\n",
      "Epoch 1807/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9108 - val_loss: 3.2660\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 2.87420\n",
      "Epoch 1808/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9030 - val_loss: 3.2966\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 2.87420\n",
      "Epoch 1809/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9055 - val_loss: 3.3360\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 2.87420\n",
      "Epoch 1810/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9086 - val_loss: 3.1478\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 2.87420\n",
      "Epoch 1811/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 3.2679\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 2.87420\n",
      "Epoch 1812/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 3.2077\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 2.87420\n",
      "Epoch 1813/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 3.9643\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 2.87420\n",
      "Epoch 1814/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9086 - val_loss: 3.0774\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 2.87420\n",
      "Epoch 1815/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8831 - val_loss: 3.5629\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 2.87420\n",
      "Epoch 1816/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 3.4230\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 2.87420\n",
      "Epoch 1817/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9060 - val_loss: 3.0125\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 2.87420\n",
      "Epoch 1818/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 4.1184\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 2.87420\n",
      "Epoch 1819/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9101 - val_loss: 3.1478\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 2.87420\n",
      "Epoch 1820/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 3.4714\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 2.87420\n",
      "Epoch 1821/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9003 - val_loss: 3.2384\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 2.87420\n",
      "Epoch 1822/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 3.3504\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 2.87420\n",
      "Epoch 1823/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 3.7518\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 2.87420\n",
      "Epoch 1824/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9084 - val_loss: 2.9875\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 2.87420\n",
      "Epoch 1825/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 3.1687\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 2.87420\n",
      "Epoch 1826/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9807 - val_loss: 3.7285\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 2.87420\n",
      "Epoch 1827/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 3.4631\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 2.87420\n",
      "Epoch 1828/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8891 - val_loss: 3.0709\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 2.87420\n",
      "Epoch 1829/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9087 - val_loss: 4.4716\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 2.87420\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 3.1802\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 2.87420\n",
      "Epoch 1831/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 3.2528\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 2.87420\n",
      "Epoch 1832/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 3.0735\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 2.87420\n",
      "Epoch 1833/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 3.2763\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 2.87420\n",
      "Epoch 1834/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9773 - val_loss: 3.4457\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 2.87420\n",
      "Epoch 1835/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 3.2792\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 2.87420\n",
      "Epoch 1836/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 3.6435\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 2.87420\n",
      "Epoch 1837/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9428 - val_loss: 3.4186\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 2.87420\n",
      "Epoch 1838/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 3.5539\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 2.87420\n",
      "Epoch 1839/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9055 - val_loss: 3.4614\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 2.87420\n",
      "Epoch 1840/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9361 - val_loss: 4.2193\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 2.87420\n",
      "Epoch 1841/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9690 - val_loss: 3.1374\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 2.87420\n",
      "Epoch 1842/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 3.3950\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 2.87420\n",
      "Epoch 1843/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 3.6741\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 2.87420\n",
      "Epoch 1844/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9061 - val_loss: 3.1872\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 2.87420\n",
      "Epoch 1845/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9000 - val_loss: 3.2906\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 2.87420\n",
      "Epoch 1846/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9706 - val_loss: 3.2175\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 2.87420\n",
      "Epoch 1847/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9084 - val_loss: 3.2781\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 2.87420\n",
      "Epoch 1848/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 3.3915\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 2.87420\n",
      "Epoch 1849/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 3.7380\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 2.87420\n",
      "Epoch 1850/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 3.5591\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 2.87420\n",
      "Epoch 1851/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8970 - val_loss: 4.0397\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 2.87420\n",
      "Epoch 1852/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 4.5036\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 2.87420\n",
      "Epoch 1853/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8941 - val_loss: 3.5002\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 2.87420\n",
      "Epoch 1854/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8861 - val_loss: 3.1045\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 2.87420\n",
      "Epoch 1855/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 3.6922\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 2.87420\n",
      "Epoch 1856/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8953 - val_loss: 3.1718\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 2.87420\n",
      "Epoch 1857/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8752 - val_loss: 3.2899\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 2.87420\n",
      "Epoch 1858/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 3.5669\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 2.87420\n",
      "Epoch 1859/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9762 - val_loss: 3.0436\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 2.87420\n",
      "Epoch 1860/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 3.4923\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 2.87420\n",
      "Epoch 1861/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9085 - val_loss: 3.2435\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 2.87420\n",
      "Epoch 1862/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9130 - val_loss: 3.3038\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 2.87420\n",
      "Epoch 1863/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 3.2879\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 2.87420\n",
      "Epoch 1864/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9130 - val_loss: 3.2959\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 2.87420\n",
      "Epoch 1865/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 3.0863\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 2.87420\n",
      "Epoch 1866/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8955 - val_loss: 3.3312\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 2.87420\n",
      "Epoch 1867/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8877 - val_loss: 3.0756\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 2.87420\n",
      "Epoch 1868/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9015 - val_loss: 3.4159\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 2.87420\n",
      "Epoch 1869/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 3.2532\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 2.87420\n",
      "Epoch 1870/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9068 - val_loss: 3.1371\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 2.87420\n",
      "Epoch 1871/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 3.6430\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 2.87420\n",
      "Epoch 1872/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8879 - val_loss: 3.3224\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 2.87420\n",
      "Epoch 1873/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 3.2800\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 2.87420\n",
      "Epoch 1874/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 3.1822\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 2.87420\n",
      "Epoch 1875/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 3.2302\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 2.87420\n",
      "Epoch 1876/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 3.2828\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 2.87420\n",
      "Epoch 1877/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9117 - val_loss: 3.3649\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 2.87420\n",
      "Epoch 1878/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 3.2501\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 2.87420\n",
      "Epoch 1879/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9111 - val_loss: 3.2771\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 2.87420\n",
      "Epoch 1880/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 3.1602\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 2.87420\n",
      "Epoch 1881/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 3.1322\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 2.87420\n",
      "Epoch 1882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8861 - val_loss: 3.0827\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 2.87420\n",
      "Epoch 1883/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 3.2288\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 2.87420\n",
      "Epoch 1884/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 3.1790\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 2.87420\n",
      "Epoch 1885/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 3.2682\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 2.87420\n",
      "Epoch 1886/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8868 - val_loss: 3.6723\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 2.87420\n",
      "Epoch 1887/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 3.2627\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 2.87420\n",
      "Epoch 1888/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9091 - val_loss: 3.3460\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 2.87420\n",
      "Epoch 1889/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8807 - val_loss: 3.8355\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 2.87420\n",
      "Epoch 1890/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 3.5513\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 2.87420\n",
      "Epoch 1891/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 3.8027\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 2.87420\n",
      "Epoch 1892/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 3.2351\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 2.87420\n",
      "Epoch 1893/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9095 - val_loss: 3.4442\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 2.87420\n",
      "Epoch 1894/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 3.1857\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 2.87420\n",
      "Epoch 1895/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8880 - val_loss: 3.2586\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 2.87420\n",
      "Epoch 1896/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9061 - val_loss: 3.3148\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 2.87420\n",
      "Epoch 1897/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8909 - val_loss: 3.1746\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 2.87420\n",
      "Epoch 1898/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8768 - val_loss: 3.3802\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 2.87420\n",
      "Epoch 1899/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 3.5083\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 2.87420\n",
      "Epoch 1900/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 3.4102\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 2.87420\n",
      "Epoch 1901/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9100 - val_loss: 3.1122\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 2.87420\n",
      "Epoch 1902/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 3.2364\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 2.87420\n",
      "Epoch 1903/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 3.3189\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 2.87420\n",
      "Epoch 1904/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 3.6551\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 2.87420\n",
      "Epoch 1905/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 3.3485\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 2.87420\n",
      "Epoch 1906/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8999 - val_loss: 3.3175\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 2.87420\n",
      "Epoch 1907/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9138 - val_loss: 3.5697\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 2.87420\n",
      "Epoch 1908/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 3.2517\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 2.87420\n",
      "Epoch 1909/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 3.3304\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 2.87420\n",
      "Epoch 1910/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9110 - val_loss: 3.6939\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 2.87420\n",
      "Epoch 1911/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 3.3766\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 2.87420\n",
      "Epoch 1912/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 3.4306\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 2.87420\n",
      "Epoch 1913/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9023 - val_loss: 3.6507\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 2.87420\n",
      "Epoch 1914/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 3.0889\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 2.87420\n",
      "Epoch 1915/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 3.1269\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 2.87420\n",
      "Epoch 1916/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9072 - val_loss: 3.7200\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 2.87420\n",
      "Epoch 1917/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9070 - val_loss: 3.3473\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 2.87420\n",
      "Epoch 1918/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 3.6101\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 2.87420\n",
      "Epoch 1919/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8870 - val_loss: 3.3431\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 2.87420\n",
      "Epoch 1920/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 3.4632\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 2.87420\n",
      "Epoch 1921/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8705 - val_loss: 3.3402\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 2.87420\n",
      "Epoch 1922/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 3.3726\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 2.87420\n",
      "Epoch 1923/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9065 - val_loss: 3.1931\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 2.87420\n",
      "Epoch 1924/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 3.6072\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 2.87420\n",
      "Epoch 1925/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 3.2480\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 2.87420\n",
      "Epoch 1926/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 3.2701\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 2.87420\n",
      "Epoch 1927/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 3.7123\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 2.87420\n",
      "Epoch 1928/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 3.4432\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 2.87420\n",
      "Epoch 1929/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9064 - val_loss: 3.2283\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 2.87420\n",
      "Epoch 1930/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 3.4124\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 2.87420\n",
      "Epoch 1931/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9584 - val_loss: 3.0571\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 2.87420\n",
      "Epoch 1932/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9574 - val_loss: 3.4266\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 2.87420\n",
      "Epoch 1933/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 3.2848\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 2.87420\n",
      "Epoch 1934/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 3.3200\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 2.87420\n",
      "Epoch 1935/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 3.4028\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 2.87420\n",
      "Epoch 1936/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 3.2399\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 2.87420\n",
      "Epoch 1937/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9086 - val_loss: 3.3508\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 2.87420\n",
      "Epoch 1938/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 3.6817\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 2.87420\n",
      "Epoch 1939/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9632 - val_loss: 3.2372\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 2.87420\n",
      "Epoch 1940/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 3.4218\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 2.87420\n",
      "Epoch 1941/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9107 - val_loss: 3.3238\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 2.87420\n",
      "Epoch 1942/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 3.2733\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 2.87420\n",
      "Epoch 1943/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 3.1710\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 2.87420\n",
      "Epoch 1944/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8967 - val_loss: 3.4065\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 2.87420\n",
      "Epoch 1945/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 3.3648\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 2.87420\n",
      "Epoch 1946/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 3.8399\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 2.87420\n",
      "Epoch 1947/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 3.3131\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 2.87420\n",
      "Epoch 1948/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 3.3338\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 2.87420\n",
      "Epoch 1949/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 3.2905\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 2.87420\n",
      "Epoch 1950/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 3.3479\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 2.87420\n",
      "Epoch 1951/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9147 - val_loss: 3.2684\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 2.87420\n",
      "Epoch 1952/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8650 - val_loss: 3.3578\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 2.87420\n",
      "Epoch 1953/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8683 - val_loss: 3.5361\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 2.87420\n",
      "Epoch 1954/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8998 - val_loss: 3.2535\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 2.87420\n",
      "Epoch 1955/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 3.3001\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 2.87420\n",
      "Epoch 1956/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 3.3072\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 2.87420\n",
      "Epoch 1957/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 3.6947\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 2.87420\n",
      "Epoch 1958/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 3.6490\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 2.87420\n",
      "Epoch 1959/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 3.2836\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 2.87420\n",
      "Epoch 1960/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8905 - val_loss: 3.4704\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 2.87420\n",
      "Epoch 1961/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 3.6445\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 2.87420\n",
      "Epoch 1962/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 3.5356\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 2.87420\n",
      "Epoch 1963/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8963 - val_loss: 3.3060\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 2.87420\n",
      "Epoch 1964/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8984 - val_loss: 3.3371\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 2.87420\n",
      "Epoch 1965/2000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8991 - val_loss: 3.6887\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 2.87420\n",
      "Epoch 1966/2000\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.9260 - val_loss: 3.7530\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 2.87420\n",
      "Epoch 1967/2000\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8814 - val_loss: 3.4861\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 2.87420\n",
      "Epoch 1968/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8888 - val_loss: 3.7958\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 2.87420\n",
      "Epoch 1969/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8769 - val_loss: 3.3798\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 2.87420\n",
      "Epoch 1970/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8905 - val_loss: 3.5387\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 2.87420\n",
      "Epoch 1971/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9111 - val_loss: 3.2869\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 2.87420\n",
      "Epoch 1972/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9138 - val_loss: 3.3062\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 2.87420\n",
      "Epoch 1973/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9613 - val_loss: 3.2865\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 2.87420\n",
      "Epoch 1974/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 3.9177\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 2.87420\n",
      "Epoch 1975/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9664 - val_loss: 3.4065\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 2.87420\n",
      "Epoch 1976/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 3.2958\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 2.87420\n",
      "Epoch 1977/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 3.3353\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 2.87420\n",
      "Epoch 1978/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 3.3828\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 2.87420\n",
      "Epoch 1979/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 3.6048\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 2.87420\n",
      "Epoch 1980/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8810 - val_loss: 3.3213\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 2.87420\n",
      "Epoch 1981/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8904 - val_loss: 3.2379\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 2.87420\n",
      "Epoch 1982/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9105 - val_loss: 3.2729\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 2.87420\n",
      "Epoch 1983/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 3.8123\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 2.87420\n",
      "Epoch 1984/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8935 - val_loss: 3.8249\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 2.87420\n",
      "Epoch 1985/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8783 - val_loss: 3.6148\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 2.87420\n",
      "Epoch 1986/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 3.3808\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 2.87420\n",
      "Epoch 1987/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9037 - val_loss: 3.3928\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 2.87420\n",
      "Epoch 1988/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8808 - val_loss: 3.2286\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 2.87420\n",
      "Epoch 1989/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8949 - val_loss: 3.3897\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 2.87420\n",
      "Epoch 1990/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 3.6045\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 2.87420\n",
      "Epoch 1991/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9035 - val_loss: 3.1608\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 2.87420\n",
      "Epoch 1992/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 3.5128\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 2.87420\n",
      "Epoch 1993/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 3.4817\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 2.87420\n",
      "Epoch 1994/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8953 - val_loss: 3.3041\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 2.87420\n",
      "Epoch 1995/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 3.2070\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 2.87420\n",
      "Epoch 1996/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 3.3502\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 2.87420\n",
      "Epoch 1997/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9003 - val_loss: 3.3389\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 2.87420\n",
      "Epoch 1998/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8884 - val_loss: 3.1106\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 2.87420\n",
      "Epoch 1999/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 3.1495\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 2.87420\n",
      "Epoch 2000/2000\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8976 - val_loss: 3.2354\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 2.87420\n"
     ]
    }
   ],
   "source": [
    "history = Imitation_model.fit(\n",
    "    input_scaled, \n",
    "    output_scaled,\n",
    "    epochs=2000,\n",
    "    verbose=1,\n",
    "    #validation_split=0.2,\n",
    "    callbacks=my_callback,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to file\n",
    "#Imitation_model.save(\"Imitation_model\",'./')\n",
    "Imitation_model = tf.keras.models.load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.254400951306768"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_scaled = Imitation_model.predict(input_scaler.transform(x_test))\n",
    "y_hat = output_scaler.inverse_transform(y_hat_scaled)\n",
    "\n",
    "sklearn.metrics.r2_score(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2ZklEQVR4nO3df3gT15kv8O+RMJifjpHdBGODYrvgpMTEAezEhMJClk1KkoZsu7sloTVJCGFDaZd2NwG62+d2G5Ld7bL34SbLDzeFPAS6m3sX0gaHhBSK4+DGNsRBhcZQyzEYbKhsHAEGgy2d+4c0QrIleWSkmZH0/TwPD9ZImnk1GunVnHnPOUJKCSIiIqMx6R0AERFRMExQRERkSExQRERkSExQRERkSExQRERkSEP0DiASGRkZ0mq16h0GERFF0ZEjR9qllJl9l8dVgrJarTh8+LDeYRARURQJIU4FW84mPiIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIKa1OlHdX29oBl1fZ2bKq06xRR7Bn1NRs1rlhhgtJQ2dZalFcFHkjlVXaUba3VKSKigRVmp2HFznrfF2O1vR0rdtajMDtN58hix6ivee+xNjzzxuGAuJ554zD2HmvTNa5YiauOuvFuZr4F6yoaAABLZ+WhvMqOdRUNWLOgQOfIiEIrzcvAq4uKsGJnPZ4smYA3a07j1UVFKM3L0Du0mDHqa7aMHIqj11145o3DeOb+2/Hzjz7HlesuWEYO1TWuWGGC0tDSWXkAgHUVDfjg+HnUNXdizYIC33IioyrNy8CTJROw4UAjVs7N1/2LWgtGfM3PzMrF7+wduHLdhQ0HGgEAw1NMeGZWrs6RxQab+DS2dFYeZljTUdvciRnWdCYnigvV9na8WXMaK+fm482a0/2ugyQiI75m2xknHr9nfMCyx+8ZD9sZp04RxRYTlIY2VdqxdrcNdc2dKLamo665E2t32xL2AiclBuX6y6uLirBq/mRf05cRvrBjxaivufbzDuyoaQlYtqOmBbWfd+gUUWwxQWmo5UIXdtS0YFFJDt56rhSLSnKwo6YFLRe69A6NKCTbGWfA9Rfl+kyi/moHjPuaL3Rd9/1dbE0PujyR8BqUhn5nv4B5BZnYe+w8LCNPYO+x85hXkInf2S/oHRpRSM/N7t8MXZqXYYhrMrFi1NcsAQw1CwBAbXOn72+pY0yxxDMoDf104RTUtzgxe1IGNhxoxOxJGahvceKnC6foHRoRxYH0EUPxzenZMJk8iclkEvjm9Gykj0jMKj4mKA2V5mVg+ZxcvF3fimJrOt6ub8XyObm6/yojovgwM9+CnTUtEABWzs2HALCzpgUz8y16hxYTTFAaqra3Y+PBJjxWNB61zZ14rGg8Nh5s0v3CKxHFhyZHF1JTTBhi9nx1DzGbkJpiQpMjMa9jM0FpyHbGieVzclF50oGVc/NRedKB5XNydb/wSmR0yTbETyhtzm6smj8JS0qt2HCgEUtKrVg1fxLanN16hxYTTFAaKsxOw8aDTQGlqxsPNuk+fAqR0Rl16CGtPfvVXGzY34it1c1YOTcfW6ubsWF/I579Kjvq0k0yaukqkdH5Dz20ft8JXx+lZLt++87RVrjcgTV7LrfEO0dbdYootlhmriGjlq4SxQMjDj2kB7NJ4IE7voQNBxqxsCgLv/nsT3qHFDM8g9IQ29GJBs+IQw9pbaJlJB6dOi6gEvjRqeMw0TJS79BigglKQ2xHJxocow49pDWz6UZZeW1zp6/s3Jyg3+QJ+rKMie3oRIPD67ceLjewqCQHhxo7UGxNx6HGDiwqyYHLrXdkscEEpTH/dvQnSyYwORGp8NzsvH6fldK8jKDXdRNZYXYa9h47j8eKsrx9KbOw99j5hG2FYYLSGNvRiWiwbvSlbPf2pWxP6L6UrOLTkH87emleBu7Ns7CZj4hUO9XRhT22NmxePM33HbJs+xE8XDhO79BigmdQGmI7OhGRekLK+Bmoffr06fLw4cN6h0FEpBulJebJkgl4s+Z0QrTACCGOSCmn913OMygiojiSTIVWTFBERHEkmQqtmKCIiOJEsnVYZoIiIooTyVZoxSIJIqIIbaq0ozA7LeD6T7W9HbYzzqTrPBwNLJIgIooSjqupDXbUJSKKkP+4molU7m00PIMiIhqEZCr31gsTFBHRICRTubdedEtQQogcIcRvhRCfCSGOCyG+p1csRESRSLZyb73oeQbVC+AHUso7ANwL4HkhxJ06xkNEpEqylXvrRbciCSllG4A279+XhBCfARgP4A96xUREpEawUvLSvAxeh4oyQ1yDEkJYARQBqAly37NCiMNCiMMOh0Pz2IiISB+6JyghxCgA/wPg+1LKi33vl1JukVJOl1JOz8zM1D5Aoji0qdLe73pItb0dmyrtUV2Xmu1EGsumSjtW77IFPKfa3o771u3HU9tqAx5bXmVH2dbavqsI+Rr8Y1Fur95lw+pdNtXxDfZ1RUPZ1lqUVwWuX+0+iCatXruuCUoIkQJPctohpdylZyxEiSSaHUnDrUvNdiKNpTA7DXtsbVi2/Qiq7e2otrdj2fYjuHDlOg40OHxf0OVVdqyraMDMfIvq12A2ASt21qO8yu67vcfWhj22toj3lR6ddU0CWFfR0G8fmETMNhmUVq9dt6GOhBACwBsALkgpv6/mORzqiEi9aM4bFG5darYTaSxKUupxuQEAKWYTNi+ehuOtTqyraMAMazrqmjuxZkEBls5SN7SQEsPsSRl4u74VjxWNR+VJB15dVAQAg9pXWs/NVG1vx9Pb6tDd4/btg9QUE14vm6H59a9ovnYjDnU0E8BiAHOFEJ96/31Nx3iIEko0O5KGW5ea7UQaS2leBpaUWtHd40Z3jxtLSq0ozcvA0ll5mGFNR21zJ2ZY01UnJ/8Ydte3YoY1Hbvrz/piGey+0rqzbmleBl4vmwGTCaht7oTJBF2SkxJLrF+7bglKSvmRlFJIKQullHd7/72rVzxEiSaaHUnDrUvNdiKNpdrejq3VzUhNMSE1xYSt1c2otrejvMqOuuZOFHvPHvpej1HzGhYWZaGuuRMLi8b7YhnsvtKjs+7xVie8J5ZwuT239aDJa5dSxs2/adOmSSIa2KFGhyz6yT55qNER9Ha01qVmO5HGcqjRIaf8+D055cfv+bYx5cfvyUlr35UTX9gjt3zYKKWUcsuHjdLqd1vNa9jyYWO///23Fcm+iuY+Vkt5zQU/elf++/sNsuBH76reB9EU7dcO4LAM8p3P6TaIElA0p4MIty4AA24n0lg2VdpxqqMLj0zNCrjO9YP/Poo7skbjF2XFvseWV9lxqLED25YU91tPsNdgO+P0xaLEcKqjCwDw8uOFquJTs19iNeXG11/7CCfPXfI16ynXpCbdNhq/ev7+mGwzmGi/9lDXoJigiIjiRKLOQ2XEIgkiIorAx00d/a45HW914uOmDp0iii0mKCKiODEz3xK0H5SavmDxiBMWEhHFCaWsfl1FAz44fj7ivmDxhmdQRERx5Gb6gsUbJigiojhyM33B4g2b+IiI4oRyzUlp1lNuA0jIMykmKCKiOHGosSPgmpPy/6HGjoRMUGziI0oyekwTMVj+sSp/+8dq1LhjYVOlHc9+NTcgEVXb2+FyY8COyvGKCYooyegxTcRg+cdamJ2GZduPYNn2IyjMTjN03LEQT+9btHAkCaIkpPU0ETfDP9at1c0AgCWlVsPHHQvx9L5FgiNJGIBRZsMk0nqaiJvhH+sDd3wJS0qtvrgBJE0THwDYzjgxe1JmwPuWyM2cTFAaSrZe4GRcekwTMVj+02S8Xd+K8qomrJybj63Vzb7mvmRhNgFv15/1TRWizAycqPuAVXwaSrZe4GRMSjOR0jx0b54l4LaR+McKAO8dO4fuHjdaOq/qHJn2qu3tWL/vj1hUkoO9x85j9qQMrKtowKKSHNjOOA333kUDz6A0lky9wMmYbGecAcmoNC8Dry4q8k2fYST+sdrOOPF62Qw8VjQeu+vPYkmpFZsXTzNk3LFgO+PEqvlf9iWn3fWtmJlvwa5PWhP2DIpFEhraVGlHy4Uu7KxpwQxvL/BFJTnIGTsyrofKp+Sk1dQP/ttRzqhmT8rEe8fO4fWy6Ql55hDK3J8dRNrwIfi0xen7Drk7Jw3Oq7048MM5eoc3aCySMICWC13YUdOCRSU5eOu5UiwqycGOmha0XOjSOzSiiGlV9qxsR7nesnxOLipPOrBq/pcDtp8Mbs8YgfoWJyZaRqC2uRMTLZ7bt2eM0Du0mOA1KA2d/aIbT3jbjy0jT2DvsfN4oiQHZ7/o1js0oogpTYOxLntWtvP0tsN4cMqt2Hiwybedr2SlJez1l2Bm3G7Bha7rqG9xYtQwM5o7rqAoJw0zbk/MQismKA0pvb0tI09gw4FGrJybj1XzJ+scFdHg+ZeAr5ybH7NEUZqXgaWzbu+3ndK8jKRJTgBwqqMLjY4uWEamoKOrB5aRKWh0dKGgIzFbYdjEp7F4Ku8lGohWxzM/Nzd097jQ0dWDrLRUdHT1oLvHpXdIMcMzKA2t3mXDHlsbNi+e5ivvXbb9CB4uHIeXHy/UOzyiiGhVrh5PZfGx1tB2ET0uiWFDTPjGtGxs/rAJ13rdaGi7qHdoMcEzKCIaFK3K1eOpLD7Wzl28hqFmga/dNQ4bDjTia3eNw1CzwLmL1/QOLSZYZq6hTZV2mE3AxoNNvovKy+fkwuUGy8xJF1qVilN0sMycYqYwOw0bDzb5xtKaPSkTGw82JWwnOzK+ZBwhO54lW5k5E5SGSvMysHxOLt6uP4tiazrerj+L5XNyk64dnYzDv1R8/b4TSXttJ164JJCfORLNHVd8Zeb5mSPhip+GsIgwQWmo2t6OjQeb8FhRFmqbO/FYURY2HmxK6ook0l88jWye7GbmW2B3dGFMqhmXr7kwJtUMu6MrYQecZoLS0JYPm/DQlFtRebIdK+fmo/JkOx6aciu2fNikd2iUxFjCHT9cbuDunDRc7HZh1DAzLna7cHdOGlxuvSOLDSYoDc3Mt2BnTQuWz8nFqvmTsXxOLnbWtCTsrx8yPv8S7lXzJ/ua+5ikjKnlQhfqW5yYkjUGl6+5MCVrDOpbnAk7XBoTlIZcbmDNggJsPNiE9ftOYOPBJqxZUBDRr59NlfZ+Xx6JPGEZxRZLuOPL3t+fQ1FOGlqd3Vg5Nx+tzm4U5aRh7+/P6R1aTLCjroaUst1LV3t9Q7ZEOt2GUnWlfKn0nS+HKBLBSsmTbfigeHL3hFvw2waHbx650cOHYF1FA/6sIFPv0GKCCUpjfdv7782zRPRloNUAnURkPB1d15FiFtiwvxGXrvZia3UzUswCHV3X9Q4tJtjEp6Fotfez6oooeQkh0N3jwoYDjejucUEIoXdIMcMEpaFvv16LsSNSAtr7x45Iwbdfr41oPay6IkpOl7t7ca3XjR5vx6cel8S1Xjcud/fqHFlsMEFp6Eujh6HR0YWFr30EAFj42kdodHThS6OHqV5HtM7CWGxBFH+aQ0yrEWp5vGOC0tDP/moqTAKob3Hiy2vfRX2LEybhWa5WtKquOMQNUfyRISp+Qy2Pd0xQGlqx4xNM9SYA5RR9anYaVuz4RPU6npud1++aU2lehqqBPf3PmpTEtmz7ESwq/5hD3JBqwc6+V++yYfUuW8CyZD0jj1XrxKZKO0LloQTNT0xQWiqacAvqWwLPdOpbnCiacIsm2+971gQAPS43qu0dLLYg1YKdfe+xtWGPrY1n5Ihd60S456eYErNQgmXmGrrgVwqaYha+s6gLGpWI9i1R95SomvDsrNxBlbxTcgrW1WHz4mkAwO4PiF1XkNK8DGSlpaLV2d3vvgkWjmZON8l29iIEgOEpJvS4JIanmCC8y7XiX6Le43Jj8+JpHOKGIhasqwO7P9wQq33R0RV8YsIznVeisn6j0TVBCSEeFEKcEEI0CiFe1DMWLfzV9GyYBHC1x41Rw8y42uOGSXiWa0UpUZ+ZZ0GK+cbbzyFuKBLBujqw+8MNsdoX13uDz6vRk6DzbejWxCeEMAN4DcCfAzgDoE4I8Wsp5R/0iinW/nSxGy4JDDEBT828Hf95sBG9bs9yLfiXqPcdJkn5BZzMv3pJnb7Hzb15FizbfgQAsHnxNN+yZC28CbZ/orEvqu3tUNKQAPBY0Xjsrj/rWZCY+Sl0ghJCPB7uiVLKXTe57WIAjVLKJu/2/gvA1wEkbIKqP/0F5hVk4itZab6x+I63OlF/+gtNth+uRD3ZvkRo8IIdRw8XjvP9rfyfrMdWrD5nSuuGZWQKniiZiA0HGrGwaDzeO9aG7p7ErOMTUgZPvUKIrd4/vwSgFMAB7+0/A3BQShk2gQ24YSG+AeBBKeUz3tuLAZRIKVf0edyzAJ4FgAkTJkw7derUzWxWV5sq7TCbgI0Hm3wXT5fPyYXLHXzQzmS1qdKOwuy0gA9ztb0dtjNO7qcY4n7XRyT7/Z6f7MNEywicunDV9x0ycexwnOq4gk/+ab7WoUeNEOKIlHJ63+Uhr0FJKZdIKZfAc/J4p5TyL6WUfwngK9GKKdhmg8SxRUo5XUo5PTMzvkfs/df3GvBSRQOWz8nFiGFD8NCUW/FSRQP+9b0GAPHZbyTSPh9qHh+tMl21sQ2m34rRR+IYTHynOrqwbPuRgP2+bPsRnEqQUQqM+p5FcrxfuNKD+hYnJo4djlXzJ2Pi2OGob3HiwpUercPWhJoiCauUss3v9nkAk6Kw7TMAcvxuZwNojcJ6+zHKgWn2Duq4rqIBJ85dwo6aFt/y1btsWLb9SMBBaYQPz0AiTSZqHu9fprt+34lBt9+rjW0wCbEwOw1PbzuM8ip7wHNqP+/QtMNqqGP7VEdXxK/pkalZAIBl249g/b4TvutKynKjUvv5NuroKYM53utbnJjy4/f69atMNGoS1EEhxPtCiDIhxHcAVAD4bRS2XQfgy0KI24UQQwH8DYBfR2G9/RjlwFT6KkjgxsVNAKOGDcEeW1vAY43y4RlIpB8utY+PRpluJNsa6HF9vwRL8zLw+D1ZeKmiAX/3359ixc56LJ+Ti7rmTk07rIY6th+ZmhXxl15pXgY2L56GHpc7oBuC0a8hqf18R+uHTyyoPd7n+c37dPmaK+jyRDJggvJeE9oEYCqAuwFskVJ+92Y3LKXsBbACwPsAPgPwlpTy+M2uNxijHJh/U5wTdHnn1R4sKbVi8+Jpusc4GJEmEzWPj1aZrtrYBnpcsC/BvcfO4/58C3bXn0V+5khsPNiEzYunafo+hju2k6VfUiSfb6PuE7XH++tlxbCMTAlYZhmZgtfLirUIU3Nq+0F9AqBCSvl3AN4XQoyOxsallO9KKSdJKfOklC9FY52hGOHA/EpW8F/RC4uy8GbNaQDQPcbBiDSZDPT4aI3YHklsAz0u2Jfg8jm5+EPbJRRb01Hb3InZkzJuKjFYX6yA9cWKAZf1FWp7g3lflm0/ghSzCSvn5iPFbAq4JmVkave5EftqRXK8P72tFh1dgdebOrp68PS2yKbsiRcDJighxFIA/w/AZu+i8QDejmFMMWGEA/O7O4MPCvvhSYdv4Nat1c2G+vAMJNJkoubx0RqxXW1sah/n/yU4e1IGNh5swvI5uZ4pVIqy8HZ9K8qr7Dd9rCkJaaDE5B9/sE6zkSb5d456LgEro4sowxcpy41MzT6P5g+faIrkeN/f4PD9PWqYOejyRBKyzNz3ACE+hafPUo2Ussi77PdSyrtiH16g6dOny8OHD0f8vPte3o+Oy9ew7aliXwfVsl/UwjJqGH63el7Q50Sz5FZZ16LyGt+yzFFD4bh8Ywy+nUtLsGz7ETxcOA6PTM3CO0db8f7x874Dt2xrLWbmW7B01o1tl1fZcaixA9uWBD+931Rpx6mOLjwyNSvgV/U7R1sx0TJS9QjoofYDgID1K2X0TY4uTLSMBACYTQgoo//6ax/hcncvim8f63teeZU94BrcCw8WDBivmvfH//Vv+bAJM/Mt2GNrgwnAX0wZB7MJ+GVNC9KGD4EbwK+ev9+3nn95rwF3jhuDNme3b7/f88/78MWVHpTmWVBt78DU7DQcO3sRwiTw93/hqRv6l70nIAHMmZSB+tNfIDXFDMfla0hNMWH0sBRIAI5L3ZAQcLkH17tSGRc0fUQKhg0xo9XZjdGpQyAgcanbBQnPcFout0TGKM9cY+2Xr8Fs8mzzjqwxAADHxWsYPtSMzivXkT5iKP50qRtXr7tx1/gxSB85FJ+1XcII7/2F2bdg25JiVNvbseXDJjz71VzfcWkSwH15Ft/7/NS2Wnza8gX+4iu34eXHC0O+jwO9h2qP+YE6oCvbsZ1x+ranbEdZrjamUAZ6Xt/7lc+K/2dDzXaUHy3zCjLxelkxnt5W60tOza8sCPm8aIt2l4SIy8z9XJNS+r5JhRBDEGf9lm8bMwzXXRIVNs8vwQpbK667JG4bE3qiwGgWVijr8td3ZJJ3jrZi8+JpeGRqVsBFbiURzMy3YF1Fg69qrLzKjnUVDZiZbwm73T22Nl8zjdKEs8fWpvp1hNsPhdlpeP/4ed9jzSZPhWJupudLSLmtjKhUbW9Hk6MLbc5uvF1/Fsu2H0F5lR0b9jfi5LlLOHnuEv54/rKqeNW8P8/NzvPtz/G3pGJdRQNM8FRAvX+sDesqGpA2fIinIsr7pa2s5+HCcXj/+Hnf857eVosLXT1wS+Cjxg58qzgHR8840eOWmJA+HOsqGtDc3gWTSeDW0cOwv8GBiZYRaHV2o8flSRytzm60ObvR68agkxMAuKXnX0dXD1qd3RAALnX34qI3OQGe4bSuuyRand1odXbjukv6lh0/68Qfzl5Eq7MbdkcXLnT1wO7owqVuF3rdEvUtThxocOBPl27cPzPf4ts3M/Mtvn0/M9+CAw0OvOR9n8ur7DjQ4MCFrh68XX827Ps40Huo9pgf6AxE2Y5/cvK/7f+FOtjP/UDP63t/sM9GJN8vSlLS68xJq8IzNWdQ/wrgCwDfBvBdAH8L4A9SyrVRjUSFwZ5BAcDa3TbsqGnxjQb8REkOXlpYGPY5yk6PxojE1fZ2fPv1WvQG+WKampOGFr+Od6G2o3xAZ1jTUdfciTULCgJ+XYba7rLtR9Dj8vQ0TzGbIq7MCrcf+t63fE5uv47I/rdfXVQEwFPK3N3jQo9LYqhZYFiK2dekpDZete+P8rg7x43GR40dvrPXnPThONN5FYtKcrD32Pl+67nxvDH4qLEdOenD0dJ5FQB8x1F+5khcuNLje8zk20bh5LnLvnUqy43CJDzJzf9vgfC/OIenmLDUO+J9333zZMkElFc14WqP23dGMDzFhFXzJ2HD/sYB38eB3sPBHPPBRPJZHuznfqDnDfRZUbudYE2/Wp49KaL5/XgzZ1AvAnAA+D2AZQDe1SM53ayXFhb6vlSy0lIHTE5AdAsrSvMy8Ldz+n+wml9ZgF89f7+q7SydlYcZ3gvyM6zpqj6opXkZWFJqRXePG909biwptUb8OsLth773LZ2VF/a2UkSwpNTqG+Dyukv64ook3kgr9D5q7EBWWiocl69j1DAzWjqvYoY1HS8tLAy6nhvPa0dWWipaOq+i2JoecBz95gdzAh5z4tzlgHUqy7VQbE0Pe39WWir8fx+5pWdZuORUbE3H0lm5IffNhgONWDorF8XWdHhzEZbOysXSWXmq3seB3sPBHPPBRPJZHuznfqDnDfRZUbOdTZV27FxaErBs59ISXfpLalF4piZBfVdKWS6l/KaU8htSynIhxPeiHkmMrd1t832ptDq7sXa3bcDnRLOwQllXX9YXK1Rvp7zKjrrmThR7f00qTR8DbXdrdTNSU0xITTFha3VzxK8jXHx97yuvsoe9rTT5eOai8lxMGWoWvrgiiTfSCr378y1odXYjc9RQXL7mQk76cNQ1d2LtblvQ9dx4XgZand2YfNso1DZ3BhxHT2+r7fcY/3Uqy7VQ29wZ9v5WZzf857UzCfiaCMOts7yqKeS+WTk3H+VVTaht7vQ1V5VXNaG8yq7qfRzoPRzMMR9MJJ/lwX7u1VSnDvTZGMipjq6Aa9kAsKi8RpfRPrQoPFOToL4TZFlZlOOIKaV574mSHFSvnocnSnKwo6YlbJKKZsWPsi7/iQnHjhzq+3tRec2A21GaOtYsKMBbz5VizYKCgPb5UNtVRgP4RdkM/KJsBgBEVDocbj/0vW/5nFys8w7lFOy2Uqn4zBuH0etyIzXFjLULCjAsxYxelxtPb6vDM28cVhVvpBV6D025FYcaO1CUkwbH5esoyknDmc6ruDsnDTtqWvDQlFsD1lNeZfd7XjueKMnB544bXwJL7rdiXkEm9jc4MHZEiu8xjkvXMbcgEztqWjBx7HBNmvcimTPH7R1NP8UkfGdToc6glIRztceN0cOH9Ns3ry4qwujhQ3DVO1Dpiw8VYO2CAlztceOligb0utxh38eB3kM1x7yaUSQi+SwP9nM/0PMG+qyo3c4va1t8f6+cmx90uRa0qogMN1jstwAsAnA/gCq/u0YDcEkpH4hqJCoM9hrU3J8dxH15YwOa9dbutuF39gs48MM5QZ8Tyyq+5lcW+Nb1yt4G37Jw2zFqFV+4yqRglUqrd9nwh7aLuHPcGF9cSkx/aPNM3BitKj7/xylVfIcaOzD+llTkjB3pq+K7L28szn7R7duP/pVqyvOWzsrDfS/vx21jhuFrheNwqLED9+ZaUPd5B6rtHVg1fxKWzsrzPXf8LanY+/tzSB85FBMtI/BpyxdIHWKOehVf+oihOH/pGlLMAr0uNy5fc2HkMDNGD0vxVecBniq+YSlmABK5maMA9K/iu3rdhfaua/jKuBtVfLeOGYZL3b3IGTvCkFV8A1XwRXKsRPrYSJ4X7Sq+1BQTunvcvv+BxKziC5egJgK4HcDL8FyHUlwCYPOOBKGpmymSIKLEFM2L9fGg2t6Op7bV+RLUL8pmxP3rHcxo5qeklAcBPAFPH6hKKWUlPMMSaTcFLBH1Y5QBkI3ACKPEaPV+rN5lw9Pb6gJG+3h6W12/AYoThZrm67cA+M+G5QLwf2MTTmLjlwpFi1EGQDYCLS7WD0Sr9+P8xW5097ixcl4+Vs2fjJXz8tHd48Z5jWbl1pqaKd+H+HfUlVJe944+ThFSDuJg7eVEkfAfGzBZmraC6XvNSa+p5rV6P4pvt+C+PAs2HmzCpau9eLPmNNYsKPCV+CcaNQnKIYR4VEr5awAQQnwdgHF6HsYR2xknls/J7ddZLxmnxU520bjI7N+0tXJuflIeQ7GaXn0wtHg/lGPj0tVe33YG2zcsHqhp4nsOwBohxGkhRAuAF+DpsEsRKsxOw8aDTZg9KdM74GgmNh5sSspmmWQXjSYhIzRt6e252XlBO8TqMUW9Vu9HUr3vUkpV/wCMAjBa7eNj8W/atGky3m35sFFaX9gjv7nxkLS+sEdu+bBR75BIJ4caHbLoJ/vkv7/fIIt+sk8eanRE/FzlOX1vk7a0ej8S9X0HcFgG+c4PV2b+pJTyTSHEqhCJbX3MsmYI8V5mvnqXDXtsbXjgji9hd30rFhZl4Tef/QkPF47z9Reh5LJ+3wlfU82q+ZNVPy/a/VDo5mj1fiTq+x6qzDzcNaiR3v+jMjkhefS63PjNZ3/Cyrn52FrdjN5EvbpJA+rbVHNvnkX1dYtgX0bKWIakPa3ej2R730MmKCnlZu///0u7cBLbI1OzAuY9AoAhZhMemZqlU0SkF6NUnxEZWcgEJYTYEO6JUsqV0Q8nsdnOOLF58TR8bO/wNevcm2dhFV8SMlL1GZFRhaviO+L9lwrgHgB/9P67G57OuhQh5fTcv1nHfzklDyNVnxEZVbgmvjcAQAhRBuDPpJQ93tubAOzTJLoEw2YdIiL11PSDykJgocQo7zKK0Iodn6AoJw22M05U29tRmpeBopw0rNjxiSGGPBpoKCblfv/H+d/WKv5oDhkVybo4VBXpLdmOQTUJ6hUA9UKIbUKIbQA+AbAuplElqIfuug37Gxyo+7wDK3bW4+lttdjf4EDRhFsMMY7aQJ1HlfvNJgTMC6Tc1ir+aI57Fsm6OP4d6S3ZjsGQ/aACHiTEbQCUeYZrpJTnYhpVCPHeD2pTpR11n3dgf4MDlpEp6OjqgdUyAucvXsPrZdMN0cw30NQFyv2zJ2Xi7fqzeKwoC5Un2zVvpozmFAuRrCvZpnYg40nEYzDi6Tb8nigAPABgqpTyVwCGCiGCz5BHYRVmp6G+xelLTsNTTGjuuIIHp9xqmANsoKkLlPt315/FDGs6dte36jLFQTSnWIhkXUaY2oGSWzIdg2qa+P4TwH0AvuW9fQnAazGLKAaM0m777ddr0X2915ecrva4YTYBu+tbNRtPa6B9EW6cr02VdpRX2fFmzWksLBqPuuZO3J+fgfKqzzUfD0zNeGRq3/dIxjbTchy0vvEr+7/vdOaxOo713r6RRfs7Re36yrbWYu1uW8AxuHa3DWVbawe1XaNTk6BKpJTPA+gGACllJ4C4mm7DKO22vW6JK96kpCQnZSAJ//hiKdy+8K8yXDV/sm/6AOWxZhOwrqIBD025FZUnHVhUkoNDje14/J4szeL3jzlUnGpea6TrivSx0dA3fmX/m02B8cTqONZ7+0YW7tgaTPJS+x3lvHIdO2pa8NCUW7Fq/mQ8NOVW7KhpgfPK9WCrjXsDXoMSQtQAKAVQJ6W8RwiRCWCflFLzSYxu5hqUEdptJ//oXVzr7b+/hw0R2LqkWLPxtELti4HG+dpUaYfZBKzf90c8OOVWVJ5sx/I5uXC5PR8wreKPZDyygd73SNalxzhofeNfPicXGw82aXYc6719Iwt1bPXtTtL3dqTr87d6lw27PjmL671uzLCmo665E0OHmPD4PePjejzPUNeg1CSoJwD8NTyddd8A8A0AP5JSaj6r7s0WSQx2YM5oqba3Y/HPa+Dy2+VmAWx/pkTzD/nN7Au992Ok4i3evvrGr/Xr0Xv7RhZqXwz2B/FA+1b5kfjK3ga43J6z2hcf8kxYGM+dvAdVJCGEMAH4HMA/AHgZQBuAx/RITjfLCHOo2M44ceuY1IBlt45Jhe2MU9M4bmZfGGE/RiLe4u2rb/zKNUCtXo/e2zeycMfWYAoZ1ByrhdlpWL/vpO/SgMsNrN93MnGbWYPNweH/D8DvBnqMVv8GOx+UUeZQmfez38qJL+yRE1/YI/PXVPj+nvez32oWw83sC6PsR7XiLd6++sarzCWmzCEW69ej9/aNbKBjK9K5vtQeq1s+bPR9b3xz4yHf3/E+rxxCzAelpkhinxDiL73l5nEp3MCcWmp0dAEAinLS8MeXvoainLSA5Vq4mX1hlP2oVrzF21ff+F1uYM2CAt+v51i/Hr23b2Thjq3BFNOoPVb32NowPMWEhUVZqG3uxMKiLAxPMfWbJSFRqLkGdQmeuaFc8FbyAZBSyjExjq2feO+oe8c/7kXBbaOx+/n7fcsWvvYRGs5dwmf//JCOkRFRtMSymEa5BuVfqKIUKiXiNahwExYCAKSUnLAwSkpyLZiZbwlY9rXCcUgbEVdV+2El6oyfRGrFclJBpRw92IDTiUhNEx+EEI8LIdYLIf5dCPFYjGNKWDPzLVhX0YDyKk9/iPIqO9ZVNPRLWvHMKH3OiBJRvDdbR0pNE99/AsgH8Evvor8GYJeezruaivcmPuBGUlL6MKxZUIClsxLrzMIIfc6IKH4MuokPwGwAU7yVFhBCvAHg91GOL2ksnZWHD46fR21zJ4qt6QmXnIDAEtuVc/OZnIhoUNQ08Z0AMMHvdg4AW2zCSXzlVXbUeZNTXXOnr7kvkcR73yMiMgY1Z1AWAJ8JIZTRCGcA+J0Q4tcAIKV8NFbBJRqleU9p1lNuA0iYMynOGkxE0aImQf1TzKNIEr+sacGikhxfMlo6Kw/N7V34ZU1LwiSocBdxmaCIKBJqyswro71RIcS/AXgEwHUAdgBLpJRfRHs7RvPThVOwYmc9FhS2+waR3HvsfEKViMayxJaIkouqMvMY+ACewotCACcBrNYpDk0pZxMrdtZj/b4TbPoiIgpDlwQlpdwnpez13vwYQLYeceghmWbDJCK6GSETlBBiQqj7ouwpAHvDxPGsEOKwEOKww+HQKKTYYYUbEZE64c6g3lb+EEL8T6QrFkL8RghxLMi/r/s9Zi2AXgA7Qq1HSrlFSjldSjk9MzMz0jAMResZWYmI4lm4Ign/0ctzI12xlPKBcPcLIb4D4GEA8+RAw1kkCFa4ERGpFy5ByRB/3zQhxIMAXgAwW0p5JZrrNjJWuBERqRcuQU0VQlyE50xquPdveG/f7HQbrwIYBuAD7zRTH0spn7uJ9RERUYIJmaCklOZYbVRKmR+rdRMRUWLQqx8UERFRWExQRERkSExQRERkSExQRERkSExQRERkSExQGtpUae83akS1vR2bKhNv0kIaGI8HovCYoDRUmJ0WMLSRMvRRYXaazpGRHng8EIUn4mmUoenTp8vDhw/rHcZNUb6EniyZgDdrTnO6jSTH44EIEEIckVJO77ucZ1Aa43Qb5I/HA1FoTFAa43Qb5I/HA1FoTFAa4nQb5I/HA1F4SZGgjFIt9e3XazF2RErAdBtjR6Tg26/XGiZGLYR6rWVba32v2b9wQLmdaPsi3PQrRMGUba1FeVXg56C8yo6yrbU6RRRbSZGgjFItddf4MWh0dGHhax8BABa+9hEaHV24a/wYw8SohVCvdWa+BSt21sNsAlbsrEd5lT3gdqLti+dm5/W75lSalxF0WhYiAJiZb8G6igZfkiqvsmNdRQNm5lt0jiw2kqaKzyjVUgtf+wj1LU6kmAV6XBJFOWnY/fz9hopRC6Feq7J89qQMvF3fiseKxqPypCOh9wVRJJSkNMOajrrmTqxZUICls+L7R03SV/EZoVpqU6Udf/9ggS85pZgF/v7BAl/TlV4x6tG8GOq1Kst317dihjUdu+vPsrqNyM/SWXmYYU1HbXMnZljT4z45hZM0CcoI1VKnOrrw5M9rfMmpxyXx5M9rcKqjS9cY9WheDPValeULi7JQ19yJhUXjWd1G5Ke8yo665k4Ue8+g+l6TSiRJkaCMUi1V9/kFuCVgEsDy2XkwCcAtPcv1jFG5OL9iZz3W7zvhiyNWZy2hXqtyzWn5nFxUnmzHmgUFqDzpwPI5uaxuI8KN5r01Cwrw1nOlWLOgIOCaVKJJimtQmyrtKMxOC/jCrba3w3bGqekF6Tv+cS/G3zIcZ764iu4eN1JTTMi+ZTjOfnEV33tgku4xrt93AhsONGLl3Hysmj85ZtsJ9X5s+bAJz341F7YzTt/9yj4ozE7T/P0iMpqyrbWYmW8JaNYrr7LjUGMHti0p1jGymxPqGlRSJCgjqba346ltdb4E9YuyGYa4vpJMBRpEZCxJXyRhBNX2dizbfgQpZhNWzs1HitmEZduP6N50ZZQmUCIif0xQGnrnaCsAYPPiaVg1fzI2L54WsFwv7DBKREbEJj4NGeVaGBGRkfAaFBERGRKvQRERUVxhgtJQMg0IS0R0s5igNHSqoyugak+p6lNGkiAiohuYoDT0yNQsAMCy7Uewft8JLNt+JGA5ERHdwASloS0fNuHRqePQ43Jjw4FG9LjceHTqOGz5sEnv0IiIDIcJSkMmAeyoaUGvy1M52euS2FHTApPQOTAiigvJdh2bCUpD9+V5JhXrdUtkpaWi1y0DlhMRhZNME5sCwBC9A0gmTY4uDE8x4XqvG63ObpgFMHSICU0OFkkQ0cD8Zx5IhnEzeQalof+qbYEA4G3hg0sCwruc4keyNbOQsRhh8lWtMEFpaHSqGVd63BAAVs7NhwBwpceN0almvUOjCCRbMwsZixEmX9UKm/g0dHvmKNhanJAANhxoBOA5g7o9c5SucVFkkq2ZhYzDf+aB0rwM3JtnifkEo3riGZSGHpoyDjuWlgQs27G0BA9NGadTRDRYydTMQsaRbDMPcLBYjZW+vB+tzm7f7ay0VFSvnqdjRDQYnOCRKHo4WKwBKMkpKy0Vza8sQFZaKlqd3Sh9eb/eoVEEOMEjkTaYoDR07mJ3wBlT9ep5yEpLxbmL3QM8k4wk2ZpZiPTCJj4iItIVm/iIiCiu6JqghBA/FEJIIQSvLhMRUQDdEpQQIgfAnwM4rVcMRERkXHqeQf0HgH8AED8XwYiISDO6JCghxKMAzkopj6p47LNCiMNCiMMOh0OD6GKHY7gREakXswQlhPiNEOJYkH9fB7AWwD+pWY+UcouUcrqUcnpmZmaswtUEp3wnIlIvZmPxSSkfCLZcCHEXgNsBHBVCAEA2gE+EEMVSynOxiscIHpmahT22NizbfgRLSq3YWt3sW05ERIE0b+KTUv5eSvklKaVVSmkFcAbAPYmenABPB8+V8/IDpnxfOS+fHTyJiIJgPygNFWanYcP+Rri9M+m63RIb9jdymgYioiB0T1DeM6mkGcSs1+VGj0ui2JqOHpdEr8utd0hERIake4JKJu8cbcUQswmPFWWhtrkTjxVlYYjZhHeOtuodGhGR4TBBaWiiZSRWzstH5cl2rJzr/X9ePiZaRuodGhGR4XBGXQ0pU4UHmw2TiIgC8QxKQ5ymgYhIPU63QUREuuJ0G0REFFeYoIiIyJCYoIiIyJCYoDRUtrUW5VWBI5eXV9lRtrVWp4iIiIyLCUpDM/MtWFfR4EtS5VV2rKtowMx8i86REREZD/tBaWjprDwAwLqKBnxw/DzqmjuxZkGBbzkREd3AMyiNLZ2VhxnWdNQ2d2KGNZ3JiYgoBCYojZVX2VHX3Iliazrqmjv7XZMiIiIPNvFpSLnmpDTrKbcB8EyKiKgPnkFp6Jc1LVhUkuNLRktn5WFRSQ5+WdOic2RERMbDBKWhny6cgr3HzqPa7pn+qtrejr3HzuOnC6foHBkRkfGwiU9DyuCwK3bW48mSCXiz5nTA4LFERHQDz6A0VpqXgSdLJmDDgUY8WTKByYmIKAQmKI1V29vxZs1prJybjzdrTvua+4iIKBATlIaq7e2+CQpXzZ/sa+5jkiIi6o8JSkOcsJCISD1OWEhERLrihIVERBRXmKCIiMiQmKCIiMiQmKA0xAkLiYjUY4LSECcsJCJSj0MdaYgTFhIRqcczKI1xwkIiInWYoDTGCQuJiNRhE5+GOGEhEZF6TFAaOtTYEXDNSfn/UGMHExQRUR8c6oiIiHTFoY6IiCiuMEEREZEhMUEREZEhMUEREZEhMUEREZEhMUEREZEhxVWZuRDCAeCU3nFESQaAdr2DMBDuj0DcH4G4P/pLpH0yUUqZ2XdhXCWoRCKEOBys7j9ZcX8E4v4IxP3RXzLsEzbxERGRITFBERGRITFB6WeL3gEYDPdHIO6PQNwf/SX8PuE1KCIiMiSeQRERkSExQRERkSExQRmAEOKHQggphMjQOxY9CSH+TQjRIISwCSF2CyFu0TsmPQghHhRCnBBCNAohXtQ7Hj0JIXKEEL8VQnwmhDguhPie3jEZgRDCLISoF0Ls0TuWWGKC0pkQIgfAnwM4rXcsBvABgClSykIAJwGs1jkezQkhzABeA/AQgDsBfEsIcae+UemqF8APpJR3ALgXwPNJvj8U3wPwmd5BxBoTlP7+A8A/AEj6ahUp5T4pZa/35scAsvWMRyfFABqllE1SyusA/gvA13WOSTdSyjYp5Sfevy/B86U8Xt+o9CWEyAawAMDP9Y4l1pigdCSEeBTAWSnlUb1jMaCnAOzVOwgdjAfQ4nf7DJL8C1khhLACKAJQo3Moevvf8PyodescR8wN0TuARCeE+A2A24LctRbAGgDztY1IX+H2h5TyV97HrIWnaWeHlrEZhAiyLOnProUQowD8D4DvSykv6h2PXoQQDwP4k5TyiBBijs7hxBwTVIxJKR8ItlwIcReA2wEcFUIAnuasT4QQxVLKcxqGqKlQ+0MhhPgOgIcBzJPJ2UnvDIAcv9vZAFp1isUQhBAp8CSnHVLKXXrHo7OZAB4VQnwNQCqAMUKIN6WUT+ocV0ywo65BCCGaAUyXUibK6MQRE0I8CGA9gNlSSofe8ehBCDEEngKReQDOAqgDsEhKeVzXwHQiPL/e3gBwQUr5fZ3DMRTvGdQPpZQP6xxKzPAaFBnJqwBGA/hACPGpEGKT3gFpzVsksgLA+/AUBLyVrMnJayaAxQDmeo+JT71nD5QEeAZFRESGxDMoIiIyJCYoIiIyJCYoIiIyJCYoIiIyJCYoIiIyJCYoohgTQrj8SqQ/9Q7Z43+/VQixSKfwiAyLI0kQxd5VKeXdYe63AlgEYGffO4QQQ/wG0CVKKuwHRRRjQojLUspRYe7/GMAdAD6HZ9SETnhGq04FMBLAT+A3YoAQ4lUAh6WU24QQ0+AZfWMUgHYAZVLKtli+HiKtsImPKPaG+zXv7Q5y/4sAqqSUd0sp/8O77D4A35FSzg21Uu8Ydf8HwDeklNMA/ALAS9EOnkgvbOIjir2BmviC+UBKeWGAx0wGMAWeoaEAwAyAZ0+UMJigiIypy+/vXgS2dqR6/xcAjksp79MsKiINsYmPSH+X4BkkN5RTAO4UQgwTQqTBM9I5AJwAkCmEuA/wNPkJIb4S21CJtMMzKCL92QD0CiGOAtgGT5GEj5SyRQjxlvdxfwRQ711+XQjxDQAbvIlrCDyzrSbz6OeUQFjFR0REhsQmPiIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIiMiQmKCIiMqT/D1+rLEm9CQL3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "\n",
    "ax.plot(y_test['F'], y_hat[:,0],'x')\n",
    "#ax[1].plot(y_test['NOX'], y_hat[:,1],'x')\n",
    "\n",
    "ax.set_xlabel('F true')\n",
    "ax.set_ylabel('F predicted')\n",
    "\n",
    "#ax[1].set_xlabel('NOx true')\n",
    "#ax[1].set_ylabel('NOx predicted')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = Imitation_model.to_json()\n",
    "with open(\"Imitation_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "Imitation_model.save_weights(\"Imitation_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('Imitation_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Imitation_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  0.0\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  0.0\n",
      "5  0.0\n",
      "[[-0.2459692]]\n"
     ]
    }
   ],
   "source": [
    "x0 = pd.DataFrame([0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "print(x0)\n",
    "prediction = loaded_model.predict(x0.T)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
